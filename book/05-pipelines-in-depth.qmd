# In-depth look into mlr3pipelines {#in-depth-pipelines}
<!--
```{r 05-pipelines-in-depth-001, include = F}
library(mlr3)
library(mlr3book)
library(mlr3pipelines)
```

This vignette is an in-depth introduction to `r mlr3book::cran_pkg("mlr3pipelines")`, the dataflow programming toolkit for machine learning in `R` using `r mlr3book::mlr_pkg("mlr3")`.
It will go through basic concepts and then give a few examples that both show the simplicity as well as the power and versatility of using `r mlr3book::cran_pkg("mlr3pipelines")`.

## What's the Point

Machine learning toolkits often try to abstract away the processes happening inside machine learning algorithms.
This makes it easy for the user to switch out one algorithm for another without having to worry about what is happening inside it, what kind of data it is able to operate on etc.
The benefit of using `r mlr3book::mlr_pkg("mlr3")`, for example, is that one can create a `r ref("Learner")`, a `r ref("Task")`, a `r ref("Resampling")` etc. and use them for typical machine learning operations.
It is trivial to exchange individual components and therefore use, for example, a different `r ref("Learner")` in the same experiment for comparison.

```{r 05-pipelines-in-depth-002}
task = as_task_classif(iris, target = "Species")
lrn = lrn("classif.rpart")
rsmp = rsmp("holdout")
resample(task, lrn, rsmp)
```

However, this modularity breaks down as soon as the learning algorithm encompasses more than just model fitting, like data preprocessing, ensembles or other meta models.
`r mlr3book::cran_pkg("mlr3pipelines")` takes modularity one step further than `r mlr3book::mlr_pkg("mlr3")`: it makes it possible to build individual steps within a `r ref("Learner")` out of building blocks called `r ref("PipeOp")`s.


## `r ref("PipeOp")`: Pipeline Operators

The most basic unit of functionality within `r mlr3book::cran_pkg("mlr3pipelines")` is the `r ref("PipeOp")`, short for "pipeline operator", which represents a transformative operation on input (for example a training dataset) leading to output.
It can therefore be seen as a generalized notion of a function, with a certain twist: `r ref("PipeOp")`s behave differently during a "training phase" and a "prediction phase".
The training phase will typically generate a certain model of the data that is saved as internal state.
The prediction phase will then operate on the input data depending on the trained model.

An example of this behavior is the *principal component analysis* operation ("`r ref("PipeOpPCA")`"):
During training, it will transform incoming data by rotating it in a way that leads to uncorrelated features ordered by their contribution to total variance.
It will *also* save the rotation matrix to be use for new data during the "prediction phase".
This makes it possible to perform "prediction" with single rows of new data, where a row's scores on each of the principal components (the components of the training data!) is computed.

```{r 05-pipelines-in-depth-003}
po = po("pca")
po$train(list(task))[[1]]$data()
```

```{r 05-pipelines-in-depth-004}
single_line_task = task$clone()$filter(1)
po$predict(list(single_line_task))[[1]]$data()
```

```{r 05-pipelines-in-depth-005}
po$state
```

This shows the most important primitives incorporated in a `r ref("PipeOp")`:
* **`$train()`**, taking a list of input arguments, turning them into a list of outputs, meanwhile saving a state in `$state`
* **`$predict()`**, taking a list of input arguments, turning them into a list of outputs, making use of the saved `$state`
* **`$state`**, the "model" trained with `$train()` and utilized during `$predict()`.

Schematically we can represent the `r ref("PipeOp")` like so:

```{r 05-pipelines-in-depth-006, echo = FALSE}
knitr::include_graphics("images/po_viz.png")
```

### Why the `$state`

It is important to take a moment and notice the importance of a `$state` variable and the `$train()` / `$predict()` dichotomy in a `r ref("PipeOp")`.
There are many preprocessing methods, for example scaling of parameters or imputation, that could in theory just be applied to training data and prediction / validation data separately, or they could be applied to a task before resampling is performed.
This would, however, be fallacious:

* The preprocessing of each instance of prediction data should not depend on the remaining prediction dataset.
A prediction on a single instance of new data should give the same result as prediction performed on a whole dataset.
* If preprocessing is performed on a task *before* resampling is done, information about the test set can leak into the training set.
Resampling should evaluate the generalization performance of the *entire* machine learning method, therefore the behavior of this entire method must only depend only on the content of the *training* split during resampling.

### Where to get `r ref("PipeOp")`s

Each `r ref("PipeOp")` is an instance of an "`R6`" class, many of which are provided by the `r mlr3book::cran_pkg("mlr3pipelines")` package itself.
They can be constructed explicitly ("`PipeOpPCA$new()`") or retrieved from the `r ref("mlr_pipeops")` dictionary: `po("pca")`.
The entire list of available `r ref("PipeOp")`s, and some meta-information, can be retrieved using `r ref("as.data.table()")`:

```{r 05-pipelines-in-depth-007}
as.data.table(mlr_pipeops)[, c("key", "input.num", "output.num")]
```

When retrieving `r ref("PipeOp")`s from the `r ref("mlr_pipeops")` dictionary, it is also possible to give additional constructor arguments, such as an [id](#pipeop-ids-and-id-name-clashes) or [parameter values](#hyperparameters).

```{r 05-pipelines-in-depth-008}
po("pca", rank. = 3)
```
-->

## `r ref("Graph")`: Networks of `r ref("PipeOp")`s
<!--

## Learners in Graphs, Graphs in Learners

The true power of `r mlr3book::cran_pkg("mlr3pipelines")` derives from the fact that it can be integrated seamlessly with `r mlr3book::mlr_pkg("mlr3")`.
Two components are mainly responsible for this:

* `r ref("PipeOpLearner")`, a `r ref("PipeOp")` that encapsulates a `r mlr3book::mlr_pkg("mlr3")` `r ref("Learner")` and creates a `r ref("PredictionData")` object in its `$predict()` phase
* `r ref("GraphLearner")`, a `r mlr3book::mlr_pkg("mlr3")` `r ref("Learner")` that can be used in place of any other `r mlr3book::mlr_pkg("mlr3")` `r ref("Learner")`, but which does prediction using a `r ref("Graph")` given to it

Note that these are dual to each other: One takes a `r ref("Learner")` and produces a `r ref("PipeOp")` (and by extension a `r ref("Graph")`); the other takes a `r ref("Graph")` and produces a `r ref("Learner")`.

### `r ref("PipeOpLearner")`

The `r ref("PipeOpLearner")` is constructed using a `r mlr3book::mlr_pkg("mlr3")` `r ref("Learner")` and will use it to create `r ref("PredictionData")` in the `$predict()` phase.
The output during `$train()` is `NULL`.
It can be used after a preprocessing pipeline, and it is even possible to perform operations on the `r ref("PredictionData")`, for example by averaging multiple predictions or by using the `PipeOpBackupLearner`" operator to impute predictions that a given model failed to create.

The following is a very simple `r ref("Graph")` that performs training and prediction on data after performing principal component analysis.

```{r 05-pipelines-in-depth-029}
gr = po("pca") %>>% po("learner",
  lrn("classif.rpart"))
```
```{r 05-pipelines-in-depth-030}
gr$train(task)
gr$predict(task)
```

### `r ref("GraphLearner")`

Although a `r ref("Graph")` has `$train()` and `$predict()` functions, it can not be used directly in places where `r mlr3book::mlr_pkg("mlr3")` `Learners` can be used like resampling or benchmarks.
For this, it needs to be wrapped in a `r ref("GraphLearner")` object, which is a thin wrapper that enables this functionality.
The resulting `r ref("Learner")` is extremely versatile, because every part of it can be modified, replaced, parameterized and optimized over.
Resampling the graph above can be done the same way that resampling of the `r ref("Learner")` was performed in the [introductory example](#whats-the-point).

```{r 05-pipelines-in-depth-031}
lrngrph = as_learner(gr)
resample(task, lrngrph, rsmp)
```

## Hyperparameters
-->
