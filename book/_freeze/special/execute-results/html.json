{
  "hash": "64cefb9a255d5bd7df0dc67041d00715",
  "result": {
    "markdown": "# Special Tasks {#sec-special-tasks}\n\n::: {.cell}\n\n:::\n\n\n\nThis chapter explores the different functions of [mlr3](https://mlr3.mlr-org.com) when dealing with specific data sets that require further statistical modification to undertake sensible analysis.\nFollowing topics are discussed:\n\n**Survival Analysis**\n\nThis sub-chapter explains how to conduct sound [survival analysis](#survival) in mlr3.\n[Survival analysis](#survival) is used to monitor the period of time until a specific event takes places.\nThis specific event could be e.g. death, transmission of a disease, marriage or divorce.\nTwo considerations are important when conducting [survival analysis](#survival):\n\n* Whether the event occurred within the frame of the given data\n* How much time it took until the event occurred\n\nIn summary, this sub-chapter explains how to account for these considerations and conduct survival analysis using the `mlr3proba` extension package.\n\n**Density Estimation**\n\nThis sub-chapter explains how to conduct (unconditional) [density estimation](#density) in mlr3.\n[Density estimation](#density) is used to estimate the probability density function of a continuous variable. Unconditional density estimation is an unsupervised task so there is no 'value' to predict, instead densities are *estimated*.\n\nThis sub-chapter explains how to estimate probability distributions for continuous variables using the `mlr3proba` extension package.\n\n**Spatiotemporal Analysis**\n\n[Spatiotemporal analysis](#spatiotemporal) data observations entail reference information about spatial and temporal characteristics.\nOne of the largest issues of [spatiotemporal data analysis](#spatiotemporal) is the inevitable presence of auto-correlation in the data.\nAuto-correlation is especially severe in data with marginal spatiotemporal variation.\nThe sub-chapter on [Spatiotemporal analysis](#spatiotemporal) provides instructions on how to account for spatiotemporal data.\n\n**Ordinal Analysis**\n\nThis is work in progress.\nSee [mlr3ordinal](https://github.com/mlr-org/mlr3ordinal) for the current state.\n\n**Functional Analysis**\n\n[Functional analysis](#functional) contains data that consists of curves varying over a continuum e.g. time, frequency or wavelength.\nThis type of analysis is frequently used when examining measurements over various time points.\nSteps on how to accommodate functional data structures in[mlr3](https://mlr3.mlr-org.com)are explained in the [functional analysis](#functional) sub-chapter.\n\n**Multilabel Classification**\n\n[Multilabel classification](#multilabel) deals with objects that can belong to more than one category at the same time.\nNumerous target labels are attributed to a single observation.\nWorking with multilabel data requires one to use modified algorithms, to accommodate data specific characteristics.\nTwo approaches to [multilabel classification](#multilabel) are prominently used:\n\n* The problem transformation method\n* The algorithm adaption method\n\nInstructions on how to deal with [multilabel classification](#multilabel) in[mlr3](https://mlr3.mlr-org.com)can be found in this sub-chapter.\n\n**Cost Sensitive Classification**\n\nThis sub-chapter deals with the implementation of [cost-sensitive classification](#cost-sens).\nRegular classification aims to minimize the misclassification rate and thus all types of misclassification errors are deemed equally severe.\n[Cost-sensitive classification](#cost-sens) is a setting where the costs caused by different kinds of errors are not assumed to be equal.\nThe objective is to minimize the expected costs.\n\nAnalytical data for a big credit institution is used as a use case to illustrate the different features.\nFirstly, the sub-chapter provides guidance on how to implement a first model.\nSubsequently, the sub-chapter contains instructions on how to modify cost sensitivity measures, thresholding and threshold tuning.\n\n**Cluster Analysis**\n\n[Cluster analysis](#cluster) aims to group data into clusters such that objects that are similar end up in the same cluster.\nFundamentally, clustering and classification are similar.\nHowever, clustering is an unsupervised task because observations do not contain true labels while in classification, labels are needed in order to train a model.\n\nThis sub-chapter explains how to perform [cluster analysis](#cluster) in[mlr3](https://mlr3.mlr-org.com)with the help of `mlr3cluster` extension package.\n\n## Survival Analysis {#survival}\n\n\n\n\n\n:::{.callout-warning}\nSurvival analysis with {mlr3proba} is currently in a fragile state after its removal from CRAN.\nHence most code examples listed in this page will not work for the time being.\nWe are actively working on a solution!\n:::\n\nSurvival analysis is a sub-field of supervised machine learning in which the aim is to predict the survival distribution of a given individual.\nArguably the main feature of survival analysis is that unlike classification and regression, learners are trained on two features:\n\n1. the time until the event takes place\n1. the event type: either censoring or death.\n\nAt a particular time-point, an individual is either: alive, dead, or censored.\nCensoring occurs if it is unknown if an individual is alive or dead.\nFor example, say we are interested in patients in hospital and every day it is recorded if they are alive or dead, then after a patient leaves it is unknown if they are alive or dead, hence they are censored.\nIf there was no censoring, then ordinary regression analysis could be used instead.\nFurthermore, survival data contains solely positive values and therefore needs to be transformed to avoid biases.\n\nNote that survival analysis accounts for both censored and uncensored observations while adjusting respective model parameters.\n\nThe package [mlr3proba](https://mlr3proba.mlr-org.com) [@mlr3proba] extends [mlr3](https://mlr3.mlr-org.com) with the following objects for survival analysis:\n\n* [`TaskSurv`](https://mlr3proba.mlr-org.com/reference/TaskSurv.html) to define (censored) survival tasks\n* [`LearnerSurv`](https://mlr3proba.mlr-org.com/reference/LearnerSurv.html) as base class for survival learners\n* [`PredictionSurv`](https://mlr3proba.mlr-org.com/reference/PredictionSurv.html) as specialized class for [`Prediction`](https://mlr3.mlr-org.com/reference/Prediction.html) objects\n* [`MeasureSurv`](https://mlr3proba.mlr-org.com/reference/MeasureSurv.html) as specialized class for performance measures\n\nFor a good introduction to survival analysis see *Modelling Survival Data in Medical Research* [@Collett2014].\n\n### TaskSurv\n\nUnlike [`TaskClassif`](https://mlr3.mlr-org.com/reference/TaskClassif.html) and [`TaskRegr`](https://mlr3.mlr-org.com/reference/TaskRegr.html) which have a single 'target' argument, [`TaskSurv`](https://mlr3proba.mlr-org.com/reference/TaskSurv.html) mimics the\n[`survival::Surv`](https://www.rdocumentation.org/packages/survival/topics/Surv) object and has three to four target arguments (dependent on censoring type).\nA [`TaskSurv`](https://mlr3proba.mlr-org.com/reference/TaskSurv.html) can be constructed with the function [`as_task_surv()`](https://mlr3proba.mlr-org.com/reference/as_task_surv.html):\n\n\n::: {.cell hash='special_cache/html/special-002_e8333707b282e13dfc0c5e3945376721'}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\nlibrary(\"mlr3proba\")\nlibrary(\"survival\")\n\nas_task_surv(survival::bladder2[, -1L], id = \"interval_censored\",\n  time = \"start\", event = \"event\", time2 = \"stop\", type = \"interval\")\n\n# type = \"right\" is default\ntask = as_task_surv(survival::rats, id = \"right_censored\",\n  time = \"time\", event = \"status\", type = \"right\")\n\nprint(task)\n\n# the target column is a survival object:\nhead(task$truth())\n\n# kaplan-meier plot\n# library(\"mlr3viz\")\nautoplot(task)\n```\n:::\n\n\n### Predict Types - crank, lp, and distr\n\nEvery [`PredictionSurv`](https://mlr3proba.mlr-org.com/reference/PredictionSurv.html) object can predict one or more of:\n\n* `lp` - Linear predictor calculated as the fitted coefficients multiplied by the test data.\n* `distr` - Predicted survival distribution, either discrete or continuous.\n  Implemented in [distr6](https://cran.r-project.org/package=distr6).\n* `crank` - Continuous risk ranking.\n* `response` - Predicted survival time.\n\n`lp` and `crank` can be used with measures of discrimination such as the concordance index.\nWhilst `lp` is a specific mathematical prediction, `crank` is any continuous ranking that identifies who is more or less likely to experience the event.\nSo far the only implemented learner that only returns a continuous ranking is `surv.svm`.\nIf a [`PredictionSurv`](https://mlr3proba.mlr-org.com/reference/PredictionSurv.html) returns an `lp` then the `crank` is identical to this.\nOtherwise `crank` is calculated as the expectation of the predicted survival distribution.\nNote that for linear proportional hazards models, the ranking (but not necessarily the `crank` score itself) given by `lp` and the expectation of `distr`, is identical.\n\nThe example below uses the [`rats`](https://mlr3proba.mlr-org.com/reference/mlr_tasks_rats.html) task shipped with [mlr3proba](https://mlr3proba.mlr-org.com).\n\n\n::: {.cell hash='special_cache/html/special-003_9202c017f7f512b31731cb168446152b'}\n\n```{.r .cell-code}\ntask = tsk(\"rats\")\nlearn = lrn(\"surv.coxph\")\n\ntrain_set = sample(task$nrow, 0.8 * task$nrow)\ntest_set = setdiff(seq_len(task$nrow), train_set)\n\nlearn$train(task, row_ids = train_set)\nprediction = learn$predict(task, row_ids = test_set)\n\nprint(prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionSurv> for 60 observations:\n    row_ids time status      crank         lp     distr\n          2   49   TRUE -0.5038971 -0.5038971 <list[1]>\n          3  104  FALSE -0.5038971 -0.5038971 <list[1]>\n         12  102  FALSE -3.4446695 -3.4446695 <list[1]>\n---                                                    \n        281   89  FALSE -2.5217340 -2.5217340 <list[1]>\n        295  104  FALSE  1.3955682  1.3955682 <list[1]>\n        300  102  FALSE -2.4602050 -2.4602050 <list[1]>\n```\n:::\n:::\n\n\n### Composition\n\nFinally we take a look at the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s implemented in [mlr3proba](https://mlr3proba.mlr-org.com), which are used for composition of predict types.\nFor example, a predict linear predictor does not have a lot of meaning by itself, but it can be composed into a survival distribution.\nSee [mlr3pipelines](https://mlr3pipelines.mlr-org.com) for full tutorials and details on [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\n\n\n::: {.cell hash='special_cache/html/special-004_fd8a95902774d21e14d2042b48ad9be3'}\n\n```{.r .cell-code}\nlibrary(\"mlr3pipelines\")\nlibrary(\"mlr3learners\")\n# PipeOpDistrCompositor - Train one model with a baseline distribution,\n# (Kaplan-Meier or Nelson-Aalen), and another with a predicted linear predictor.\ntask = tsk(\"rats\")\n# remove the factor column for support with glmnet\ntask$select(c(\"litter\", \"rx\"))\nlearner_lp = lrn(\"surv.glmnet\")\nlearner_distr = lrn(\"surv.kaplan\")\nprediction_lp = learner_lp$train(task)$predict(task)\nprediction_distr = learner_distr$train(task)$predict(task)\nprediction_lp$distr\n\n# Doesn't need training. Base = baseline distribution. ph = Proportional hazards.\n\npod = po(\"compose_distr\", form = \"ph\", overwrite = FALSE)\nprediction = pod$predict(list(base = prediction_distr, pred = prediction_lp))$output\n\n# Now we have a predicted distr!\n\nprediction$distr\n\n# This can all be simplified by using the distrcompose pipeline\n\nglm.distr = ppl(\"distrcompositor\", learner = lrn(\"surv.glmnet\"),\n  estimator = \"kaplan\", form = \"ph\", overwrite = FALSE, graph_learner = TRUE)\nglm.distr$train(task)$predict(task)\n```\n:::\n\n\n### Benchmark Experiment\n\nFinally, we conduct a small benchmark study on the [`rats`](https://mlr3proba.mlr-org.com/reference/mlr_tasks_rats.html) task using some of the integrated survival learners:\n\n\n::: {.cell hash='special_cache/html/special-005_230ea7b74fc65bbfe370d9c1553e8d54'}\n\n```{.r .cell-code}\nlibrary(\"mlr3learners\")\n\ntask = tsk(\"rats\")\n\n# some integrated learners\nlearners = lrns(c(\"surv.coxph\", \"surv.kaplan\", \"surv.ranger\"))\nprint(learners)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n<LearnerSurvCoxPH:surv.coxph>: Cox Proportional Hazards\n* Model: -\n* Parameters: list()\n* Packages: mlr3, mlr3proba, survival, distr6\n* Predict Types:  crank, [distr], lp\n* Feature Types: logical, integer, numeric, factor\n* Properties: weights\n\n[[2]]\n<LearnerSurvKaplan:surv.kaplan>: Kaplan-Meier Estimator\n* Model: -\n* Parameters: list()\n* Packages: mlr3, mlr3proba, survival, distr6\n* Predict Types:  [crank], distr\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: missings\n\n[[3]]\n<LearnerSurvRanger:surv.ranger>: Random Forest\n* Model: -\n* Parameters: num.threads=1\n* Packages: mlr3, mlr3proba, mlr3extralearners, ranger\n* Predict Types:  crank, [distr]\n* Feature Types: logical, integer, numeric, character, factor, ordered\n* Properties: importance, oob_error, weights\n```\n:::\n\n```{.r .cell-code}\n# Harrell's C-Index for survival\nmeasure = msr(\"surv.cindex\")\nprint(measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureSurvCindex:surv.cindex>\n* Packages: mlr3, mlr3proba\n* Range: [0, 1]\n* Minimize: FALSE\n* Average: macro\n* Parameters: weight_meth=I, tiex=0.5\n* Properties: -\n* Predict type: crank\n* Return type: Score\n```\n:::\n\n```{.r .cell-code}\nset.seed(1)\nbmr = benchmark(benchmark_grid(task, learners, rsmp(\"cv\", folds = 3)))\nbmr$aggregate(measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr      resample_result task_id  learner_id resampling_id iters surv.cindex\n1:  1 <ResampleResult[21]>    rats  surv.coxph            cv     3   0.7671307\n2:  2 <ResampleResult[21]>    rats surv.kaplan            cv     3   0.5000000\n3:  3 <ResampleResult[21]>    rats surv.ranger            cv     3   0.7827599\n```\n:::\n\n```{.r .cell-code}\nautoplot(bmr, measure = measure)\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-005-1.png){width=672}\n:::\n:::\n\n\nThe experiment indicates that both the Cox PH and the random forest have better discrimination than the Kaplan-Meier baseline estimator, but that the machine learning random forest is not consistently better than the interpretable Cox PH.\n\n## Density Estimation {#density}\n\n\n\n\n\n:::{.callout-warning}\nSurvival analysis with {mlr3proba} is currently in a fragile state after its removal from CRAN.\nHence most code examples listed in this page will not work for the time being.\nWe are actively working on a solution!\n:::\n\nDensity estimation is the learning task to find the unknown distribution from which an i.i.d. data set is generated.\nWe interpret this broadly, with this distribution not necessarily being continuous (so may possess a mass not density).\nThe conditional case, where a distribution is predicted conditional on covariates, is known as ‘probabilistic supervised regression’, and will be implemented in [mlr3proba](https://mlr3proba.mlr-org.com) in the near-future.\nUnconditional density estimation is viewed as an unsupervised task.\nFor a good overview to density estimation see *Density estimation for statistics and data analysis* [@Silverman1986].\n\nThe package [mlr3proba](https://mlr3proba.mlr-org.com) extends [mlr3](https://mlr3.mlr-org.com) with the following objects for density estimation:\n\n* [`TaskDens`](https://mlr3proba.mlr-org.com/reference/TaskDens.html) to define density tasks\n* [`LearnerDens`](https://mlr3proba.mlr-org.com/reference/LearnerDens.html) as base class for density estimators\n* [`PredictionDens`](https://mlr3proba.mlr-org.com/reference/PredictionDens.html) as specialized class for [`Prediction`](https://mlr3.mlr-org.com/reference/Prediction.html) objects\n* [`MeasureDens`](https://mlr3proba.mlr-org.com/reference/MeasureDens.html) as specialized class for performance measures\n\nIn this example we demonstrate the basic functionality of the package on the [`faithful`](https://www.rdocumentation.org/packages/datasets/topics/faithful) data from the datasets package.\nThis task ships as pre-defined [`TaskDens`](https://mlr3proba.mlr-org.com/reference/TaskDens.html) with [mlr3proba](https://mlr3proba.mlr-org.com).\n\n\n::: {.cell hash='special_cache/html/special-007_aabc573479af00c99051a3e1cf039220'}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\nlibrary(\"mlr3proba\")\n\ntask = tsk(\"precip\")\nprint(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskDens:precip> (70 x 1): Annual Precipitation\n* Target: -\n* Properties: -\n* Features (1):\n  - dbl (1): precip\n```\n:::\n\n```{.r .cell-code}\n# histogram and density plot\nlibrary(\"mlr3viz\")\n# FIXME\n# autoplot(task, type = \"overlay\")\n```\n:::\n\n\nUnconditional density estimation is an unsupervised method.\nHence, [`TaskDens`](https://mlr3proba.mlr-org.com/reference/TaskDens.html) is an unsupervised task which inherits directly from [`Task`](https://mlr3.mlr-org.com/reference/Task.html) unlike [`TaskClassif`](https://mlr3.mlr-org.com/reference/TaskClassif.html) and [`TaskRegr`](https://mlr3.mlr-org.com/reference/TaskRegr.html).\nHowever, [`TaskDens`](https://mlr3proba.mlr-org.com/reference/TaskDens.html) still has a `target` argument and a `$truth` field defined by:\n\n  * `target` - the name of the variable in the data for which to estimate density\n  * `$truth` - the values of the `target` column (which is *not* the true density, which is always unknown)\n\n### Train and Predict\n\nDensity learners have `train` and `predict` methods, though being unsupervised, 'prediction' is actually 'estimation'.\nIn training, a [distr6](https://cran.r-project.org/package=distr6) object is created,\n[see here](https://alan-turing-institute.github.io/distr6/) for full tutorials on how to access the probability density function, `pdf`, cumulative distribution function, `cdf`, and other important fields and methods.\nThe predict method is simply a wrapper around `self$model$pdf` and if available `self$model$cdf`, i.e. evaluates the pdf/cdf at given points.\nNote that in prediction the points to evaluate the pdf and cdf are determined by the `target` column in the [`TaskDens`](https://mlr3proba.mlr-org.com/reference/TaskDens.html) object used for testing.\n\n\n::: {.cell hash='special_cache/html/special-008_55f89bf78169c0823a50146e05f3da37'}\n\n```{.r .cell-code}\n# create task and learner\n\ntask_faithful = TaskDens$new(id = \"eruptions\", backend = datasets::faithful$eruptions)\nlearner = lrn(\"dens.hist\")\n\n# train/test split\ntrain_set = sample(task_faithful$nrow, 0.8 * task_faithful$nrow)\ntest_set = setdiff(seq_len(task_faithful$nrow), train_set)\n\n# fitting KDE and model inspection\nlearner$train(task_faithful, row_ids = train_set)\nlearner$model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$distr\nHistogram() \n\n$hist\n$breaks\n[1] 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5\n\n$counts\n[1] 39 30  5  4 25 62 49  3\n\n$density\n[1] 0.35944700 0.27649770 0.04608295 0.03686636 0.23041475 0.57142857 0.45161290\n[8] 0.02764977\n\n$mids\n[1] 1.75 2.25 2.75 3.25 3.75 4.25 4.75 5.25\n\n$xname\n[1] \"dat\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\nattr(,\"class\")\n[1] \"dens.hist\"\n```\n:::\n\n```{.r .cell-code}\nclass(learner$model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"dens.hist\"\n```\n:::\n\n```{.r .cell-code}\n# make predictions for new data\nprediction = learner$predict(task_faithful, row_ids = test_set)\n```\n:::\n\n\nEvery [`PredictionDens`](https://mlr3proba.mlr-org.com/reference/PredictionDens.html) object can estimate:\n\n  * `pdf` - probability density function\n\nSome learners can estimate:\n\n  * `cdf` - cumulative distribution function\n\n### Benchmark Experiment\n\nFinally, we conduct a small benchmark study on the [`precip`](https://mlr3proba.mlr-org.com/reference/mlr_tasks_precip.html) task using some of the integrated survival learners:\n\n\n::: {.cell hash='special_cache/html/special-009_158f6ad72e5d52e39f7ec2414dcfeca5'}\n\n```{.r .cell-code}\n# some integrated learners\nlearners = lrns(c(\"dens.hist\", \"dens.kde\"))\nprint(learners)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n<LearnerDensHistogram:dens.hist>: Histogram Density Estimator\n* Model: -\n* Parameters: list()\n* Packages: mlr3, mlr3proba, distr6\n* Predict Types:  [pdf], cdf, distr\n* Feature Types: integer, numeric\n* Properties: -\n\n[[2]]\n<LearnerDensKDE:dens.kde>: Kernel Density Estimator\n* Model: -\n* Parameters: kernel=Epan, bandwidth=silver\n* Packages: mlr3, mlr3proba, distr6\n* Predict Types:  [pdf], distr\n* Feature Types: integer, numeric\n* Properties: missings\n```\n:::\n\n```{.r .cell-code}\n# Logloss for probabilistic predictions\nmeasure = msr(\"dens.logloss\")\nprint(measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureDensLogloss:dens.logloss>: Log Loss\n* Packages: mlr3, mlr3proba\n* Range: [0, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: eps=1e-15\n* Properties: -\n* Predict type: pdf\n```\n:::\n\n```{.r .cell-code}\nset.seed(1)\nbmr = benchmark(benchmark_grid(task, learners, rsmp(\"cv\", folds = 3)))\nbmr$aggregate(measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr      resample_result task_id learner_id resampling_id iters dens.logloss\n1:  1 <ResampleResult[21]>  precip  dens.hist            cv     3     4.396138\n2:  2 <ResampleResult[21]>  precip   dens.kde            cv     3     4.817715\n```\n:::\n\n```{.r .cell-code}\nautoplot(bmr, measure = measure)\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-009-1.png){width=672}\n:::\n:::\n\n\nThe results of this experiment show that the sophisticated Penalized Density Estimator does not outperform the baseline histogram, but that the Kernel Density Estimator has at least consistently better (i.e. lower logloss) results.\n\n## Spatiotemporal Analysis {#spatiotemporal}\n\nAuthor: [Patrick Schratz](https://pat-s.me)\n\n\n\n\n\nData observations may entail reference information about spatial or temporal characteristics.\nSpatial information is stored as coordinates, usually named \"x\" and \"y\" or \"lat\"/\"lon\".\nTreating spatiotemporal data using non-spatial data methods can lead to over-optimistic performance estimates.\nHence, methods specifically designed to account for the special nature of spatiotemporal data are needed.\n\nIn the [mlr3](https://cran.r-project.org/package=mlr3) framework, the following packages relate to this field:\n\n- [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) (biased-reduced performance estimation)\n- [mlr3temporal](https://github.com/mlr-org/mlr3temporal) (time-series support)\n- [mlr3spatial](https://github.com/mlr-org/mlr3spatial) (spatial prediction support)\n\nThe following (sub-)sections introduce the potential pitfalls of spatiotemporal data in machine learning and how to account for it.\nNote that not all functionality will be covered, and that some of the used packages are still in early lifecycles.\nIf you want to contribute to one of the packages mentioned above, please contact [Patrick Schratz](https://github.com/pat-s).\n\n### Creating a spatial Task {#spatial-task}\n\nTo make use of spatial resampling methods, a {mlr3} task that is aware of its spatial characteristic needs to be created.\nTwo `Task` child classes exist in {mlr3spatiotempcv} for this purpose:\n\n- `TaskClassifST`\n- `TaskRegrST`\n\nTo create one of these, you have multiple options:\n\n1. Use the constructor of the `Task` directly via `$new()` - this only works for data.table backends (!)\n1. Use the `as_task_*` converters (e.g. if your data is stored in an `sf` object)\n\nWe recommend the latter, as the `as_task_*` converters aim to make task construction easier, e.g., by creating the `DataBackend` (which is required to create a Task in {mlr3}) automatically and setting the `crs` and `coordinate_names` fields.\nLet's assume your (point) data is stored in with an `sf` object, which is a common scenario for spatial analysis in R.\n\n\n::: {.cell hash='special_cache/html/special-011_a28aeab5fdeb1305714e521967d8c320'}\n\n```{.r .cell-code}\n# create 'sf' object\ndata_sf = sf::st_as_sf(ecuador, coords = c(\"x\", \"y\"), crs = 32717)\n\n# create `TaskClassifST` from `sf` object\ntask = as_task_classif_st(data_sf, id = \"ecuador_task\", target = \"slides\", positive = \"TRUE\")\n```\n:::\n\n\nYou can also use a plain `data.frame`.\nIn this case, `crs` and `coordinate_names` need to be passed along explicitly as they cannot be inferred directly from the `sf` object:\n\n\n::: {.cell hash='special_cache/html/special-012_51a57956c2ab3842dc60c27d1032e9e1'}\n\n```{.r .cell-code}\ntask = as_task_classif_st(ecuador, id = \"ecuador_task\", target = \"slides\",\n  positive = \"TRUE\", coordinate_names = c(\"x\", \"y\"), crs = 32717)\n```\n:::\n\n\nThe `*ST` task family prints a subset of the coordinates by default:\n\n\n::: {.cell hash='special_cache/html/special-013_b16ad62e537a5e5b8c00cd4e72440f0e'}\n\n```{.r .cell-code}\nprint(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClassifST:ecuador_task> (751 x 11)\n* Target: slides\n* Properties: twoclass\n* Features (10):\n  - dbl (10): carea, cslope, dem, distdeforest, distroad,\n    distslidespast, hcurv, log.carea, slope, vcurv\n* Coordinates:\n            x       y\n  1: 712882.5 9560002\n  2: 715232.5 9559582\n  3: 715392.5 9560172\n  4: 715042.5 9559312\n  5: 715382.5 9560142\n ---                 \n747: 714472.5 9558482\n748: 713142.5 9560992\n749: 713322.5 9560562\n750: 715392.5 9557932\n751: 713802.5 9560862\n```\n:::\n:::\n\n\nAll `*ST` tasks can be treated as their super class equivalents `TaskClassif` or `TaskRegr` in subsequent {mlr3} modeling steps.\n\n### Autocorrelation {#autocorrelation}\n\nData which includes spatial or temporal information requires special treatment in machine learning (similar to [survival](#survival), [ordinal](#ordinal) and other task types listed in the [special tasks](#special-tasks) chapter).\nIn contrast to non-spatial/non-temporal data, observations inherit a natural grouping, either in space or time or in both space and time [@legendre1993].\nThis grouping causes observations to be autocorrelated, either in space (spatial autocorrelation (SAC)), time (temporal autocorrelation (TAC)) or both space and time (spatiotemporal autocorrelation (STAC)).\nFor simplicity, the acronym STAC is used as a generic term in the following chapter for all the different characteristics introduced above.\n\n*What effects does STAC have in statistical/machine learning?*\n\nThe overarching problem is that STAC violates the assumption that the observations in the train and test datasets are independent [@hastie2001].\nIf this assumption is violated, the reliability of the resulting performance estimates, for example retrieved via cross-validation, is decreased.\nThe magnitude of this decrease is linked to the magnitude of STAC in the dataset, which cannot be determined easily.\n\nOne approach to account for the existence of STAC is to use dedicated resampling methods.\n[mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) provides access to the most frequently used spatiotemporal resampling methods.\nThe following example showcases how a spatial dataset can be used to retrieve a bias-reduced performance estimate of a learner.\n\nThe following examples use the [`ecuador`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_tasks_ecuador.html) dataset created by [Jannes Muenchow](https://scholar.google.com/citations?user=Slq94Y4AAAAJ&hl=de&authuser=1&oi=ao).\nIt contains information on the occurrence of landslides (binary) in the Andes of Southern Ecuador.\nThe landslides were mapped from aerial photos taken in 2000.\nThe dataset is well suited to serve as an example because it it relatively small and of course due to the spatial nature of the observations.\nPlease refer to @muenchow2012 for a detailed description of the dataset.\n\nTo account for the spatial autocorrelation probably present in the landslide data, we will make use one of the most used spatial partitioning methods, a cluster-based k-means grouping [@brenning2012], ([`spcv_coords`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_spcv_coords.html) in [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal)).\nThis method performs a clustering in 2D space which contrasts with the commonly used random partitioning for non-spatial data.\nThe grouping has the effect that train and test data are more separated in space as they would be by conducting a random partitioning, thereby reducing the effect of STAC.\n\nBy contrast, when using the classical random partitioning approach with spatial data, train and test observations would be located side-by-side across the full study area (a visual example is provided further below).\nThis leads to a high similarity between train and test sets, resulting in \"better\" but biased performance estimates in every fold of a CV compared to the spatial CV approach.\nHowever, these low error rates are mainly caused due to the STAC in the observations and the lack of appropriate partitioning methods and not by the power of the fitted model.\n\n### Spatiotemporal Cross-Validation and Partitioning {#spatiotemp-cv}\n\nOne part of spatiotemporal machine learning is dealing with the spatiotemporal components of the data during performance estimation.\nPerformance is commonly estimated via cross-validation and [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) provides specialized resamplings methods for spatiotemporal data.\nThe following chapters showcases how these methods can be applied and how they differ compared to non-spatial resampling methods, e.g. random partitioning.\nIn addition, examples which show how resamplings with spatial information can be visualized using [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal).\n\nBesides performance estimation, prediction on spatiotemporal data is another challenging task.\nSee @sec-spatial-prediction for more information about how this topic is handled within the mlr3 framework.\n\n#### Spatial CV vs. Non-Spatial CV {#sp-vs-nsp-cv}\n\nIn the following a spatial and non-spatial CV will be applied to showcase the mentioned performance differences.\n\nThe performance of a simple classification tree (`\"classif.rpart\"`) is evaluated on a random partitioning ([`repeated_cv`](https://mlr3.mlr-org.com/reference/mlr_resamplings_repeated_cv.html)) with four folds and two repetitions.\nThe chosen evaluation measure is \"classification error\" (`\"classif.ce\"`).\n\nFor the spatial example, [`repeated_spcv_coords`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_repeated_spcv_coords.html) is chosen whereas [`repeated_cv`](https://mlr3.mlr-org.com/reference/mlr_resamplings_repeated_cv.html) represents the non-spatial example.\n\n:::{.callout-note}\nThe selection of [`repeated_spcv_coords`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_repeated_spcv_coords.html) in this example is arbitrary.\nFor your use case, you might want to use a different spatial partitioning method (but not necessarily!).\nHave a look at the [\"Getting Started\"](https://mlr3spatiotempcv.mlr-org.com/dev/articles/mlr3spatiotempcv.html#resampling-methods) vignette of [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) to see all available methods and choose one which **fits your data and its prediction purpose**.\n:::\n\n##### Non-Spatial CV {#nsp-cv}\n\nIn this example the [`ecuador`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_tasks_ecuador.html) example task is taken to estimate the performance of an `rpart` learner with fixed parameters on it.\n\n:::{.callout-warning}\nIn practice you usually might want to tune the hyperparameters of the learner in this case and apply a nested CV in which the inner loop is used for hyperparameter tuning.\n:::\n\n\n::: {.cell hash='special_cache/html/special-014_99e63d3b945f9063e49cc82066a53d3f'}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\nlibrary(\"mlr3spatiotempcv\")\nset.seed(42)\n\n# be less verbose\nlgr::get_logger(\"bbotk\")$set_threshold(\"warn\")\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n\ntask = tsk(\"ecuador\")\n\nlearner = lrn(\"classif.rpart\", maxdepth = 3, predict_type = \"prob\")\nresampling_nsp = rsmp(\"repeated_cv\", folds = 4, repeats = 2)\nrr_nsp = resample(\n  task = task, learner = learner,\n  resampling = resampling_nsp)\n\nrr_nsp$aggregate(measures = msr(\"classif.ce\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n 0.3388575 \n```\n:::\n:::\n\n\n##### Spatial CV {#sp-cv}\n\n\n::: {.cell hash='special_cache/html/special-015_7d497937178c30ad0687fd39ef178808'}\n\n```{.r .cell-code}\ntask = tsk(\"ecuador\")\n\nlearner = lrn(\"classif.rpart\", maxdepth = 3, predict_type = \"prob\")\nresampling_sp = rsmp(\"repeated_spcv_coords\", folds = 4, repeats = 2)\nrr_sp = resample(\n  task = task, learner = learner,\n  resampling = resampling_sp)\n\nrr_sp$aggregate(measures = msr(\"classif.ce\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n  0.412529 \n```\n:::\n:::\n\n\nHere, the performance of the classification tree learner is around 7 percentage points worse when using Spatial Cross-Validation (SpCV) compared to Non-Spatial Cross-Validation (NSpCV).\nThe resulting difference in performance is variable as it depends on the dataset, the magnitude of STAC and the learner itself.\nFor algorithms with a higher tendency of overfitting to the training set, the difference between the two methods will be larger.\n\nNow, what does it mean that the performance in the spatial case is worse?\nShould you ditch SpCV and keep using non-spatial partitioning?\nThe answer is **NO**.\nThe reason why the spatial partitioning scenario results in a lower predictive performance is because throughout the CV the model has been trained on data that is less similar than the test data compared against the non-spatial scenario.\nOr in other words: in the non-spatial scenario, train and test data are almost identical (due to spatial autocorrelation).\n\nThis means that the result from the SpCV setting is more close to the true predictive power of the model - whereas the result from non-spatial CV is overoptimistic and biased.\n\n:::{.callout-note}\nThe result of the SpCV setting is by no means the absolute truth - it is also biased, but (most often) less compared to the non-spatial setting.\n:::\n\n### Visualization of Spatiotemporal Partitions {#vis-spt-partitions}\n\nEvery partitioning method in [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) comes with S3 methods for `plot()` and `autoplot()` to visualize the created groups.\nIn a 2D space [ggplot2](https://cran.r-project.org/package=ggplot2) is used in the backgroudn while for spatiotemporal methods 3D visualizations via [plotly](https://cran.r-project.org/package=plotly) are created.\n\nThe following examples shows how the `resampling_sp` object from the previous example can be visualized.\nIn this case I want to look at the first four partitions of the first repetition.\nThe point size is adjusted via argument `size`.\nAfter the plot creation, additional `scale_*` calls are used to adjust the coordinate labels on the x and y axes, respectively.\n\n\n::: {.cell fig.asp='0.8' hash='special_cache/html/special-016_e0cbdc77e29b7e67612e15cc17ece137'}\n\n```{.r .cell-code}\nautoplot(resampling_sp, task, fold_id = c(1:4), size = 0.7) *\n  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *\n  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.02))\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-016-1.png){width=672}\n:::\n:::\n\n\n:::{.callout-warning}\nNote that setting the correct CRS for the given data is important which is done **during task creation**.\nSpatial offsets of up to multiple meters may occur if the wrong CRS is supplied initially.\n:::\n\nThis example used a built-in mlr3 task via [`tsk()`](https://mlr3.mlr-org.com/reference/mlr_sugar.html).\nIn practice however, one needs to create a spatiotemporal task via [`TaskClassifST`](https://mlr3spatiotempcv.mlr-org.com/reference/TaskClassifST.html)/[`TaskRegrST`](https://mlr3spatiotempcv.mlr-org.com/reference/TaskRegrST.html) and set the `crs` argument (unless a `sf` object is handed over).\n\n[mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) can also visualize non-spatial partitonings.\nThis helps to visually compare differences.\nLet's use the objects from the previous example again, this time `resampling_nsp`.\n\n\n::: {.cell fig.asp='0.8' hash='special_cache/html/special-017_9adae646231e91465b3707078ff49259'}\n\n```{.r .cell-code}\nautoplot(resampling_nsp, task, fold_id = c(1:4), size = 0.7) *\n  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *\n  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.02))\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-017-1.png){width=672}\n:::\n:::\n\n\nThe visualization show very well how close train and test observations are located next to each other.\n\n#### Spatial Block Visualization {#vis-spatial-block}\n\nThis examples showcases another SpCV method: [`spcv_block`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_spcv_block.html).\nThis method makes use of rectangular blocks to divide the study area into equally-sized parts.\n{mlr3spatiotempcv} has support for visualizing the created blocks and displaying their respective fold ID to get a better understanding how the final folds were composed out of the partitions.\nE.g. the \"Fold 1 Repetition 1\" plot shows that the test set is composed out of two \"blocks\" with the ID \"1\" in this case.\n\n:::{.callout-note}\nThe use of `range = 1000L` is arbitrary here and should not be copy-pasted into a real application.\n:::\n\n\n::: {.cell hash='special_cache/html/special-018_b1d657e2e5a067ac665517cc5153a54f'}\n\n```{.r .cell-code}\ntask = tsk(\"ecuador\")\nresampling = rsmp(\"spcv_block\", range = 1000L)\n\n# Visualize train/test splits of multiple folds\nautoplot(resampling, task, size = 0.7,\n  fold_id = c(1, 2), show_blocks = TRUE, show_labels = TRUE) *\n  ggplot2::scale_x_continuous(breaks = seq(-79.085, -79.055, 0.02))\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-018-1.png){width=672}\n:::\n:::\n\n\n#### Spatiotemporal Visualization {#vis-spatiotemp}\n\nWhen going spatiotemporal, two dimensions are not enough anymore.\nTo visualize space and time together, a 3D solution is needed.\n{mlr3spatiotempcv} makes use of [plotly](https://cran.r-project.org/package=plotly) for this purpose.\n\nThe following examples uses a modified version of the `cookfarm_mlr3` task for showcasing reasons.\nBy adjusting some levels, the individual partitions can be recognized very well.\n\n:::{.callout-warning}\nIn practice, you should not modify your data to achieve \"good looking\" visualizations as done in this example.\nThis is only done for (visual) demonstration purposes.\n:::\n\nIn the following we use the [`sptcv_cstf`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_sptcv_cstf.html) method after @meyer2018.\nOnly the temporal variable is used in this first example, denoted by setting the column role \"time\" to variable \"Date\".\nThis column role is then picked up by the resampling method.\nLast, `autoplot()` is called with an explicit definition of `plot3D = TRUE`.\nThis is because [`sptcv_cstf`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_sptcv_cstf.html) can also be visualized in 2D (which only makes sense if the \"space\" column role is used for partitioning).\n\nLast, `sample_fold_n` is used to take a stratified random sample from all partitions.\nThe call to [`plotly::layout()`](https://www.rdocumentation.org/packages/plotly/topics/layout) only adjusts the default viewing angle of the plot - in interactive visualizations, this is not needed and the viewing angle can be adjusted with the mouse.\n\n:::{.callout-warning}\nThis is done to reduce the final plot size and keep things small for demos like this one.\nWe don't recommend doing this in actual studies - unless you prominently communicate this alongside the resulting plot.\n:::\n\n\n::: {.cell hash='special_cache/html/special-019_74c8cf73b326da0632b0de73d56b5716'}\n\n```{.r .cell-code}\ndata = cookfarm_mlr3\nset.seed(42)\ndata$Date = sample(rep(c(\n  \"2020-01-01\", \"2020-02-01\", \"2020-03-01\", \"2020-04-01\",\n  \"2020-05-01\"), times = 1, each = 35768))\ntask_spt = as_task_regr_st(data,\n  id = \"cookfarm\", target = \"PHIHOX\",\n  coordinate_names = c(\"x\", \"y\"), coords_as_features = FALSE,\n  crs = 26911)\ntask_spt$set_col_roles(\"Date\", roles = \"time\")\n\nrsmp_cstf_time = rsmp(\"sptcv_cstf\", folds = 5)\n\nplot = autoplot(rsmp_cstf_time,\n  fold_id = 5, task = task_spt, plot3D = TRUE,\n  sample_fold_n = 3000L\n)\nplotly::layout(plot, scene = list(camera = list(eye = list(z = 0.58))))\n```\n:::\n\n\nIf both space and time are used for partitioning in [`sptcv_cstf`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_sptcv_cstf.html), the visualization becomes even more powerful as it allows to also show the observations which are omitted, i.e., not being used in either train and test sets for a specific fold.\n\n\n::: {.cell hash='special_cache/html/special-020_659bd70c7f7560459a01d5a1ae70854c'}\n\n```{.r .cell-code}\ntask_spt$set_col_roles(\"SOURCEID\", roles = \"space\")\ntask_spt$set_col_roles(\"Date\", roles = \"time\")\n\nrsmp_cstf_space_time = rsmp(\"sptcv_cstf\", folds = 5)\n\nplot = autoplot(rsmp_cstf_space_time,\n  fold_id = 4, task = task_spt, plot3D = TRUE,\n  show_omitted = TRUE, sample_fold_n = 3000L)\n\nplotly::layout(plot, scene = list(camera =\nlist(eye = list(z = 0.58, x = -1.4, y = 1.6))))\n```\n:::\n\n\nCombining multiple spatiotemporal plots with [`plotly::layout()`](https://www.rdocumentation.org/packages/plotly/topics/layout) is possible but somewhat cumbersome.\nFirst, a list of plots containing the individuals plots must be created.\nThese plots can then be passed to [`plotly::subplot()`](https://www.rdocumentation.org/packages/plotly/topics/subplot).\nThis return is then passed to [`plotly::layout()`](https://www.rdocumentation.org/packages/plotly/topics/layout).\n\n\n::: {.cell hash='special_cache/html/special-021_4c6ca89db27046edab7d850c53b97f96'}\n\n```{.r .cell-code}\npl = autoplot(rsmp_cstf_space_time, task = task_spt,\n  fold_id = c(1, 2, 3, 4), point_size = 3,\n  axis_label_fontsize = 10, plot3D = TRUE,\n  sample_fold_n = 3000L, show_omitted = TRUE\n)\n\n# Warnings can be ignored\npl_subplot = plotly::subplot(pl)\n\nplotly::layout(pl_subplot,\n  title = \"Individual Folds\",\n  scene = list(\n    domain = list(x = c(0, 0.5), y = c(0.5, 1)),\n    aspectmode = \"cube\",\n    camera = list(eye = list(z = 0.20, x = -1.4, y = 1.6))\n  ),\n  scene2 = list(\n    domain = list(x = c(0.5, 1), y = c(0.5, 1)),\n    aspectmode = \"cube\",\n    camera = list(eye = list(z = 0.1, x = -1.4, y = 1.6))\n  ),\n  scene3 = list(\n    domain = list(x = c(0, 0.5), y = c(0, 0.5)),\n    aspectmode = \"cube\",\n    camera = list(eye = list(z = 0.1, x = -1.4, y = 1.6))\n  ),\n  scene4 = list(\n    domain = list(x = c(0.5, 1), y = c(0, 0.5)),\n    aspectmode = \"cube\",\n    camera = list(eye = list(z = 0.58, x = -1.4, y = 1.6))\n  )\n)\n```\n:::\n\n\nUnfortunately, titles in subplots cannot be created dynamically. However, there is a manual workaround via annotations show in [this RPubs post](https://rpubs.com/bcd/subplot-titles).\n\n### Choosing a Resampling Method {#choose-spt-rsmp}\n\nWhile the example in this section made use of the [`spcv_coords`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_resamplings_spcv_coords.html) method, this should by no means infer that this method is the best or only method suitable for this task.\nEven though this method is quite popular, it was mainly chosen because of the clear visual grouping differences when being applied on the [`ecuador`](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_tasks_ecuador.html) task when compared to random partitioning.\n\nIn fact, most often multiple spatial partitioning methods can be used for a dataset.\nIt is recommended (required) that users familiarize themselves with each implemented method and decide which method to choose based on the specific characteristics of the dataset.\nFor almost all methods implemented in [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal), there is a scientific publication describing the strengths and weaknesses of the respective approach (either linked in the help file of [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) or its respective dependency packages).\n\n:::{.callout-tip}\nIn the example above, a cross-validation without hyperparameter tuning was shown.\nIf a nested CV is desired, it is recommended to use the same spatial partitioning method for the inner loop (= tuning level).\nSee @schratz2019 for more details and chapter 11 of [Geocomputation with R](https://geocompr.robinlovelace.net/spatial-cv.html) [@lovelace2019].\n:::\n\n:::{.callout-tip}\nA list of all implemented methods in [mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal) can be found in the [Getting Started](https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html#resampling-methods) vignette of the package.\n:::\n\nIf you want to learn even more about the field of spatial partitioning, STAC and the problems associated with it, the works of [Prof. Hanna Meyer](https://scholar.google.com/citations?user=9YibxW0AAAAJ&hl=en) and [Prof. Alexander Brenning](https://scholar.google.com/citations?hl=en&user=GD5bzTgAAAAJ) are very much recommended for further reference.\n\n### Spatial Prediction {#sec-spatial-prediction}\n\nSupport for spatial prediction with [terra](https://cran.r-project.org/package=terra), [raster](https://cran.r-project.org/package=raster), [stars](https://cran.r-project.org/package=stars) and [sf](https://cran.r-project.org/package=sf) objects is available via [mlr3spatial](https://github.com/mlr-org/mlr3spatial).\n\nMore information and usage examples are coming soon!\n\n## Ordinal Analysis {#ordinal}\n\nThis is work in progress.\nSee [mlr3ordinal](https://github.com/mlr-org/mlr3ordinal) for the current state of the implementation.\n\n## Functional Analysis {#functional}\n\nFunctional data is data containing an ordering on the dimensions.\nThis implies that functional data consists of curves varying over a continuum, such as time, frequency, or wavelength.\n\n### How to model functional data?\n\nThere are two ways to model functional data:\n\n* Modification of the learner, so that the learner is suitable for the functional data\n* Modification of the task, so that the task matches the standard- or classification-learner\n\nThe development has not started yet, we are looking for contributors.\nOpen an issue in [mlr3fda](https://github.com/mlr-org/mlr3fda) if you are interested!\n\n## Multilabel Classification {#multilabel}\n\nMultilabel classification deals with objects that can belong to more than one category at the same time.\n\nThe development has not started yet, we are looking for contributes.\nOpen an issue in [mlr3multioutput](https://github.com/mlr-org/mlr3multioutput) if you are interested!\n\n## Cost-Sensitive Classification {#cost-sens}\n\n\nIn regular classification the aim is to minimize the misclassification rate and thus all types of misclassification errors are deemed equally severe.\nA more general setting is cost-sensitive classification.\nCost sensitive classification does not assume that the costs caused by different kinds of errors are equal.\nThe objective of cost sensitive classification is to minimize the expected costs.\n\nImagine you are an analyst for a big credit institution.\nLet's also assume that a correct decision of the bank would result in 35% of the profit at the end of a specific period.\nA correct decision means that the bank predicts that a customer will pay their bills (hence would obtain a loan), and the customer indeed has good credit.\nOn the other hand, a wrong decision means that the bank predicts that the customer's credit is in good standing, but the opposite is true.\nThis would result in a loss of 100% of the given loan.\n\n|                           | Good Customer (truth)       | Bad Customer (truth)       |\n| :-----------------------: | :-------------------------: | :------------------------: |\n| Good Customer (predicted) | + 0.35                      | - 1.0                      |\n| Bad Customer (predicted)  | 0                           | 0                          |\n\n\nExpressed as costs (instead of profit), we can write down the cost-matrix as follows:\n\n\n::: {.cell hash='special_cache/html/special-022_c98cc97c0cfa17c15407d42527da249d'}\n\n```{.r .cell-code}\ncosts = matrix(c(-0.35, 0, 1, 0), nrow = 2)\ndimnames(costs) = list(response = c(\"good\", \"bad\"), truth = c(\"good\", \"bad\"))\nprint(costs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        truth\nresponse  good bad\n    good -0.35   1\n    bad   0.00   0\n```\n:::\n:::\n\n\nAn exemplary data set for such a problem is the [`German Credit`](https://mlr3.mlr-org.com/reference/mlr_tasks_german_credit.html) task:\n\n\n::: {.cell hash='special_cache/html/special-023_5b28d0288f9cbdccdd55330836186bb4'}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\ntask = tsk(\"german_credit\")\ntable(task$truth())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\ngood  bad \n 700  300 \n```\n:::\n:::\n\n\nThe data has 70% customers who are able to pay back their credit, and 30% bad customers who default on the debt.\nA manager, who doesn't have any model, could decide to give either everybody a credit or to give nobody a credit.\nThe resulting costs for the German credit data are:\n\n\n::: {.cell hash='special_cache/html/special-024_c3d53e5b9a734ec78decee25d641776e'}\n\n```{.r .cell-code}\n# nobody:\n(700 * costs[2, 1] + 300 * costs[2, 2]) / 1000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\n# everybody\n(700 * costs[1, 1] + 300 * costs[1, 2]) / 1000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.055\n```\n:::\n:::\n\n\nIf the average loan is $20,000, the credit institute would lose more than one million dollar if it would grant everybody a credit:\n\n\n::: {.cell hash='special_cache/html/special-025_8e2b19ffe986d3735c1fae084b29ed3a'}\n\n```{.r .cell-code}\n# average profit * average loan * number of customers\n0.055 * 20000 * 1000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1100000\n```\n:::\n:::\n\n\nOur goal is to find a model which minimizes the costs (and thereby maximizes the expected profit).\n\n### A First Model\n\nFor our first model, we choose an ordinary logistic regression (implemented in add-on package [mlr3learners](https://mlr3learners.mlr-org.com)).\nWe first create a classification task, then resample the model using a 10-fold cross validation and extract the resulting confusion matrix:\n\n\n::: {.cell hash='special_cache/html/special-026_a763cc3c7679f1007593d34974d75c98'}\n\n```{.r .cell-code}\nlibrary(\"mlr3learners\")\nlearner = lrn(\"classif.log_reg\")\nrr = resample(task, learner, rsmp(\"cv\"))\n\nconfusion = rr$prediction()$confusion\nprint(confusion)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        truth\nresponse good bad\n    good  608 154\n    bad    92 146\n```\n:::\n:::\n\n\nTo calculate the average costs like above, we can simply multiply the elements of the confusion matrix with the elements of the previously introduced cost matrix, and sum the values of the resulting matrix:\n\n\n::: {.cell hash='special_cache/html/special-027_2bf6bd769aea5bcf765d5217d150a310'}\n\n```{.r .cell-code}\navg_costs = sum(confusion * costs) / 1000\nprint(avg_costs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.0588\n```\n:::\n:::\n\n\nWith an average loan of \\$20,000, the logistic regression yields the following costs:\n\n\n::: {.cell hash='special_cache/html/special-028_608faea4dc204cdcdc3ef5e31dac5d2b'}\n\n```{.r .cell-code}\navg_costs * 20000 * 1000\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -1176000\n```\n:::\n:::\n\n\nInstead of losing over \\$1,000,000, the credit institute now can expect a profit of more than \\$1,000,000.\n\n### Cost-sensitive Measure\n\nOur natural next step would be to further improve the modeling step in order to maximize the profit.\nFor this purpose we first create a cost-sensitive classification measure which calculates the costs based on our cost matrix.\nThis allows us to conveniently quantify and compare modeling decisions.\nFortunately, there already is a predefined measure [`Measure`](https://mlr3.mlr-org.com/reference/Measure.html) for this purpose: [`MeasureClassifCosts`](https://mlr3.mlr-org.com/reference/mlr_measures_classif.costs.html):\n\n\n::: {.cell hash='special_cache/html/special-029_2ae97dd352e27b5f49947644eaf1387b'}\n\n```{.r .cell-code}\ncost_measure = msr(\"classif.costs\", costs = costs)\nprint(cost_measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<MeasureClassifCosts:classif.costs>: Cost-sensitive Classification\n* Packages: mlr3\n* Range: [-Inf, Inf]\n* Minimize: TRUE\n* Average: macro\n* Parameters: normalize=TRUE\n* Properties: requires_task\n* Predict type: response\n```\n:::\n:::\n\n\nIf we now call [`resample()`](https://mlr3.mlr-org.com/reference/resample.html) or [`benchmark()`](https://mlr3.mlr-org.com/reference/benchmark.html), the cost-sensitive measures will be evaluated.\nWe compare the logistic regression to a simple featureless learner and to a random forest from package [ranger](https://cran.r-project.org/package=ranger) :\n\n\n::: {.cell hash='special_cache/html/special-030_f902c593e6f4e84ff36dad8e668e9bf5'}\n\n```{.r .cell-code}\nlearners = list(\n  lrn(\"classif.log_reg\"),\n  lrn(\"classif.featureless\"),\n  lrn(\"classif.ranger\")\n)\ncv3 = rsmp(\"cv\", folds = 3)\nbmr = benchmark(benchmark_grid(task, learners, cv3))\nbmr$aggregate(cost_measure)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr      resample_result       task_id          learner_id resampling_id\n1:  1 <ResampleResult[21]> german_credit     classif.log_reg            cv\n2:  2 <ResampleResult[21]> german_credit classif.featureless            cv\n3:  3 <ResampleResult[21]> german_credit      classif.ranger            cv\n2 variables not shown: [iters, classif.costs]\n```\n:::\n:::\n\n\nAs expected, the featureless learner is performing comparably bad.\nThe logistic regression and the random forest work equally well.\n\n### Thresholding\n\nAlthough we now correctly evaluate the models in a cost-sensitive fashion, the models themselves are unaware of the classification costs.\nThey assume the same costs for both wrong classification decisions (false positives and false negatives).\nSome learners natively support cost-sensitive classification (e.g., XXX).\nHowever, we will concentrate on a more generic approach which works for all models which can predict probabilities for class labels: thresholding.\n\nMost learners can calculate the probability $p$ for the positive class.\nIf $p$ exceeds the threshold $0.5$, they predict the positive class, and the negative class otherwise.\n\nFor our binary classification case of the credit data, the we primarily want to minimize the errors where the model predicts \"good\", but truth is \"bad\" (i.e., the number of false positives) as this is the more expensive error.\nIf we now increase the threshold to values $> 0.5$, we reduce the number of false negatives.\nNote that we increase the number of false positives simultaneously, or, in other words, we are trading false positives for false negatives.\n\n\n::: {.cell hash='special_cache/html/special-031_5b4528d3df75f0fa1217584ba08da27c'}\n\n```{.r .cell-code}\n# fit models with probability prediction\nlearner = lrn(\"classif.log_reg\", predict_type = \"prob\")\nrr = resample(task, learner, rsmp(\"cv\"))\np = rr$prediction()\nprint(p)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionClassif> for 1000 observations:\n    row_ids truth response  prob.good  prob.bad\n          2   bad      bad 0.40126720 0.5987328\n         17  good     good 0.97406360 0.0259364\n         46  good     good 0.74870171 0.2512983\n---                                            \n        973   bad      bad 0.09917846 0.9008215\n        976  good     good 0.78358973 0.2164103\n        997  good     good 0.51492948 0.4850705\n```\n:::\n\n```{.r .cell-code}\n# helper function to try different threshold values interactively\nwith_threshold = function(p, th) {\n  p$set_threshold(th)\n  list(confusion = p$confusion, costs = p$score(measures = cost_measure, task = task))\n}\n\nwith_threshold(p, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$confusion\n        truth\nresponse good bad\n    good  598 152\n    bad   102 148\n\n$costs\nclassif.costs \n      -0.0573 \n```\n:::\n\n```{.r .cell-code}\nwith_threshold(p, 0.75)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$confusion\n        truth\nresponse good bad\n    good  462  75\n    bad   238 225\n\n$costs\nclassif.costs \n      -0.0867 \n```\n:::\n\n```{.r .cell-code}\nwith_threshold(p, 1.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$confusion\n        truth\nresponse good bad\n    good    0   0\n    bad   700 300\n\n$costs\nclassif.costs \n            0 \n```\n:::\n\n```{.r .cell-code}\n# TODO: include plot of threshold vs performance\n```\n:::\n\n\nInstead of manually trying different threshold values, one uses use [`optimize()`](https://www.rdocumentation.org/packages/stats/topics/optimize) to find a good threshold value w.r.t. our performance measure:\n\n\n::: {.cell hash='special_cache/html/special-032_685b71722cddfc450654061d4c7d0a1e'}\n\n```{.r .cell-code}\n# simple wrapper function which takes a threshold and returns the resulting model performance\n# this wrapper is passed to optimize() to find its minimum for thresholds in [0.5, 1]\nf = function(th) {\n  with_threshold(p, th)$costs\n}\nbest = optimize(f, c(0.5, 1))\nprint(best)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$minimum\n[1] 0.6905289\n\n$objective\nclassif.costs \n     -0.08925 \n```\n:::\n\n```{.r .cell-code}\n# optimized confusion matrix:\nwith_threshold(p, best$minimum)$confusion\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        truth\nresponse good bad\n    good  515  91\n    bad   185 209\n```\n:::\n:::\n\n\nNote that the function `\"optimize()\"` is intended for unimodal functions and therefore may converge to a local optimum here.\nSee below for better alternatives to find good threshold values.\n\n### Threshold Tuning\n\nBefore we start, we have load all required packages:\n\n\n::: {.cell hash='special_cache/html/special-033_9d8510fd3d52d88c688933f7ab8b352c'}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\nlibrary(\"mlr3pipelines\")\nlibrary(\"mlr3tuning\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: paradox\n```\n:::\n:::\n\n\n### Adjusting thresholds: Two strategies\n\nCurrently [mlr3pipelines](https://mlr3pipelines.mlr-org.com) offers two main strategies towards adjusting `classification thresholds`.\nWe can either expose the thresholds as a `hyperparameter` of the Learner by using [`PipeOpThreshold`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_threshold.html).\nThis allows us to tune the `thresholds` via an outside optimizer from [mlr3tuning](https://mlr3tuning.mlr-org.com).\n\nAlternatively, we can also use [`PipeOpTuneThreshold`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_tunethreshold.html) which automatically tunes the threshold after each learner is fit.\n\nIn this blog-post, we'll go through both strategies.\n\n### PipeOpThreshold\n\n[`PipeOpThreshold`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_threshold.html) can be put directly after a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html).\n\nA simple example would be:\n\n\n::: {.cell hash='special_cache/html/special-034_cc69dae0f9ca4b080e09198fe3605a2f'}\n\n```{.r .cell-code}\ngr = lrn(\"classif.rpart\", predict_type = \"prob\") %>>% po(\"threshold\")\nl = as_learner(gr)\n```\n:::\n\n\nNote, that `predict_type = \"prob\"` is required for `po(\"threshold\")` to have any effect.\n\nThe `thresholds` are now exposed as a `hyperparameter` of the [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) we created:\n\n\n::: {.cell hash='special_cache/html/special-035_0d21794c43fd4282b5334f0bcfbb46ba'}\n\n```{.r .cell-code}\nl$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ParamSetCollection>\n                              id    class lower upper nlevels        default\n 1:             classif.rpart.cp ParamDbl     0     1     Inf           0.01\n 2:     classif.rpart.keep_model ParamLgl    NA    NA       2          FALSE\n 3:     classif.rpart.maxcompete ParamInt     0   Inf     Inf              4\n 4:       classif.rpart.maxdepth ParamInt     1    30      30             30\n 5:   classif.rpart.maxsurrogate ParamInt     0   Inf     Inf              5\n 6:      classif.rpart.minbucket ParamInt     1   Inf     Inf <NoDefault[3]>\n 7:       classif.rpart.minsplit ParamInt     1   Inf     Inf             20\n 8: classif.rpart.surrogatestyle ParamInt     0     1       2              0\n 9:   classif.rpart.usesurrogate ParamInt     0     2       3              2\n10:           classif.rpart.xval ParamInt     0   Inf     Inf             10\n11:         threshold.thresholds ParamUty    NA    NA     Inf <NoDefault[3]>\n1 variable not shown: [value]\n```\n:::\n:::\n\n\nWe can now tune those thresholds from the outside as follows:\n\nBefore tuning, we have to define which hyperparameters we want to tune over.\nIn this example, we only tune over the `thresholds` parameter of the `threshold` pipeop.\nyou can easily imagine, that we can also jointly tune over additional hyperparameters, i.e. rpart's `cp` parameter.\n\nAs the [`Task`](https://mlr3.mlr-org.com/reference/Task.html) we aim to optimize for is a binary task, we can simply specify the threshold param:\n\n\n::: {.cell hash='special_cache/html/special-036_f3e5a254dc10d4e6d98cd411af0ca8ee'}\n\n```{.r .cell-code}\nlibrary(\"paradox\")\nps = ps(threshold.thresholds = p_dbl(lower = 0, upper = 1))\n```\n:::\n\n\nWe now create a [`AutoTuner`](https://mlr3tuning.mlr-org.com/reference/AutoTuner.html), which automatically tunes the supplied learner over the [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html) we supplied above.\n\n\n::: {.cell hash='special_cache/html/special-037_fbc61ee33e6612b32b4064ac40776819'}\n\n```{.r .cell-code}\nat = AutoTuner$new(\n  learner = l,\n  resampling = rsmp(\"cv\", folds = 3L),\n  measure = msr(\"classif.ce\"),\n  search_space = ps,\n  terminator = trm(\"evals\", n_evals = 5L),\n  tuner = tnr(\"random_search\")\n)\n\nat$train(tsk(\"german_credit\"))\n```\n:::\n\n\nInside the `trafo`, we simply collect all set params into a named vector via `map_dbl` and store it\nin the `threshold.thresholds` slot expected by the learner.\n\nAgain, we create a [`AutoTuner`](https://mlr3tuning.mlr-org.com/reference/AutoTuner.html), which automatically tunes the supplied learner over the [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html) we supplied above.\n\nOne drawback of this strategy is, that this requires us to fit a new model for each new threshold setting.\nWhile setting a threshold and computing performance is relatively cheap, fitting the learner is often\nmore computationally demanding.\nA better strategy is therefore often to optimize the thresholds separately after each model fit.\n\n### PipeOpTunethreshold\n\n[`PipeOpTuneThreshold`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_tunethreshold.html) on the other hand works together with [`PipeOpLearnerCV`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner_cv.html).\nIt directly optimizes the `cross-validated` predictions made by this [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html).\nThis is done in order to avoid over-fitting the threshold tuning.\n\nA simple example would be:\n\n\n::: {.cell hash='special_cache/html/special-038_fb76902f7c84fa16be636a87bff8368a'}\n\n```{.r .cell-code}\ngr = po(\"learner_cv\", lrn(\"classif.rpart\", predict_type = \"prob\")) %>>% po(\"tunethreshold\")\nl2 = as_learner(gr)\n```\n:::\n\n\nNote, that `predict_type` = \"prob\" is required for `po(\"tunethreshold\")` to work.\nAdditionally, note that this time no `threshold` parameter is exposed, it is automatically tuned internally.\n\n\n::: {.cell hash='special_cache/html/special-039_b8c22879de500c2641e61d55b91925b1'}\n\n```{.r .cell-code}\nl2$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ParamSetCollection>\n                                        id    class lower upper nlevels\n 1:        classif.rpart.resampling.method ParamFct    NA    NA       2\n 2:         classif.rpart.resampling.folds ParamInt     2   Inf     Inf\n 3: classif.rpart.resampling.keep_response ParamLgl    NA    NA       2\n 4:                       classif.rpart.cp ParamDbl     0     1     Inf\n 5:               classif.rpart.keep_model ParamLgl    NA    NA       2\n 6:               classif.rpart.maxcompete ParamInt     0   Inf     Inf\n 7:                 classif.rpart.maxdepth ParamInt     1    30      30\n 8:             classif.rpart.maxsurrogate ParamInt     0   Inf     Inf\n 9:                classif.rpart.minbucket ParamInt     1   Inf     Inf\n10:                 classif.rpart.minsplit ParamInt     1   Inf     Inf\n11:           classif.rpart.surrogatestyle ParamInt     0     1       2\n12:             classif.rpart.usesurrogate ParamInt     0     2       3\n13:                     classif.rpart.xval ParamInt     0   Inf     Inf\n14:           classif.rpart.affect_columns ParamUty    NA    NA     Inf\n15:                  tunethreshold.measure ParamUty    NA    NA     Inf\n16:                tunethreshold.optimizer ParamUty    NA    NA     Inf\n17:                tunethreshold.log_level ParamUty    NA    NA     Inf\n2 variables not shown: [default, value]\n```\n:::\n:::\n\n\nNote that we can set `rsmp(\"intask\")` as a resampling strategy for \"learner_cv\" in order to evaluate\npredictions on the \"training\" data.\nThis is generally not advised, as it might lead to over-fitting on the thresholds but can significantly reduce runtime.\n\nFor more information, see the post on Threshold Tuning on the [mlr3 gallery](https://mlr3gallery.mlr-org.com/).\n\n## Cluster Analysis {#cluster}\n\nCluster analysis is a type of unsupervised machine learning where the goal is to group data into clusters, where each cluster contains similar observations.\nThe similarity is based on specified metrics that are task and application dependent.\nCluster analysis is closely related to classification in a sense that each observation needs to be assigned to a cluster or a class.\nHowever, unlike classification problems where each observation is labeled, clustering works on data sets without true labels or class assignments.\n\nThe package [mlr3cluster](https://mlr3cluster.mlr-org.com) extends [mlr3](https://mlr3.mlr-org.com) with the following objects for cluster analysis:\n\n* [`TaskClust`](https://mlr3cluster.mlr-org.com/reference/TaskClust.html) to define clustering tasks\n* [`LearnerClust`](https://mlr3cluster.mlr-org.com/reference/LearnerClust.html) as base class for clustering learners\n* [`PredictionClust`](https://mlr3cluster.mlr-org.com/reference/PredictionClust.html) as specialized class for [`Prediction`](https://mlr3.mlr-org.com/reference/Prediction.html) objects\n* [`MeasureClust`](https://mlr3cluster.mlr-org.com/reference/MeasureClust.html) as specialized class for performance measures\n\nSince clustering is a type of unsupervised learning, `TaskClust` is slightly different from [`TaskRegr`](https://mlr3.mlr-org.com/reference/TaskRegr.html) and [`TaskClassif`](https://mlr3.mlr-org.com/reference/TaskClassif.html) objects.\nMore specifically:\n\n  * `truth()` function is missing because observations are not labeled.\n  * `target` field is empty and will return `character(0)` if accessed anyway.\n\nAdditionally, `LearnerClust` provides two extra fields that are absent from supervised learners:\n\n  * `assignments` returns cluster assignments for training data. It return `NULL` if accessed before training.\n  * `save_assignments` is a boolean field that controls whether or not to store training set assignments in a learner.\n\nFinally, `PredictionClust` contains additional two fields:\n\n  * `partition` stores cluster partitions.\n  * `prob` stores cluster probabilities for each observation.\n\n### Train and Predict\n\nClustering learners provide both `train` and `predict` methods.\nThe analysis typically consists of building clusters using all available data.\nTo be consistent with the rest of the library, we refer to this process as training.\n\nSome learners can assign new observations to existing groups with `predict`.\nHowever, prediction does not always make sense, as it is the case for hierarchical clustering.\nIn hierarchical clustering, the goal is to build a hierarchy of nested clusters by either splitting large clusters into smaller ones or merging smaller clusters into bigger ones.\nThe final result is a tree or dendrogram which can change if a new data point is added.\nFor consistency with the rest of the ecosystem, [mlr3cluster](https://mlr3cluster.mlr-org.com) offers `predict` method for hierarchical clusterers but it simply assigns all points to a specified number of clusters by cutting the resulting tree at a corresponding level.\nMoreover, some learners estimate the probability of each observation belonging to a given cluster.\n`predict_types` field gives a list of prediction types for each learner.\n\nAfter training, the `model` field stores a learner's model that looks different for each learner depending on the underlying library.\n`predict` returns a `PredictionClust` object that gives a simplified view of the learned model.\nIf the data given to the `predict` method is the same as the one on which the learner was trained, `predict` simply returns cluster assignments for the \"training\" observations.\nOn the other hand, if the test set contains new data, `predict` will estimate cluster assignments for that data set.\nSome learners do not support estimating cluster partitions on new data and will instead return assignments for training data and print a warning message.\n\nIn the following example, a [`$k$-means learner`](https://mlr3cluster.mlr-org.com/reference/mlr_learners_clust.kmeans.html) is applied on the [`US arrest data set`](https://mlr3cluster.mlr-org.com/reference/mlr_tasks_usarrests.html).\nThe class labels are predicted and the contribution of the task features to assignment of the respective class are visualized.\n\n\n::: {.cell hash='special_cache/html/special-040_725305c261656d1cce4fdab47bf53680'}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\nlibrary(\"mlr3cluster\")\nlibrary(\"mlr3viz\")\nset.seed(1L)\n\n# create an example task\ntask = tsk(\"usarrests\")\nprint(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<TaskClust:usarrests> (50 x 4): US Arrests\n* Target: -\n* Properties: -\n* Features (4):\n  - int (2): Assault, UrbanPop\n  - dbl (2): Murder, Rape\n```\n:::\n\n```{.r .cell-code}\nautoplot(task)\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-040-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# create a k-means learner\nlearner = lrn(\"clust.kmeans\")\n\n# assigning each observation to one of the two clusters (default in clust.kmeans)\nlearner$train(task)\nlearner$model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nK-means clustering with 2 clusters of sizes 21, 29\n\nCluster means:\n   Assault    Murder     Rape UrbanPop\n1 255.0000 11.857143 28.11429 67.61905\n2 109.7586  4.841379 16.24828 64.03448\n\nClustering vector:\n [1] 1 1 1 1 1 1 2 1 1 1 2 2 1 2 2 2 2 1 2 1 2 1 2 1 2 2 2 1 2 2 1 1 1 2 2 2 2 2\n[39] 2 1 2 1 1 2 2 2 2 2 2 2\n\nWithin cluster sum of squares by cluster:\n[1] 41636.73 54762.30\n (between_SS / total_SS =  72.9 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n```\n:::\n\n```{.r .cell-code}\n# make \"predictions\" for the same data\nprediction = learner$predict(task)\nautoplot(prediction, task)\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-040-2.png){width=672}\n:::\n:::\n\n\n### Measures\n\nThe difference between supervised and unsupervised learning is that there is no ground truth data in unsupervised learning.\nIn a supervised setting, such as classification, we would need to compare our predictions to true labels.\nSince clustering is an example of unsupervised learning, there are no true labels to which we can compare.\nHowever, we can still measure the quality of cluster assignments by quantifying how closely objects within the same cluster are related (cluster cohesion) as well as how distinct different clusters are from each other (cluster separation).\n\nTo assess the quality of clustering, there are a few built-in evaluation metrics available.\nOne of them is [`within sum of squares (WSS)`](https://mlr3cluster.mlr-org.com/reference/mlr_measures_clust.wss.html) which calculates the sum of squared differences between observations and centroids.\nWSS is useful because it quantifies cluster cohesion.\nThe range of this measure is $[0, \\infty)$ where a smaller value means that clusters are more compact.\n\nAnother measure is [`silhouette quality index`](https://mlr3cluster.mlr-org.com/reference/mlr_measures_clust.silhouette.html) that quantifies how well each point belongs to its assigned cluster versus neighboring cluster.\nSilhouette values are in $[-1, 1]$ range.\n\nPoints with silhouette closer to:\n\n   * 1 are well clustered\n   * 0 lie between two clusters\n   * -1 likely placed in the wrong cluster\n\nThe following is an example of conducting a benchmark experiment with various learners on [`iris data set`](https://mlr3.mlr-org.com/reference/mlr_tasks_iris.html) without target variable and assessing the quality of each learner with both within sum of squares and silhouette measures.\n\n\n::: {.cell hash='special_cache/html/special-041_e47d75ee4c290813f364385d21206545'}\n\n```{.r .cell-code}\ndesign = benchmark_grid(\n  tasks = TaskClust$new(\"iris\", iris[-5]),\n  learners = list(\n    lrn(\"clust.kmeans\", centers = 3L),\n    lrn(\"clust.pam\", k = 2L),\n    lrn(\"clust.cmeans\", centers = 3L)),\n  resamplings = rsmp(\"insample\"))\nprint(design)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              task                  learner               resampling\n1: <TaskClust[46]> <LearnerClustKMeans[38]> <ResamplingInsample[20]>\n2: <TaskClust[46]>    <LearnerClustPAM[38]> <ResamplingInsample[20]>\n3: <TaskClust[46]> <LearnerClustCMeans[38]> <ResamplingInsample[20]>\n```\n:::\n\n```{.r .cell-code}\n# execute benchmark\nbmr = benchmark(design)\n\n# define measure\nmeasures = list(msr(\"clust.wss\"), msr(\"clust.silhouette\"))\nbmr$aggregate(measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   nr      resample_result task_id   learner_id resampling_id iters clust.wss\n1:  1 <ResampleResult[21]>    iris clust.kmeans      insample     1  78.85144\n2:  2 <ResampleResult[21]>    iris    clust.pam      insample     1 153.32572\n3:  3 <ResampleResult[21]>    iris clust.cmeans      insample     1  79.02617\n1 variable not shown: [clust.silhouette]\n```\n:::\n:::\n\n\nThe experiment shows that using k-means algorithm with three centers produces a better within sum of squares score than any other learner considered. However, pam (partitioning around medoids) learner with two clusters performs the best when considering silhouette measure which takes into the account both cluster cohesion and separation.\n\n### Visualization\n\nCluster analysis in [mlr3](https://mlr3.mlr-org.com) is integrated with [mlr3viz](https://mlr3viz.mlr-org.com) which provides a number of useful plots. Some of those plots are shown below.\n\n\n::: {.cell hash='special_cache/html/special-042_5d18b1a282bc296049c4edb86b2cbdec'}\n\n```{.r .cell-code}\ntask = TaskClust$new(\"iris\", iris[-5])\nlearner = lrn(\"clust.kmeans\")\nlearner$train(task)\nprediction = learner$predict(task)\n\n# performing PCA on task and showing assignments\nautoplot(prediction, task, type = \"pca\")\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-042-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# same as above but with probability ellipse that assumes normal distribution\nautoplot(prediction, task, type = \"pca\", frame = TRUE, frame.type = \"norm\")\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-042-2.png){width=672}\n:::\n\n```{.r .cell-code}\ntask = tsk(\"usarrests\")\nlearner = lrn(\"clust.agnes\")\nlearner$train(task)\n\n# dendrogram for hierarchical clustering\nautoplot(learner)\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-042-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# advanced dendrogram options from `factoextra::fviz_dend`\nautoplot(learner,\n  k = learner$param_set$values$k, rect_fill = TRUE,\n  rect = TRUE)\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-042-4.png){width=672}\n:::\n:::\n\n\nSilhouette plots can help to visually assess the quality of the analysis and help choose a number of clusters for a given data set.\nThe red dotted line shows the mean silhouette value and each bar represents a data point.\nIf most points in each cluster have an index around or higher than mean silhouette, the number of clusters is chosen well.\n\n\n::: {.cell hash='special_cache/html/special-043_a53fb58dcd6edae13319c1add9768111'}\n\n```{.r .cell-code}\n# silhouette plot allows to visually inspect the quality of clustering\ntask = TaskClust$new(\"iris\", iris[-5])\nlearner = lrn(\"clust.kmeans\")\nlearner$param_set$values = list(centers = 5L)\nlearner$train(task)\nprediction = learner$predict(task)\nautoplot(prediction, task, type = \"sil\")\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-043-1.png){width=672}\n:::\n:::\n\n\nThe plot shows that all points in cluster 5 and almost all points in clusters 4, 2 and 1 are below average silhouette index.\nThis means that a lot of observations lie either on the border of clusters or are likely assigned to the wrong cluster.\n\n\n::: {.cell hash='special_cache/html/special-044_cc6d0eb7d39c64b9d58bdcba86ec83a4'}\n\n```{.r .cell-code}\nlearner = lrn(\"clust.kmeans\")\nlearner$param_set$values = list(centers = 2L)\nlearner$train(task)\nprediction = learner$predict(task)\nautoplot(prediction, task, type = \"sil\")\n```\n\n::: {.cell-output-display}\n![](special_files/figure-html/special-044-1.png){width=672}\n:::\n:::\n\n\nSetting the number of centers to two improves both average silhouette score as well as overall quality of clustering because almost all points in cluster 1 are higher than and a lot of points in cluster 2 are close to mean silhouette.\nHence, having two centers might be a better choice for the number of clusters.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}