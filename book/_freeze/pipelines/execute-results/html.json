{
  "hash": "69f411df144cc56610cd4587624d7170",
  "result": {
    "markdown": "# Pipelines {#pipelines}\n\n::: {.cell}\n\n:::\n\n\n\n\n\n[mlr3pipelines](https://mlr3pipelines.mlr-org.com) [@mlr3pipelines] is a dataflow programming toolkit.\nThis chapter focuses on the applicant's side of the package.\nA more in-depth and technically oriented guide can be found in the [In-depth look into mlr3pipelines](#in-depth-pipelines) chapter.\n\nMachine learning workflows can be written as directed “Graphs”/\"Pipelines\" that represent data flows between preprocessing, model fitting, and ensemble learning units in an expressive and intuitive language.\nWe will most often use the term \"Graph\" in this manual but it can interchangeably be used  with \"pipeline\" or \"workflow\".\n\nBelow you can examine an example for such a graph:\n\n\n::: {.cell layout-align=\"center\" hash='pipelines_cache/html/pipelines-002_f90921e2efc7a3226077eb3f1220ac18'}\n::: {.cell-output-display}\n![](images/single_pipe.svg){fig-align='center' width=98%}\n:::\n:::\n\n\nSingle computational steps can be represented as so-called PipeOps, which can then be connected with directed edges in a Graph.\nThe scope of [mlr3pipelines](https://mlr3pipelines.mlr-org.com) is still growing.\nCurrently supported features are:\n\n* Data manipulation and preprocessing operations, e.g. PCA, feature filtering, imputation\n* Task subsampling for speed and outcome class imbalance handling\n* [mlr3](https://mlr3.mlr-org.com) Learner operations for prediction and stacking\n* Ensemble methods and aggregation of predictions\n\nAdditionally, we implement several meta operators that can be used to construct powerful pipelines:\n\n* Simultaneous path branching (data going both ways)\n* Alternative path branching (data going one specific way, controlled by hyperparameters)\n\nAn extensive introduction to creating custom **PipeOps** (PO's) can be found in the [technical introduction](#extending-pipeops).\n\nUsing methods from [mlr3tuning](https://mlr3tuning.mlr-org.com), it is even possible to simultaneously optimize parameters of multiple processing units.\n\nA predecessor to this package is the [mlrCPO](https://cran.r-project.org/package=mlrCPO) package, which works with [mlr](https://cran.r-project.org/package=mlr) 2.x.\nOther packages that provide, to varying degree, some preprocessing functionality or machine learning domain specific language, are:\n\n* the [caret](https://cran.r-project.org/package=caret) package and the related [recipes](https://cran.r-project.org/package=recipes)  project\n* the [dplyr](https://cran.r-project.org/package=dplyr) package\n\nAn example for a Pipeline that can be constructed using [mlr3pipelines](https://mlr3pipelines.mlr-org.com) is depicted below:\n\n\n::: {.cell width='10' height='10' hash='pipelines_cache/html/pipelines-003_c58bcdda67353bd2834a0a244c31c860'}\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-003-1.png){width=672}\n:::\n:::\n\n\n## The Building Blocks: PipeOps {#pipe-pipeops}\n\n\n\n\n\nThe building blocks of [mlr3pipelines](https://mlr3pipelines.mlr-org.com) are **PipeOp**-objects (PO).\nThey can be constructed directly using `PipeOp<NAME>$new()`, but the recommended way is to retrieve them from the [`mlr_pipeops`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops.html) dictionary:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-005_a9fc4786d222b0306c91e37c53c7390f'}\n\n```{.r .cell-code}\nlibrary(\"mlr3pipelines\")\nas.data.table(mlr_pipeops)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               key                    packages                           tags\n 1:         boxcox mlr3pipelines,bestNormalize                 data transform\n 2:         branch               mlr3pipelines                           meta\n 3:          chunk               mlr3pipelines                           meta\n 4: classbalancing               mlr3pipelines imbalanced data,data transform\n 5:     classifavg         mlr3pipelines,stats                       ensemble\n---                                                                          \n60:      threshold               mlr3pipelines               target transform\n61:  tunethreshold         mlr3pipelines,bbotk               target transform\n62:       unbranch               mlr3pipelines                           meta\n63:         vtreat        mlr3pipelines,vtreat encode,missings,data transform\n64:     yeojohnson mlr3pipelines,bestNormalize                 data transform\n7 variables not shown: [feature_types, input.num, output.num, input.type.train, input.type.predict, output.type.train, output.type.predict]\n```\n:::\n:::\n\n\nSingle POs can be created using the dictionary:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-006_d3dbcdac9035c522d56bd7cc627c4e7f'}\n\n```{.r .cell-code}\npca = mlr_pipeops$get(\"pca\")\n```\n:::\n\n\nor using **syntactic sugar** `po(<name>)`:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-007_a9e905e5f4dbbaf20cc28b0122f63b2d'}\n\n```{.r .cell-code}\npca = po(\"pca\")\n```\n:::\n\n\nSome POs require additional arguments for construction:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-008_cede7121e48029cbcc9c8f1f74d336bf'}\n\n```{.r .cell-code}\nlearner = po(\"learner\")\n\n# Error in as_learner(learner) : argument \"learner\" is missing, with no default argument \"learner\" is missing, with no default\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-009_c05436aed263e33652772907a4db35de'}\n\n```{.r .cell-code}\nlearner = mlr_pipeops$get(\"learner\", lrn(\"classif.rpart\"))\n```\n:::\n\n\nor in short `po(\"learner\", lrn(\"classif.rpart\"))`.\n\nHyperparameters of POs can be set through the `param_vals` argument.\nHere we set the fraction of features for a filter:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-010_4a25df042cd9579b71a9e697a3c0a276'}\n\n```{.r .cell-code}\nfilter = po(\"filter\",\n  filter = mlr3filters::flt(\"variance\"),\n  param_vals = list(filter.frac = 0.5))\n```\n:::\n\n\nor in short notation:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-011_3334527b696ddd810851ac3496583a83'}\n\n```{.r .cell-code}\npo(\"filter\", mlr3filters::flt(\"variance\"), filter.frac = 0.5)\n```\n:::\n\n\nThe figure below shows an exemplary [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html).\nIt takes an input, transforms it during `.$train` and `.$predict` and returns data:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-012_093dc2369561b93c5a5f194ae9ca8922'}\n::: {.cell-output-display}\n![](images/po_viz.png){width=464}\n:::\n:::\n\n\n## The Pipeline Operator: `%>>%` {#pipe-operator}\n\n\n\n\n\nIt is possible to create intricate `Graphs` with edges going all over the place (as long as no loops are introduced).\nIrrespective, there is usually a clear direction of flow between \"layers\" in the [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html).\nIt is therefore convenient to build up a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) from layers.\n\nThis can be done using the **`%>>%`** (\"double-arrow\") operator.\nIt takes either a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) or a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) on each of its sides and connects all of the outputs of its left-hand side to one of the inputs each of its right-hand side.\nThe number of inputs therefore must match the number of outputs.\n\n\n::: {.cell layout-align=\"center\" hash='pipelines_cache/html/pipelines-014_a47fbcdb80176276e5e2617e86c40d0c'}\n\n```{.r .cell-code}\nlibrary(\"magrittr\")\n\ngr = po(\"scale\") %>>% po(\"pca\")\ngr$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-014-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Nodes, Edges and Graphs {#pipe-nodes-edges-graphs}\n\n\n\n\n\nPOs are combined into [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)s.\n\nPOs are identified by their `$id`.\nNote that the operations all modify the object in-place and return the object itself.\nTherefore, multiple modifications can be chained.\n\nFor this example we use the `pca` PO defined above and a new PO named \"mutate\".\nThe latter creates a new feature from existing variables.\nAdditionally, we use the filter PO again.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-016_8b04732b25ecd237b56b07a580b68fec'}\n\n```{.r .cell-code}\nmutate = po(\"mutate\")\n\nfilter = po(\"filter\",\n  filter = mlr3filters::flt(\"variance\"),\n  param_vals = list(filter.frac = 0.5))\n```\n:::\n\nThe recommended way to construct a graph is to use the `%>>%` operator to chain POs or [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)s.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-017_ed2813e18ee4330bd759b30bc2bcd40c'}\n\n```{.r .cell-code}\ngraph = mutate %>>% filter\n```\n:::\n\n\nTo illustrate how this sugar operator works under the surface we will include an example of the manual way (= hard way) to construct a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html).\nThis is done by creating an empty graph first.\nThen one fills the empty graph with POs, and connects edges between the POs.\nConceptually, this may look like this:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-018_691e27fa9e931aee3d6f91f40ac13b03'}\n::: {.cell-output-display}\n![](images/po_nodes.svg)\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-019_1d7e9740e7a47eae2f73b32eb81a9f23'}\n\n```{.r .cell-code}\ngraph = Graph$new()$\n  add_pipeop(mutate)$\n  add_pipeop(filter)$\n  add_edge(\"mutate\", \"variance\") # add connection mutate -> filter\n```\n:::\n\n\nThe constructed [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)  can be inspected using its `$plot()` function:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-020_c9f2f9c0b6c5fc71fe5566d4b459604a'}\n\n```{.r .cell-code}\ngraph$plot()\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-020-1.png){width=672}\n:::\n:::\n\n\n**Chaining multiple POs of the same kind**\n\nIf multiple POs of the same kind should be chained, it is necessary to change the `id` to avoid name clashes.\nThis can be done by either accessing the `$id` slot or during construction:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-021_cd948f866b534c802d8a2dccd10dea30'}\n\n```{.r .cell-code}\ngraph$add_pipeop(po(\"pca\"))\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-022_c2d9f491685e8c5665882e7cd2dd0898'}\n\n```{.r .cell-code}\ngraph$add_pipeop(po(\"pca\", id = \"pca2\"))\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-023_6cc3738a4e775952e050e1afe52a7425'}\n\n```{.r .cell-code}\ngraph$plot()\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-023-1.png){width=672}\n:::\n:::\n\n\n## Modeling {#pipe-modeling}\n\n\n\n\n\nThe main purpose of a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) is to build combined preprocessing and model fitting pipelines that can be used as [mlr3](https://mlr3.mlr-org.com) [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html).\n\nConceptually, the process may be summarized as follows:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-025_483314ccdce5884551a181f6a3a764cc'}\n::: {.cell-output-display}\n![](images/pipe_action.svg)\n:::\n:::\n\n\nIn the following we chain two preprocessing tasks:\n\n* mutate (creation of a new feature)\n* filter (filtering the dataset)\n\nSubsequently one can chain a PO learner to train and predict on the modified dataset.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-026_0b8b281567b260d77a321b110d42036f'}\n\n```{.r .cell-code}\nmutate = po(\"mutate\")\nfilter = po(\"filter\",\n  filter = mlr3filters::flt(\"variance\"),\n  param_vals = list(filter.frac = 0.5))\n\ngraph = mutate %>>%\n  filter %>>%\n  po(\"learner\",\n    learner = lrn(\"classif.rpart\"))\n```\n:::\n\n\nUntil here we defined the main pipeline stored in [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html).\nNow we can train and predict the pipeline:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-027_e74557ea950653d94a6897183fafbca5'}\n\n```{.r .cell-code}\ntask = tsk(\"iris\")\ngraph$train(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$classif.rpart.output\nNULL\n```\n:::\n\n```{.r .cell-code}\ngraph$predict(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$classif.rpart.output\n<PredictionClassif> for 150 observations:\n    row_ids     truth  response\n          1    setosa    setosa\n          2    setosa    setosa\n          3    setosa    setosa\n---                            \n        148 virginica virginica\n        149 virginica virginica\n        150 virginica virginica\n```\n:::\n:::\n\n\nRather than calling `$train()` and `$predict()` manually, we can put the pipeline [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) into a [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) object.\nA [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) encapsulates the whole pipeline (including the preprocessing steps) and can be put into [`resample()`](https://mlr3.mlr-org.com/reference/resample.html) or [`benchmark()`](https://mlr3.mlr-org.com/reference/benchmark.html) .\nIf you are familiar with the old _mlr_ package, this is the equivalent of all the `make*Wrapper()` functions.\nThe pipeline being encapsulated (here [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)) must always produce a [`Prediction`](https://mlr3.mlr-org.com/reference/Prediction.html)  with its `$predict()` call, so it will probably contain at least one [`PipeOpLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner.html) .\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-028_f2b747758ed33aaeccd9b20ce68c60c4'}\n\n```{.r .cell-code}\nglrn = as_learner(graph)\n```\n:::\n\n\nThis learner can be used for model fitting, resampling, benchmarking, and tuning:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-029_d1645d9c8e6dcaefd35288c57191c8f5'}\n\n```{.r .cell-code}\ncv3 = rsmp(\"cv\", folds = 3)\nresample(task, glrn, cv3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ResampleResult> of 3 iterations\n* Task: iris\n* Learner: mutate.variance.classif.rpart\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n```\n:::\n:::\n\n\n### Setting Hyperparameters {#pipe-hyperpars}\n\nIndividual POs offer hyperparameters because they contain `$param_set` slots that can be read and written from `$param_set$values` (via the [paradox](https://paradox.mlr-org.com) package).\nThe parameters get passed down to the [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html), and finally to the [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) .\nThis makes it not only possible to easily change the behavior of a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)  / [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) and try different settings manually, but also to perform tuning using the [mlr3tuning](https://mlr3tuning.mlr-org.com) package.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-030_49d19c0119406e4be41d73d5020c4a48'}\n\n```{.r .cell-code}\nglrn$param_set$values$variance.filter.frac = 0.25\ncv3 = rsmp(\"cv\", folds = 3)\nresample(task, glrn, cv3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ResampleResult> of 3 iterations\n* Task: iris\n* Learner: mutate.variance.classif.rpart\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n```\n:::\n:::\n\n\n### Tuning {#pipe-tuning}\n\nIf you are unfamiliar with tuning in [mlr3](https://mlr3.mlr-org.com), we recommend to take a look at the section about [tuning](#tuning) first.\nHere we define a [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html) for the \"rpart\" learner and the \"variance\" filter which should be optimized during the tuning process.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-031_c35de0d1c653695627f71de11003aa30'}\n\n```{.r .cell-code}\nlibrary(\"paradox\")\nps = ps(\n  classif.rpart.cp = p_dbl(lower = 0, upper = 0.05),\n  variance.filter.frac = p_dbl(lower = 0.25, upper = 1)\n)\n```\n:::\n\n\nAfter having defined the [`Tuner`](https://mlr3tuning.mlr-org.com/reference/Tuner.html), a random search with 10 iterations is created.\nFor the inner resampling, we are simply using holdout (single split into train/test) to keep the runtimes reasonable.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-032_aec74db645babb16b825564f5348d059'}\n\n```{.r .cell-code}\nlibrary(\"mlr3tuning\")\ninstance = TuningInstanceSingleCrit$new(\n  task = task,\n  learner = glrn,\n  resampling = rsmp(\"holdout\"),\n  measure = msr(\"classif.ce\"),\n  search_space = ps,\n  terminator = trm(\"evals\", n_evals = 20)\n)\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-033_7a29ff08ecbfd631a9717baad782f7e3'}\n\n```{.r .cell-code}\ntuner = tnr(\"random_search\")\ntuner$optimize(instance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   classif.rpart.cp variance.filter.frac learner_param_vals  x_domain\n1:       0.04886918            0.6870548          <list[5]> <list[2]>\n1 variable not shown: [classif.ce]\n```\n:::\n:::\n\n\nThe tuning result can be found in the respective `result` slots.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-034_9dc15eb6c9a6db3b8c8a84dd11df599c'}\n\n```{.r .cell-code}\ninstance$result_learner_param_vals\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$mutate.mutation\nlist()\n\n$mutate.delete_originals\n[1] FALSE\n\n$variance.filter.frac\n[1] 0.6870548\n\n$classif.rpart.xval\n[1] 0\n\n$classif.rpart.cp\n[1] 0.04886918\n```\n:::\n\n```{.r .cell-code}\ninstance$result_y\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n      0.02 \n```\n:::\n:::\n\n\n## Non-Linear Graphs {#pipe-nonlinear}\n\n\n\n\n\nThe Graphs seen so far all have a linear structure.\nSome POs may have multiple input or output channels.\nThese channels make it possible to create non-linear Graphs with alternative paths taken by the data.\n\nPossible types are:\n\n- [Branching](#pipe-model-ensembles-branching-copying):\n  Splitting of a node into several paths, e.g. useful when comparing multiple feature-selection methods (pca, filters).\n  Only one path will be executed.\n- [Copying](#pipe-model-ensembles-branching-copying):\n  Splitting of a node into several paths, all paths will be executed (sequentially).\n  Parallel execution is not yet supported.\n- [Stacking](#pipe-model-ensembles-stacking):\n  Single graphs are stacked onto each other, i.e. the output of one [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) is the input for another.\n  In machine learning this means that the prediction of one [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) is used as input for another [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)\n\n### Branching & Copying {#pipe-model-ensembles-branching-copying}\n\nThe [`PipeOpBranch`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_branch.html) and [`PipeOpUnbranch`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_unbranch.html) POs make it possible to specify multiple alternative paths.\nOnly one path is actually executed, the others are ignored.\nThe active path is determined by a hyperparameter.\nThis concept makes it possible to tune alternative preprocessing paths (or learner models).\n\nBelow a conceptual visualization of branching:\n\n\n::: {.cell layout-align=\"center\" hash='pipelines_cache/html/pipelines-036_2a79b95c17d4aad83e127b05a99fe872'}\n::: {.cell-output-display}\n![](images/branching.svg){fig-align='center' width=98%}\n:::\n:::\n\n\n`PipeOp(Un)Branch` is initialized either with the number of branches, or with a `character`-vector indicating the names of the branches.\nIf names are given, the \"branch-choosing\" hyperparameter becomes more readable.\nIn the following, we set three options:\n\n1. Doing nothing (\"nop\")\n1. Applying a PCA\n1. Scaling the data\n\nIt is important to \"unbranch\" again after \"branching\", so that the outputs are merged into one result objects.\n\nIn the following we first create the branched graph and then show what happens if the \"unbranching\" is not applied:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-037_d4dd9cc4ba1379af04d8b8d3a5a583c1'}\n\n```{.r .cell-code}\ngraph = po(\"branch\", c(\"nop\", \"pca\", \"scale\")) %>>%\n  gunion(list(\n    po(\"nop\", id = \"null1\"),\n    po(\"pca\"),\n    po(\"scale\")\n  ))\n```\n:::\n\n\nWithout \"unbranching\" one creates the following graph:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-038_7f8022c4699161313ae1ac200ec2e8bd'}\n\n```{.r .cell-code}\ngraph$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-038-1.png){width=672}\n:::\n:::\n\n\nNow when \"unbranching\", we obtain the following results:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-039_015226f005cd127765c9c8eb16d97bf8'}\n\n```{.r .cell-code}\n(graph %>>% po(\"unbranch\", c(\"nop\", \"pca\", \"scale\")))$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-039-1.png){width=672}\n:::\n:::\n\n\nThe same can be achieved using a shorter notation:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-040_c5edb9e5a00b96744b00a52d9cbc0a70'}\n\n```{.r .cell-code}\n# List of pipeops\nopts = list(po(\"nop\", \"no_op\"), po(\"pca\"), po(\"scale\"))\n# List of po ids\nopt_ids = mlr3misc::map_chr(opts, `[[`, \"id\")\npo(\"branch\", options = opt_ids) %>>%\n  gunion(opts) %>>%\n  po(\"unbranch\", options = opt_ids)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGraph with 5 PipeOps:\n       ID         State        sccssors       prdcssors\n   branch <<UNTRAINED>> no_op,pca,scale                \n    no_op <<UNTRAINED>>        unbranch          branch\n      pca <<UNTRAINED>>        unbranch          branch\n    scale <<UNTRAINED>>        unbranch          branch\n unbranch <<UNTRAINED>>                 no_op,pca,scale\n```\n:::\n:::\n\n\n### Model Ensembles {#pipe-model-ensembles}\n\nWe can leverage the different operations presented to connect POs.\nThis allows us to form powerful graphs.\n\nBefore we go into details, we split the task into train and test indices.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-041_c1241ed603fb6cd2a38d0a816dddaaa5'}\n\n```{.r .cell-code}\ntask = tsk(\"iris\")\ntrain.idx = sample(seq_len(task$nrow), 120)\ntest.idx = setdiff(seq_len(task$nrow), train.idx)\n```\n:::\n\n\n#### Bagging {#pipe-model-ensembles-bagging}\n\nWe first examine Bagging introduced by [@Breiman1996].\nThe basic idea is to create multiple predictors and then aggregate those to a single, more powerful predictor.\n\n> \"... multiple versions are formed\n> by making bootstrap replicates of the learning set\n> and using these as new learning sets\" [@Breiman1996]\n\nBagging then aggregates a set of predictors by averaging (regression) or majority vote (classification).\nThe idea behind bagging is, that a set of weak, but different predictors can be combined in order to arrive at a single, better predictor.\n\nWe can achieve this by downsampling our data before training a learner, repeating this e.g. 10 times and then performing a majority vote on the predictions.\nGraphically, it may be summarized as follows:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-042_b28142934790ba29bf4c642b1afc6634'}\n::: {.cell-output-display}\n![](images/nonlinear_pipeops.svg)\n:::\n:::\n\n\nFirst, we create a simple pipeline, that uses [`PipeOpSubsample`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_subsample.html) before a [`PipeOpLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner.html) is trained:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-043_9fcfceea88877918300b03a356e47ac8'}\n\n```{.r .cell-code}\nsingle_pred = po(\"subsample\", frac = 0.7) %>>%\n  po(\"learner\", lrn(\"classif.rpart\"))\n```\n:::\n\n\nWe can now copy this operation 10 times using [`pipeline_greplicate`](https://mlr3pipelines.mlr-org.com/reference/mlr_graphs_greplicate.html).\nThe [`pipeline_greplicate`](https://mlr3pipelines.mlr-org.com/reference/mlr_graphs_greplicate.html) allows us to parallelize many copies of an operation by creating a Graph containing `n` copies of the input Graph.\nWe can also create it using  **syntactic sugar** via [`ppl()`](https://mlr3pipelines.mlr-org.com/reference/ppl.html):\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-044_e3ca7e95691dae85a2feae0100e8a0b4'}\n\n```{.r .cell-code}\npred_set = ppl(\"greplicate\", single_pred, 10L)\n```\n:::\n\n\nAfterwards we need to aggregate the 10 pipelines to form a single model:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-045_ed0bf89002b7b532bc53407ef2e4d352'}\n\n```{.r .cell-code}\nbagging = pred_set %>>%\n  po(\"classifavg\", innum = 10)\n```\n:::\n\n\nNow we can plot again to see what happens:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-046_e01a3296f9dde213719c8acca6cf49d3'}\n\n```{.r .cell-code}\nbagging$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-046-1.png){width=720}\n:::\n:::\n\n\nThis pipeline can again be used in conjunction with [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) in order for Bagging to be used like a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html):\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-047_ee27c476f61ae8f70afd55565b3ef683'}\n\n```{.r .cell-code}\nbaglrn = as_learner(bagging)\nbaglrn$train(task, train.idx)\nbaglrn$predict(task, test.idx)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionClassif> for 30 observations:\n    row_ids     truth prob.setosa prob.versicolor prob.virginica\n         16    setosa           1             0.0            0.0\n         18    setosa           1             0.0            0.0\n         21    setosa           1             0.0            0.0\n---                                                             \n        129 virginica           0             0.0            1.0\n        134 virginica           0             0.5            0.5\n        149 virginica           0             0.0            1.0\n```\n:::\n:::\n\n\nIn conjunction with different `Backends`, this can be a very powerful tool.\nIn cases when the data does not fully fit in memory, one can obtain a fraction of the data for each learner from a [`DataBackend`](https://mlr3.mlr-org.com/reference/DataBackend.html) and then aggregate predictions over all learners.\n\n#### Stacking {#pipe-model-ensembles-stacking}\n\nStacking [@Wolpert1992] is another technique that can improve model performance.\nThe basic idea behind stacking is the use of predictions from one model as features for a subsequent model to possibly improve performance.\n\nBelow an conceptual illustration of stacking:\n\n\n::: {.cell layout-align=\"center\" hash='pipelines_cache/html/pipelines-048_7af87cfc8083c2deaffa487dc6658910'}\n::: {.cell-output-display}\n![](images/stacking.svg){fig-align='center' width=98%}\n:::\n:::\n\n\nAs an example we can train a decision tree and use the predictions from this model in conjunction with the original features in order to train an additional model on top.\n\nTo limit overfitting, we additionally do not predict on the original predictions of the learner.\nInstead, we predict on out-of-bag predictions.\nTo do all this, we can use [`PipeOpLearnerCV`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner_cv.html) .\n\n[`PipeOpLearnerCV`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner_cv.html) performs nested cross-validation on the training data, fitting a model in each fold.\nEach of the models is then used to predict on the out-of-fold data.\nAs a result, we obtain predictions for every data point in our input data.\n\nWe first create a \"level 0\" learner, which is used to extract a lower level prediction.\nAdditionally, we `$clone()` the learner object to obtain a copy of the learner.\nSubsequently, one sets a custom id for the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) .\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-049_2e2e3ef812731792e4c84919a20cf7f2'}\n\n```{.r .cell-code}\nlrn = lrn(\"classif.rpart\")\nlrn_0 = po(\"learner_cv\", lrn$clone())\nlrn_0$id = \"rpart_cv\"\n```\n:::\n\n\nWe use [`PipeOpNOP`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_nop.html)  in combination with [`gunion`](https://mlr3pipelines.mlr-org.com/reference/gunion.html), in order to send the unchanged Task to the next level.\nThere it is combined with the predictions from our decision tree learner.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-050_181988b20ee4b33d63d2810c67d5accd'}\n\n```{.r .cell-code}\nlevel_0 = gunion(list(lrn_0, po(\"nop\")))\n```\n:::\n\n\nAfterwards, we want to concatenate the predictions from [`PipeOpLearnerCV`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner_cv.html) and the original Task using [`PipeOpFeatureUnion`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_featureunion.html) :\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-051_94b8a752160dc441a58646675175a95a'}\n\n```{.r .cell-code}\ncombined = level_0 %>>% po(\"featureunion\", 2)\n```\n:::\n\n\nNow we can train another learner on top of the combined features:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-052_e8f7d4baf0eeffc216fa421b14e0b4d2'}\n\n```{.r .cell-code}\nstack = combined %>>% po(\"learner\", lrn$clone())\nstack$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-052-1.png){width=720}\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-053_6737b24b98f9b673a141ad280f2731be'}\n\n```{.r .cell-code}\nstacklrn = as_learner(stack)\nstacklrn$train(task, train.idx)\nstacklrn$predict(task, test.idx)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<PredictionClassif> for 30 observations:\n    row_ids     truth   response\n         16    setosa     setosa\n         18    setosa     setosa\n         21    setosa     setosa\n---                             \n        129 virginica  virginica\n        134 virginica versicolor\n        149 virginica  virginica\n```\n:::\n:::\n\n\nIn this vignette, we showed a very simple use-case for stacking.\nIn many real-world applications, stacking is done for multiple levels and on multiple representations of the dataset.\nOn a lower level, different preprocessing methods can be defined in conjunction with several learners.\nOn a higher level, we can then combine those predictions in order to form a very powerful model.\n\n#### Multilevel Stacking\n\nIn order to showcase the power of [mlr3pipelines](https://mlr3pipelines.mlr-org.com), we will show a more complicated stacking example.\n\nIn this case, we train a [glmnet](https://cran.r-project.org/package=glmnet) and 2 different [rpart](https://cran.r-project.org/package=rpart) models (some transform its inputs using [`PipeOpPCA`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_pca.html)) on our task in the \"level 0\" and concatenate them with the original features (via [`gunion`](https://mlr3pipelines.mlr-org.com/reference/gunion.html)).\nThe result is then passed on to \"level 1\", where we copy the concatenated features 3 times and put this task into an [rpart](https://cran.r-project.org/package=rpart) and a [glmnet](https://cran.r-project.org/package=glmnet) model.\nAdditionally, we keep a version of the \"level 0\" output (via [`PipeOpNOP`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_nop.html)) and pass this on to \"level 2\".\nIn \"level 2\" we simply concatenate all \"level 1\" outputs and train a final decision tree.\n\nIn the following examples, use `<lrn>$param_set$values$<param_name> = <param_value>` to set hyperparameters for the different learner.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-054_4ec50d323666fb612c2deaaf3b564219'}\n\n```{.r .cell-code}\nlibrary(\"magrittr\")\nlibrary(\"mlr3learners\") # for classif.glmnet\n\nrprt = lrn(\"classif.rpart\", predict_type = \"prob\")\nglmn = lrn(\"classif.glmnet\", predict_type = \"prob\")\n\n#  Create Learner CV Operators\nlrn_0 = po(\"learner_cv\", rprt, id = \"rpart_cv_1\")\nlrn_0$param_set$values$maxdepth = 5L\nlrn_1 = po(\"pca\", id = \"pca1\") %>>% po(\"learner_cv\", rprt, id = \"rpart_cv_2\")\nlrn_1$param_set$values$rpart_cv_2.maxdepth = 1L\nlrn_2 = po(\"pca\", id = \"pca2\") %>>% po(\"learner_cv\", glmn)\n\n# Union them with a PipeOpNULL to keep original features\nlevel_0 = gunion(list(lrn_0, lrn_1, lrn_2, po(\"nop\", id = \"NOP1\")))\n\n# Cbind the output 3 times, train 2 learners but also keep level\n# 0 predictions\nlevel_1 = level_0 %>>%\n  po(\"featureunion\", 4) %>>%\n  po(\"copy\", 3) %>>%\n  gunion(list(\n    po(\"learner_cv\", rprt, id = \"rpart_cv_l1\"),\n    po(\"learner_cv\", glmn, id = \"glmnt_cv_l1\"),\n    po(\"nop\", id = \"NOP_l1\")\n  ))\n\n# Cbind predictions, train a final learner\nlevel_2 = level_1 %>>%\n  po(\"featureunion\", 3, id = \"u2\") %>>%\n  po(\"learner\", rprt, id = \"rpart_l2\")\n\n# Plot the resulting graph\nlevel_2$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-054-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntask = tsk(\"iris\")\nlrn = as_learner(level_2)\n```\n:::\n\n\nAnd we can again call `.$train` and `.$predict`:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-055_e50bf1bae13b6ff1fe0c676b28f63329'}\n\n```{.r .cell-code}\nlrn$\n  train(task, train.idx)$\n  predict(task, test.idx)$\n  score()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n       0.1 \n```\n:::\n:::\n\n\n## Adding new PipeOps {#extending-pipeops}\n\nThis section showcases how the [mlr3pipelines](https://mlr3pipelines.mlr-org.com) package can be extended to include custom [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\nTo run the following examples, we will need a [`Task`](https://mlr3.mlr-org.com/reference/Task.html); we are using the well-known \"Iris\" task:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-056_de9901f7f7bbdee67e0023715fbb996e'}\n\n```{.r .cell-code}\nlibrary(\"mlr3\")\ntask = tsk(\"iris\")\ntask$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n  1:    setosa          1.4         0.2          5.1         3.5\n  2:    setosa          1.4         0.2          4.9         3.0\n  3:    setosa          1.3         0.2          4.7         3.2\n  4:    setosa          1.5         0.2          4.6         3.1\n  5:    setosa          1.4         0.2          5.0         3.6\n ---                                                            \n146: virginica          5.2         2.3          6.7         3.0\n147: virginica          5.0         1.9          6.3         2.5\n148: virginica          5.2         2.0          6.5         3.0\n149: virginica          5.4         2.3          6.2         3.4\n150: virginica          5.1         1.8          5.9         3.0\n```\n:::\n:::\n\n\n[mlr3pipelines](https://mlr3pipelines.mlr-org.com) is fundamentally built around [`R6`](https://r6.r-lib.org/).\nWhen planning to create custom [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) objects, it can only help to [familiarize yourself with it](https://adv-r.hadley.nz/r6.html).\n\nIn principle, all a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) must do is inherit from the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) R6 class and implement the `.train()` and `.predict()` functions.\nThere are, however, several auxiliary subclasses that can make the creation of *certain* operations much easier.\n\n### General Case Example: `PipeOpCopy` {#ext-pipeopcopy}\n\nA very simple yet useful [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) is `PipeOpCopy`, which takes a single input and creates a variable number of output channels, all of which receive a copy of the input data.\nIt is a simple example that showcases the important steps in defining a custom [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html).\nWe will show a simplified version here, **`PipeOpCopyTwo`**, that creates exactly two copies of its input data.\n\nThe following figure visualizes how our [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) is situated in the `Pipeline` and the significant in- and outputs.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-057_b8239c2ebcfffca496a322069de70dac'}\n::: {.cell-output-display}\n![](images/po_multi_viz.png){width=430}\n:::\n:::\n\n\n#### First Steps: Inheriting from [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)\n\nThe first part of creating a custom [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) is inheriting from [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html).\nWe make a mental note that we need to implement a `.train()` and a `.predict()` function, and that we probably want to have an `initialize()` as well:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-058_6474e0dfdffb0f50e95ed3aaf8ba832a'}\n\n```{.r .cell-code}\nPipeOpCopyTwo = R6::R6Class(\"PipeOpCopyTwo\",\n  inherit = mlr3pipelines::PipeOp,\n  public = list(\n    initialize = function(id = \"copy.two\") {\n      ....\n    },\n  ),\n  private == list(\n    .train = function(inputs) {\n      ....\n    },\n\n    .predict = function(inputs) {\n      ....\n    }\n  )\n)\n```\n:::\n\n\nNote, that **private** methods, e.g. `.train` and `.predict` etc are prefixed with a `.`.\n\n#### Channel Definitions\n\nWe need to tell the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) the layout of its channels: How many there are, what their names are going to be, and what types are acceptable.\nThis is done on initialization of the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) (using a `super$initialize` call) by giving the `input` and `output` `data.table` objects.\nThese must have three columns: a `\"name\"` column giving the names of input and output channels, and a `\"train\"` and `\"predict\"` column naming the class of objects we expect during training and prediction as input / output.\nA special value for these classes is `\"*\"`, which indicates that any class will be accepted; our simple copy operator accepts any kind of input, so this will be useful. We have only one input, but two output channels.\n\nBy convention, we name a single channel `\"input\"` or `\"output\"`, and a group of channels [`\"input1\"`, `\"input2\"`, ...], unless there is a reason to give specific different names. Therefore, our `input` `data.table` will have a single row `<\"input\", \"*\", \"*\">`, and our `output` table will have two rows, `<\"output1\", \"*\", \"*\">` and `<\"output2\", \"*\", \"*\">`.\n\nAll of this is given to the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) creator. Our `initialize()` will thus look as follows:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-059_309af584c7eaa34c9ba74d034c00ff34'}\n\n```{.r .cell-code}\ninitialize = function(id = \"copy.two\") {\n  input = data.table::data.table(name = \"input\", train = \"*\", predict = \"*\")\n  # the following will create two rows and automatically fill the `train`\n  # and `predict` cols with \"*\"\n  output = data.table::data.table(\n    name = c(\"output1\", \"output2\"),\n    train = \"*\", predict = \"*\"\n  )\n  super$initialize(id,\n    input = input,\n    output = output\n  )\n}\n```\n:::\n\n\n#### Train and Predict\n\nBoth `.train()` and `.predict()` will receive a `list` as input and must give a `list` in return.\nAccording to our `input` and `output` definitions, we will always get a list with a single element as input, and will need to return a list with two elements. Because all we want to do is create two copies, we will just create the copies using `c(inputs, inputs)`.\n\nTwo things to consider:\n\n- The `.train()` function must always modify the `self$state` variable to something that is not `NULL` or `NO_OP`.\n  This is because the `$state` slot is used as a signal that [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)  has been trained on data, even if the state itself is not important to the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) (as in our case).\n  Therefore, our `.train()` will set `self$state = list()`.\n\n- It is not necessary to \"clone\" our input or make deep copies, because we don't modify the data.\n  However, if we were changing a reference-passed object, for example by changing data in a [`Task`](https://mlr3.mlr-org.com/reference/Task.html), we would have to make a deep copy first.\n  This is because a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) may never modify its input object by reference.\n\nOur `.train()` and `.predict()` functions are now:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-060_a05ea46288c48c7d7b57d88fe99d8f23'}\n\n```{.r .cell-code}\n.train = function(inputs) {\n  self$state = list()\n  c(inputs, inputs)\n}\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-061_5104df9287427e4823bf2076174a25f4'}\n\n```{.r .cell-code}\n.predict = function(inputs) {\n  c(inputs, inputs)\n}\n```\n:::\n\n\n#### Putting it Together\n\nThe whole definition thus becomes\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-062_dd19e2d7025c8790bb3bee54978caee7'}\n\n```{.r .cell-code}\nPipeOpCopyTwo = R6::R6Class(\"PipeOpCopyTwo\",\n  inherit = mlr3pipelines::PipeOp,\n  public = list(\n    initialize = function(id = \"copy.two\") {\n      super$initialize(id,\n        input = data.table::data.table(name = \"input\", train = \"*\", predict = \"*\"),\n        output = data.table::data.table(name = c(\"output1\", \"output2\"),\n                            train = \"*\", predict = \"*\")\n      )\n    }\n  ),\n  private = list(\n    .train = function(inputs) {\n      self$state = list()\n      c(inputs, inputs)\n    },\n\n    .predict = function(inputs) {\n      c(inputs, inputs)\n    }\n  )\n)\n```\n:::\n\n\nWe can create an instance of our [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html), put it in a graph, and see what happens when we train it on something:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-063_e63de678506a01eee2a7cd0d01bffe34'}\n\n```{.r .cell-code}\nlibrary(\"mlr3pipelines\")\npoct = PipeOpCopyTwo$new()\ngr = Graph$new()\ngr$add_pipeop(poct)\n\nprint(gr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGraph with 1 PipeOps:\n       ID         State sccssors prdcssors\n copy.two <<UNTRAINED>>                   \n```\n:::\n\n```{.r .cell-code}\nresult = gr$train(task)\n\nstr(result)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ copy.two.output1:Classes 'TaskClassif', 'TaskSupervised', 'Task', 'R6' <TaskClassif:iris> \n $ copy.two.output2:Classes 'TaskClassif', 'TaskSupervised', 'Task', 'R6' <TaskClassif:iris> \n```\n:::\n:::\n\n\n### Special Case: Preprocessing {#ext-pipe-preproc}\n\nMany [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s perform an operation on exactly one [`Task`](https://mlr3.mlr-org.com/reference/Task.html), and return exactly one [`Task`](https://mlr3.mlr-org.com/reference/Task.html). They may even not care about the \"Target\" / \"Outcome\" variable of that task, and only do some modification of some input data.\nHowever, it is usually important to them that the [`Task`](https://mlr3.mlr-org.com/reference/Task.html) on which they perform prediction has the same data columns as the [`Task`](https://mlr3.mlr-org.com/reference/Task.html) on which they train.\nFor these cases, the auxiliary base class [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html) exists.\nIt inherits from [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) itself, and other [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s should use it if they fall in the kind of use-case named above.\n\nWhen inheriting from [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html), one must either implement the private methods `.train_task()` and `.predict_task()`, or the methods `.train_dt()`, `.predict_dt()`, depending on whether wants to operate on a [`Task`](https://mlr3.mlr-org.com/reference/Task.html) object or on its data as `data.table`s.\nIn the second case, one can optionally also overload the `.select_cols()` method, which chooses which of the incoming [`Task`](https://mlr3.mlr-org.com/reference/Task.html)'s features are given to the `.train_dt()` / `.predict_dt()` functions.\n\nThe following will show two examples: `PipeOpDropNA`, which removes a [`Task`](https://mlr3.mlr-org.com/reference/Task.html)'s rows with missing values during training (and implements `.train_task()` and `.predict_task()`), and [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html), which scales a [`Task`](https://mlr3.mlr-org.com/reference/Task.html)'s numeric columns (and implements `.train_dt()`, `.predict_dt()`, and `.select_cols()`).\n\n#### Example: `PipeOpDropNA`\n\nDropping rows with missing values may be important when training a model that can not handle them.\n\nBecause [mlr3](https://mlr3.mlr-org.com) `\"Task\", text = \"Tasks\")` only contain a view to the underlying data, it is not necessary to modify data to remove rows with missing values.\nInstead, the rows can be removed using the [`Task`](https://mlr3.mlr-org.com/reference/Task.html)'s `$filter` method, which modifies the [`Task`](https://mlr3.mlr-org.com/reference/Task.html) in-place.\nThis is done in the private method `.train_task()`.\nWe take care that we also set the `$state` slot to signal that the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) was trained.\n\nThe private method `.predict_task()` does not need to do anything; removing missing values during prediction is not as useful, since learners that cannot handle them will just ignore the respective rows.\nFurthermore, [mlr3](https://mlr3.mlr-org.com) expects a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) to always return just as many predictions as it was given input rows, so a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) that removes [`Task`](https://mlr3.mlr-org.com/reference/Task.html) rows during training can not be used inside a [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html).\n\nWhen we inherit from [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html), it sets the `input` and `output` `data.table`s for us to only accept a single [`Task`](https://mlr3.mlr-org.com/reference/Task.html).\nThe only thing we do during `initialize()` is therefore to set an `id` (which can optionally be changed by the user).\n\nThe complete `PipeOpDropNA` can therefore be written as follows.\nNote that it inherits from [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html), unlike the `PipeOpCopyTwo` example from above:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-064_0a814f0a6dfac49b23e7d6335e37ee1b'}\n\n```{.r .cell-code}\nPipeOpDropNA = R6::R6Class(\"PipeOpDropNA\",\n  inherit = mlr3pipelines::PipeOpTaskPreproc,\n  public = list(\n    initialize = function(id = \"drop.na\") {\n      super$initialize(id)\n    }\n  ),\n\n  private = list(\n    .train_task = function(task) {\n      self$state = list()\n      featuredata = task$data(cols = task$feature_names)\n      exclude = apply(is.na(featuredata), 1, any)\n      task$filter(task$row_ids[!exclude])\n    },\n\n    .predict_task = function(task) {\n      # nothing to be done\n      task\n    }\n  )\n)\n```\n:::\n\n\nTo test this [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html), we create a small task with missing values:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-065_be4c3b0143098f47c5210b4a74c34423'}\n\n```{.r .cell-code}\nsmalliris = iris[(1:5) * 30, ]\nsmalliris[1, 1] = NA\nsmalliris[2, 2] = NA\nsitask = as_task_classif(smalliris, target = \"Species\")\nprint(sitask$data())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n1:     setosa          1.6         0.2           NA         3.2\n2: versicolor          3.9         1.4          5.2          NA\n3: versicolor          4.0         1.3          5.5         2.5\n4:  virginica          5.0         1.5          6.0         2.2\n5:  virginica          5.1         1.8          5.9         3.0\n```\n:::\n:::\n\n\nWe test this by feeding it to a new [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) that uses `PipeOpDropNA`.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-066_e9673fd287649b33d17918cf3085c73b'}\n\n```{.r .cell-code}\ngr = Graph$new()\ngr$add_pipeop(PipeOpDropNA$new())\n\nfiltered_task = gr$train(sitask)[[1]]\nprint(filtered_task$data())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n1: versicolor          4.0         1.3          5.5         2.5\n2:  virginica          5.0         1.5          6.0         2.2\n3:  virginica          5.1         1.8          5.9         3.0\n```\n:::\n:::\n\n\n#### Example: `PipeOpScaleAlways`\n\nAn often-applied preprocessing step is to simply **center** and/or **scale** the data to mean $0$ and standard deviation $1$.\nThis fits the [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html) pattern quite well.\nBecause it always replaces all columns that it operates on, and does not require any information about the task's target, it only needs to overload the `.train_dt()` and `.predict_dt()` functions.\nThis saves some boilerplate-code from getting the correct feature columns out of the task, and replacing them after modification.\n\nBecause scaling only makes sense on numeric features, we want to instruct [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html) to give us only these numeric columns.\nWe do this by overloading the `.select_cols()` function: It is called by the class to determine which columns to pass to `.train_dt()` and `.predict_dt()`.\nIts input is the [`Task`](https://mlr3.mlr-org.com/reference/Task.html) that is being transformed, and it should return a `character` vector of all features to work with.\nWhen it is not overloaded, it uses all columns; instead, we will set it to only give us numeric columns.\nBecause the `levels()` of the data table given to `.train_dt()` and `.predict_dt()` may be different from the [`Task`](https://mlr3.mlr-org.com/reference/Task.html)'s levels, these functions must also take a `levels` argument that is a named list of column names indicating their levels.\nWhen working with numeric data, this argument can be ignored, but it should be used instead of `levels(dt[[column]])` for factorial or character columns.\n\nThis is the first [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) where we will be using the `$state` slot for something useful: We save the centering offset and scaling coefficient and use it in `$.predict()`!\n\nFor simplicity, we are not using hyperparameters and will always scale and center all data.\nCompare this `PipeOpScaleAlways` operator to the one defined inside the [mlr3pipelines](https://mlr3pipelines.mlr-org.com) package, [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html).\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-067_c253f5f9485aa9b588d9d65d786d52e6'}\n\n```{.r .cell-code}\nPipeOpScaleAlways = R6::R6Class(\"PipeOpScaleAlways\",\n  inherit = mlr3pipelines::PipeOpTaskPreproc,\n  public = list(\n    initialize = function(id = \"scale.always\") {\n      super$initialize(id = id)\n    }\n  ),\n\n  private = list(\n    .select_cols = function(task) {\n      task$feature_types[type == \"numeric\", id]\n    },\n\n    .train_dt = function(dt, levels, target) {\n      sc = scale(as.matrix(dt))\n      self$state = list(\n        center = attr(sc, \"scaled:center\"),\n        scale = attr(sc, \"scaled:scale\")\n      )\n      sc\n    },\n\n    .predict_dt = function(dt, levels) {\n      t((t(dt) - self$state$center) / self$state$scale)\n    }\n  )\n)\n```\n:::\n\n\n_(Note for the observant: If you check `PipeOpScale.R` from the [mlr3pipelines](https://mlr3pipelines.mlr-org.com) package, you will notice that is uses \"`get(\"type\")`\" and \"`get(\"id\")`\" instead of \"`type`\" and \"`id`\", because the static code checker on CRAN would otherwise complain about references to undefined variables. This is a \"problem\" with `data.table` and not exclusive to [mlr3pipelines](https://mlr3pipelines.mlr-org.com).)_\n\nWe can, again, create a new [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) that uses this [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) to test it.\nCompare the resulting data to the original \"iris\" [`Task`](https://mlr3.mlr-org.com/reference/Task.html) data printed at the beginning:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-068_11543d940a4c81db7f085a3922e85e3b'}\n\n```{.r .cell-code}\ngr = Graph$new()\ngr$add_pipeop(PipeOpScaleAlways$new())\n\nresult = gr$train(task)\n\nresult[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n  1:    setosa   -1.3357516  -1.3110521  -0.89767388  1.01560199\n  2:    setosa   -1.3357516  -1.3110521  -1.13920048 -0.13153881\n  3:    setosa   -1.3923993  -1.3110521  -1.38072709  0.32731751\n  4:    setosa   -1.2791040  -1.3110521  -1.50149039  0.09788935\n  5:    setosa   -1.3357516  -1.3110521  -1.01843718  1.24503015\n ---                                                            \n146: virginica    0.8168591   1.4439941   1.03453895 -0.13153881\n147: virginica    0.7035638   0.9192234   0.55148575 -1.27867961\n148: virginica    0.8168591   1.0504160   0.79301235 -0.13153881\n149: virginica    0.9301544   1.4439941   0.43072244  0.78617383\n150: virginica    0.7602115   0.7880307   0.06843254 -0.13153881\n```\n:::\n:::\n\n\n### Special Case: Preprocessing with Simple Train\n\nIt is possible to make even further simplifications for many [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s that perform mostly the same operation during training and prediction.\nThe point of [`Task`](https://mlr3.mlr-org.com/reference/Task.html) preprocessing is often to modify the training data in mostly the same way as prediction data (but in a way that *may* depend on training data).\n\nConsider constant feature removal, for example: The goal is to remove features that have no variance, or only a single factor level.\nHowever, what features get removed must be decided during *training*, and may only depend on training data.\nFurthermore, the actual process of removing features is the same during training and prediction.\n\nA simplification to make is therefore to have a private method `.get_state(task)` which sets the `$state` slot during training, and a private method `.transform(task)`, which gets called both during training *and* prediction.\nThis is done in the [`PipeOpTaskPreprocSimple`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreprocSimple.html) class.\nJust like [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html), one can inherit from this and overload these functions to get a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) that performs preprocessing with very little boilerplate code.\n\nJust like [`PipeOpTaskPreproc`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreproc.html), [`PipeOpTaskPreprocSimple`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreprocSimple.html) offers the possibility to instead overload the `.get_state_dt(dt, levels)` and `.transform_dt(dt, levels)` methods (and optionally, again, the `.select_cols(task)` function) to operate on `data.table` feature data instead of the whole [`Task`](https://mlr3.mlr-org.com/reference/Task.html).\n\nEven some methods that do not use [`PipeOpTaskPreprocSimple`](https://mlr3pipelines.mlr-org.com/reference/PipeOpTaskPreprocSimple.html) *could* work in a similar way: The `PipeOpScaleAlways` example from above will be shown to also work with this paradigm.\n\n#### Example: `PipeOpDropConst`\n\nA typical example of a preprocessing operation that does almost the same operation during training and prediction is an operation that drops features depending on a criterion that is evaluated during training.\nOne simple example of this is dropping constant features.\nBecause the [mlr3](https://mlr3.mlr-org.com) [`Task`](https://mlr3.mlr-org.com/reference/Task.html) class offers a flexible view on underlying data, it is most efficient to drop columns from the task directly using its `$select()` function, so the `.get_state_dt(dt, levels)` / `.transform_dt(dt, levels)` functions will *not* get used; instead we overload the `.get_state(task)` and `.transform(task)` methods.\n\nThe `.get_state()` function's result is saved to the `$state` slot, so we want to return something that is useful for dropping features.\nWe choose to save the names of all the columns that have nonzero variance.\nFor brevity, we use `length(unique(column)) > 1` to check whether more than one distinct value is present; a more sophisticated version could have a tolerance parameter for numeric values that are very close to each other.\n\nThe `.transform()` method is evaluated both during training *and* prediction, and can rely on the `$state` slot being present.\nAll it does here is call the `Task$select` function with the columns we chose to keep.\n\nThe full [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) could be written as follows:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-069_4fb1033613ef42a46820269a5dcece33'}\n\n```{.r .cell-code}\nPipeOpDropConst = R6::R6Class(\"PipeOpDropConst\",\n  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,\n  public = list(\n    initialize = function(id = \"drop.const\") {\n      super$initialize(id = id)\n    }\n  ),\n\n  private = list(\n    .get_state = function(task) {\n      data = task$data(cols = task$feature_names)\n      nonconst = sapply(data, function(column) length(unique(column)) > 1)\n      list(cnames = colnames(data)[nonconst])\n    },\n\n    .transform = function(task) {\n      task$select(self$state$cnames)\n    }\n  )\n)\n```\n:::\n\n\nThis can be tested using the first five rows of the \"Iris\" [`Task`](https://mlr3.mlr-org.com/reference/Task.html), for which one feature (`\"Petal.Width\"`) is constant:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-070_aac7986f019119ee666d50247d28a58a'}\n\n```{.r .cell-code}\nirishead = task$clone()$filter(1:5)\nirishead$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n1:  setosa          1.4         0.2          5.1         3.5\n2:  setosa          1.4         0.2          4.9         3.0\n3:  setosa          1.3         0.2          4.7         3.2\n4:  setosa          1.5         0.2          4.6         3.1\n5:  setosa          1.4         0.2          5.0         3.6\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-071_1f067d9de9674b9a0d5af6c643d4d462'}\n\n```{.r .cell-code}\ngr = Graph$new()$add_pipeop(PipeOpDropConst$new())\ndropped_task = gr$train(irishead)[[1]]\n\ndropped_task$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Length Sepal.Length Sepal.Width\n1:  setosa          1.4          5.1         3.5\n2:  setosa          1.4          4.9         3.0\n3:  setosa          1.3          4.7         3.2\n4:  setosa          1.5          4.6         3.1\n5:  setosa          1.4          5.0         3.6\n```\n:::\n:::\n\n\nWe can also see that the `$state` was correctly set.\nCalling `$.predict()` with this graph, even with different data (the whole Iris [`Task`](https://mlr3.mlr-org.com/reference/Task.html)!) will still drop the `\"Petal.Width\"` column, as it should.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-072_424d5437a6f354ca2075db41ff885bda'}\n\n```{.r .cell-code}\ngr$pipeops$drop.const$state\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$cnames\n[1] \"Petal.Length\" \"Sepal.Length\" \"Sepal.Width\" \n\n$affected_cols\n[1] \"Petal.Length\" \"Petal.Width\"  \"Sepal.Length\" \"Sepal.Width\" \n\n$intasklayout\n             id    type\n1: Petal.Length numeric\n2:  Petal.Width numeric\n3: Sepal.Length numeric\n4:  Sepal.Width numeric\n\n$outtasklayout\n             id    type\n1: Petal.Length numeric\n2: Sepal.Length numeric\n3:  Sepal.Width numeric\n\n$outtaskshell\nEmpty data.table (0 rows and 4 cols): Species,Petal.Length,Sepal.Length,Sepal.Width\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-073_183815d5bf3a18b477566c4c3ceaba9b'}\n\n```{.r .cell-code}\ndropped_predict = gr$predict(task)[[1]]\n\ndropped_predict$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Sepal.Length Sepal.Width\n  1:    setosa          1.4          5.1         3.5\n  2:    setosa          1.4          4.9         3.0\n  3:    setosa          1.3          4.7         3.2\n  4:    setosa          1.5          4.6         3.1\n  5:    setosa          1.4          5.0         3.6\n ---                                                \n146: virginica          5.2          6.7         3.0\n147: virginica          5.0          6.3         2.5\n148: virginica          5.2          6.5         3.0\n149: virginica          5.4          6.2         3.4\n150: virginica          5.1          5.9         3.0\n```\n:::\n:::\n\n\n#### Example: `PipeOpScaleAlwaysSimple`\n\nThis example will show how a `PipeOpTaskPreprocSimple` can be used when only working on feature data in form of a `data.table`.\nInstead of calling the `scale()` function, the `center` and `scale` values are calculated directly and saved to the `$state` slot.\nThe `.transform_dt()` function will then perform the same operation during both training and prediction: subtract the `center` and divide by the `scale` value.\nAs in the [`PipeOpScaleAlways` example above](#example-pipeopscalealways), we use `.select_cols()` so that we only work on numeric columns.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-074_483a511baba6404176595b5712addd05'}\n\n```{.r .cell-code}\nPipeOpScaleAlwaysSimple = R6::R6Class(\"PipeOpScaleAlwaysSimple\",\n  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,\n  public = list(\n    initialize = function(id = \"scale.always.simple\") {\n      super$initialize(id = id)\n    }\n  ),\n\n  private = list(\n    .select_cols = function(task) {\n      task$feature_types[type == \"numeric\", id]\n    },\n\n    .get_state_dt = function(dt, levels, target) {\n      list(\n        center = sapply(dt, mean),\n        scale = sapply(dt, sd)\n      )\n    },\n\n    .transform_dt = function(dt, levels) {\n      t((t(dt) - self$state$center) / self$state$scale)\n    }\n  )\n)\n```\n:::\n\n\nWe can compare this [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) to the one above to show that it behaves the same.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-075_4515ab5acd8351b7da1deff25987ef36'}\n\n```{.r .cell-code}\ngr = Graph$new()$add_pipeop(PipeOpScaleAlways$new())\nresult_posa = gr$train(task)[[1]]\n\ngr = Graph$new()$add_pipeop(PipeOpScaleAlwaysSimple$new())\nresult_posa_simple = gr$train(task)[[1]]\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-076_9a27b2071f4f489a2fa679548d34d122'}\n\n```{.r .cell-code}\nresult_posa$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n  1:    setosa   -1.3357516  -1.3110521  -0.89767388  1.01560199\n  2:    setosa   -1.3357516  -1.3110521  -1.13920048 -0.13153881\n  3:    setosa   -1.3923993  -1.3110521  -1.38072709  0.32731751\n  4:    setosa   -1.2791040  -1.3110521  -1.50149039  0.09788935\n  5:    setosa   -1.3357516  -1.3110521  -1.01843718  1.24503015\n ---                                                            \n146: virginica    0.8168591   1.4439941   1.03453895 -0.13153881\n147: virginica    0.7035638   0.9192234   0.55148575 -1.27867961\n148: virginica    0.8168591   1.0504160   0.79301235 -0.13153881\n149: virginica    0.9301544   1.4439941   0.43072244  0.78617383\n150: virginica    0.7602115   0.7880307   0.06843254 -0.13153881\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-077_ef0b4ce13970c0c1b2b6d151d0205a09'}\n\n```{.r .cell-code}\nresult_posa_simple$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n  1:    setosa   -1.3357516  -1.3110521  -0.89767388  1.01560199\n  2:    setosa   -1.3357516  -1.3110521  -1.13920048 -0.13153881\n  3:    setosa   -1.3923993  -1.3110521  -1.38072709  0.32731751\n  4:    setosa   -1.2791040  -1.3110521  -1.50149039  0.09788935\n  5:    setosa   -1.3357516  -1.3110521  -1.01843718  1.24503015\n ---                                                            \n146: virginica    0.8168591   1.4439941   1.03453895 -0.13153881\n147: virginica    0.7035638   0.9192234   0.55148575 -1.27867961\n148: virginica    0.8168591   1.0504160   0.79301235 -0.13153881\n149: virginica    0.9301544   1.4439941   0.43072244  0.78617383\n150: virginica    0.7602115   0.7880307   0.06843254 -0.13153881\n```\n:::\n:::\n\n\n### Hyperparameters {#ext-pipe-hyperpars}\n\n[mlr3pipelines](https://mlr3pipelines.mlr-org.com) uses the [[paradox](https://paradox.mlr-org.com)](https://paradox.mlr-org.com) package to define parameter spaces for [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\nParameters for [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s can modify their behavior in certain ways, e.g. switch centering or scaling off in the [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html) operator.\nThe unified interface makes it possible to have parameters for whole [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)s that modify the individual [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)'s behavior.\nThe [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)s, when encapsulated in [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html)s, can even be tuned using the tuning functionality in [mlr3tuning](https://mlr3tuning.mlr-org.com).\n\nHyperparameters are declared during initialization, when calling the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)'s `$initialize()` function, by giving a `param_set` argument.\nThe `param_set` must be a [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html) from the [paradox](https://paradox.mlr-org.com) package; see [the tuning chapter](#searchspace) or the [in-depth [paradox](https://paradox.mlr-org.com) chapter](#paradox) for more information on how to define parameter spaces.\nAfter construction, the [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html) can be accessed through the `$param_set` slot.\nWhile it is *possible* to modify this [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html), using e.g. the `$add()` and `$add_dep()` functions, *after* adding it to the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html), it is strongly advised against.\n\nHyperparameters can be set and queried through the `$values` slot.\nWhen setting hyperparameters, they are automatically checked to satisfy all conditions set by the `$param_set`, so it is not necessary to type check them.\nBe aware that it is always possible to *remove* hyperparameter values.\n\nWhen a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) is initialized, it usually does not have any parameter values---`$values` takes the value `list()`.\nIt is possible to set initial parameter values in the `$initialize()` constructor; this must be done *after* the `super$initialize()` call where the corresponding [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html) must be supplied.\nThis is because setting `$values` checks against the current `$param_set`, which would fail if the `$param_set` was not set yet.\n\nWhen using an underlying library function (the `scale` function in [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html), say), then there is usually a \"default\" behaviour of that function when a parameter is not given.\nIt is good practice to use this default behaviour whenever a parameter is not set (or when it was removed).\nThis can easily be done when using the [mlr3misc](https://mlr3misc.mlr-org.com) library's [`mlr3misc::invoke()`](https://mlr3misc.mlr-org.com/reference/invoke.html) function, which has functionality similar to `\"do.call()\"`.\n\n#### Hyperparameter Example: [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html)\n\nHow to use hyperparameters can best be shown through the example of [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html), which is very similar to the example above, `PipeOpScaleAlways`.\nThe difference is made by the presence of hyperparameters.\n[`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html) constructs a [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html) in its `$initialize` function and passes this on to the `super$initialize` function:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-078_977e9b2abe01f392a179bf3518981bd6'}\n\n```{.r .cell-code}\nPipeOpScale$public_methods$initialize\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (id = \"scale\", param_vals = list()) \n.__PipeOpScale__initialize(self = self, private = private, super = super, \n    id = id, param_vals = param_vals)\n<environment: namespace:mlr3pipelines>\n```\n:::\n:::\n\n\nThe user has access to this and can set and get parameters.\nTypes are automatically checked:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-079_af96bf69331bb3e809add3d7378443c4'}\n\n```{.r .cell-code}\npss = po(\"scale\")\nprint(pss$param_set)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ParamSet:scale>\n               id    class lower upper nlevels        default value\n1:         center ParamLgl    NA    NA       2           TRUE      \n2:          scale ParamLgl    NA    NA       2           TRUE      \n3:         robust ParamLgl    NA    NA       2 <NoDefault[3]> FALSE\n4: affect_columns ParamUty    NA    NA     Inf  <Selector[1]>      \n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-080_aa9e1dc012947eeedc5e33bc13ee44a2'}\n\n```{.r .cell-code}\npss$param_set$values$center = FALSE\nprint(pss$param_set$values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$robust\n[1] FALSE\n\n$center\n[1] FALSE\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-081_f9775b2bcfeb64e171e0d2b48979036a'}\n\n```{.r .cell-code}\npss$param_set$values$scale = \"TRUE\" # bad input is checked!\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in self$assert(xs): Assertion on 'xs' failed: scale: Must be of type 'logical flag', not 'character'.\n```\n:::\n:::\n\n\nHow [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html) handles its parameters can be seen in its `$.train_dt` method: It gets the relevant parameters from its `$values` slot and uses them in the [`mlr3misc::invoke()`](https://mlr3misc.mlr-org.com/reference/invoke.html) call.\nThis has the advantage over calling `scale()` directly that if a parameter is not given, its default value from the `\"scale()\"` function will be used.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-082_737e592b40b98b18583eb65ed1a02072'}\n\n```{.r .cell-code}\nPipeOpScale$private_methods$.train_dt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (dt, levels, target) \n.__PipeOpScale__.train_dt(self = self, private = private, super = super, \n    dt = dt, levels = levels, target = target)\n<environment: namespace:mlr3pipelines>\n```\n:::\n:::\n\n\nAnother change that is necessary compared to `PipeOpScaleAlways` is that the attributes `\"scaled:scale\"` and `\"scaled:center\"` are not always present, depending on parameters, and possibly need to be set to default values $1$ or $0$, respectively.\n\nIt is now even possible (if a bit pointless) to call [`PipeOpScale`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_scale.html) with both `scale` and `center` set to `FALSE`, which returns the original dataset, unchanged.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-083_06e81ceb483779a2d1ac7c5dfa242f8c'}\n\n```{.r .cell-code}\npss$param_set$values$scale = FALSE\npss$param_set$values$center = FALSE\n\ngr = Graph$new()\ngr$add_pipeop(pss)\n\nresult = gr$train(task)\n\nresult[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n  1:    setosa          1.4         0.2          5.1         3.5\n  2:    setosa          1.4         0.2          4.9         3.0\n  3:    setosa          1.3         0.2          4.7         3.2\n  4:    setosa          1.5         0.2          4.6         3.1\n  5:    setosa          1.4         0.2          5.0         3.6\n ---                                                            \n146: virginica          5.2         2.3          6.7         3.0\n147: virginica          5.0         1.9          6.3         2.5\n148: virginica          5.2         2.0          6.5         3.0\n149: virginica          5.4         2.3          6.2         3.4\n150: virginica          5.1         1.8          5.9         3.0\n```\n:::\n:::\n\n\n## Special Operators {#pipe-special-ops}\n\n\n\n\n\nThis section introduces some special operators, that might be useful in numerous further applications.\n\n### Imputation: `PipeOpImpute`\n\nOften you will be using data sets that have missing values.\nThere are many methods of dealing with this issue, from relatively simple imputation using either mean, median or histograms to way more involved methods including using machine learning algorithms in order to predict missing values.\nThese methods are called imputation.\n\nThe following [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s, [`PipeOpImpute`](https://mlr3pipelines.mlr-org.com/reference/PipeOpImpute.html):\n\n- Add an indicator column marking whether a value for a given feature was missing or not (numeric only)\n- Impute numeric values from a histogram\n- Impute categorical values using a learner\n- We use `po(\"featureunion\")` and `po(\"nop\")` to cbind the missing indicator features. In other words to combine the indicator columns with the rest of the data.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-085_6b34fb63c5fa11686d651c46aea676e3'}\n\n```{.r .cell-code}\n# Imputation example\ntask = tsk(\"penguins\")\ntask$missings()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       species     bill_depth    bill_length      body_mass flipper_length \n             0              2              2              2              2 \n        island            sex           year \n             0             11              0 \n```\n:::\n\n```{.r .cell-code}\n# Add missing indicator columns (\"dummy columns\") to the Task\npom = po(\"missind\")\n# Simply pushes the input forward\nnop = po(\"nop\")\n# Imputes numerical features by histogram.\npon = po(\"imputehist\", id = \"imputer_num\")\n# combines features (used here to add indicator columns to original data)\npou = po(\"featureunion\")\n# Impute categorical features by fitting a Learner (\"classif.rpart\") for each feature.\npof = po(\"imputelearner\", lrn(\"classif.rpart\"), id = \"imputer_fct\", affect_columns = selector_type(\"factor\"))\n```\n:::\n\n\nNow we construct the graph.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-086_2342b7c4a2b9e6b2f92a826ecf321047'}\n\n```{.r .cell-code}\nimpgraph = list(\n  pom,\n  nop\n) %>>% pou %>>% pof %>>% pon\n\nimpgraph$plot()\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-086-1.png){width=672}\n:::\n:::\n\n\nNow we get the new task and we can see that all of the missing values have been imputed.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-087_86de009997054d1e07493c7f2f6520b5'}\n\n```{.r .cell-code}\nnew_task = impgraph$train(task)[[1]]\n\nnew_task$missings()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               species     missing_bill_depth    missing_bill_length \n                     0                      0                      0 \n     missing_body_mass missing_flipper_length                 island \n                     0                      0                      0 \n                  year                    sex             bill_depth \n                     0                      0                      0 \n           bill_length              body_mass         flipper_length \n                     0                      0                      0 \n```\n:::\n:::\n\n\nA learner can thus be equipped with automatic imputation of missing values by adding an imputation Pipeop.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-088_ca9849168609fa0d944cfe95453208ab'}\n\n```{.r .cell-code}\npolrn = po(\"learner\", lrn(\"classif.rpart\"))\nlrn = as_learner(impgraph %>>% polrn)\n```\n:::\n\n\n### Feature Engineering: `PipeOpMutate`\n\nNew features can be added or computed from a task using [`PipeOpMutate`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_mutate.html) .\nThe operator evaluates one or multiple expressions provided in an `alist`.\nIn this example, we compute some new features on top of the `iris` task.\nThen we add them to the data as illustrated below:\n\n`iris` dataset looks like this:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-089_175f9b91c3f52572f660c68b78ac000e'}\n\n```{.r .cell-code}\ntask = task = tsk(\"iris\")\nhead(as.data.table(task))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n1:  setosa          1.4         0.2          5.1         3.5\n2:  setosa          1.4         0.2          4.9         3.0\n3:  setosa          1.3         0.2          4.7         3.2\n4:  setosa          1.5         0.2          4.6         3.1\n5:  setosa          1.4         0.2          5.0         3.6\n6:  setosa          1.7         0.4          5.4         3.9\n```\n:::\n:::\n\n\nOnce we do the mutations, you can see the new columns:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-090_9ac3887f104bf21db79d7fdb002ccdb5'}\n\n```{.r .cell-code}\npom = po(\"mutate\")\n\n# Define a set of mutations\nmutations = list(\n  Sepal.Sum = ~ Sepal.Length + Sepal.Width,\n  Petal.Sum = ~ Petal.Length + Petal.Width,\n  Sepal.Petal.Ratio = ~ (Sepal.Length / Petal.Length)\n)\npom$param_set$values$mutation = mutations\n\nnew_task = pom$train(list(task))[[1]]\nhead(as.data.table(new_task))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Length Petal.Width Sepal.Length Sepal.Width Sepal.Sum\n1:  setosa          1.4         0.2          5.1         3.5       8.6\n2:  setosa          1.4         0.2          4.9         3.0       7.9\n3:  setosa          1.3         0.2          4.7         3.2       7.9\n4:  setosa          1.5         0.2          4.6         3.1       7.7\n5:  setosa          1.4         0.2          5.0         3.6       8.6\n6:  setosa          1.7         0.4          5.4         3.9       9.3\n2 variables not shown: [Petal.Sum, Sepal.Petal.Ratio]\n```\n:::\n:::\n\n\nIf outside data is required, we can make use of the `env` parameter.\nMoreover, we provide an environment, where expressions are evaluated (`env` defaults to `.GlobalEnv`).\n\n### Training on data subsets: `PipeOpChunk`\n\nIn cases, where data is too big to fit into the machine's memory, an often-used technique is to split the data into several parts.\nSubsequently, the parts are trained on each part of the data.\n\nAfter undertaking these steps, we aggregate the models.\nIn this example, we split our data into 4 parts using [`PipeOpChunk`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_chunk.html) .\nAdditionally, we create 4 [`PipeOpLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner.html)  POS, which are then trained on each split of the data.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-091_9a57bfb97c3fa712cf431b347184a2c6'}\n\n```{.r .cell-code}\nchks = po(\"chunk\", 4)\nlrns = ppl(\"greplicate\", po(\"learner\", lrn(\"classif.rpart\")), 4)\n```\n:::\n\n\nAfterwards we can use [`PipeOpClassifAvg`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_classifavg.html) to aggregate the predictions from the 4 different models into a new one.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-092_062977228d410d7ed6fcd6718bd83525'}\n\n```{.r .cell-code}\nmjv = po(\"classifavg\", 4)\n```\n:::\n\n\nWe can now connect the different operators and visualize the full graph:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-093_3654d4cc29a17bab0eeae9a6d6a77a73'}\n\n```{.r .cell-code}\npipeline = chks %>>% lrns %>>% mjv\npipeline$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-093-1.png){width=720}\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-094_75033e4bea9b5d211dd5f9830fed60ad'}\n\n```{.r .cell-code}\ntask = tsk(\"iris\")\ntrain.idx = sample(seq_len(task$nrow), 120)\ntest.idx = setdiff(seq_len(task$nrow), train.idx)\n\npipelrn = as_learner(pipeline)\npipelrn$train(task, train.idx)$\n  predict(task, train.idx)$\n  score()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclassif.ce \n       NaN \n```\n:::\n:::\n\n\n### Feature Selection: `PipeOpFilter` and `PipeOpSelect`\n\nThe package [mlr3filters](https://mlr3filters.mlr-org.com) contains many different `\"mlr3filters::Filter\")`s that can be used to select features for subsequent learners.\nThis is often required when the data has a large amount of features.\n\nA [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) for filters is [`PipeOpFilter`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_filter.html):\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-095_69e33ec3993e7f6db6adba9c1f3d5221'}\n\n```{.r .cell-code}\npo(\"filter\", mlr3filters::flt(\"information_gain\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPipeOp: <information_gain> (not trained)\nvalues: <list()>\nInput channels <name [train type, predict type]>:\n  input [Task,Task]\nOutput channels <name [train type, predict type]>:\n  output [Task,Task]\n```\n:::\n:::\n\n\nHow many features to keep can be set using `filter_nfeat`, `filter_frac` and `filter_cutoff`.\n\nFilters can be selected / de-selected by name using [`PipeOpSelect`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_select.html).\n\n## In-depth look into mlr3pipelines {#in-depth-pipelines}\n\n\n\n\n\nThis vignette is an in-depth introduction to [mlr3pipelines](https://cran.r-project.org/package=mlr3pipelines), the dataflow programming toolkit for machine learning in `R` using [mlr3](https://mlr3.mlr-org.com).\nIt will go through basic concepts and then give a few examples that both show the simplicity as well as the power and versatility of using [mlr3pipelines](https://cran.r-project.org/package=mlr3pipelines).\n\n### What's the Point\n\nMachine learning toolkits often try to abstract away the processes happening inside machine learning algorithms.\nThis makes it easy for the user to switch out one algorithm for another without having to worry about what is happening inside it, what kind of data it is able to operate on etc.\nThe benefit of using [mlr3](https://mlr3.mlr-org.com), for example, is that one can create a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html), a [`Task`](https://mlr3.mlr-org.com/reference/Task.html), a [`Resampling`](https://mlr3.mlr-org.com/reference/Resampling.html) etc. and use them for typical machine learning operations.\nIt is trivial to exchange individual components and therefore use, for example, a different [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) in the same experiment for comparison.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-097_e1d7b63a8ae6b8f0d42a37baa2e2c08d'}\n\n```{.r .cell-code}\ntask = as_task_classif(iris, target = \"Species\")\nlrn = lrn(\"classif.rpart\")\nrsmp = rsmp(\"holdout\")\nresample(task, lrn, rsmp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ResampleResult> of 1 iterations\n* Task: iris\n* Learner: classif.rpart\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n```\n:::\n:::\n\n\nHowever, this modularity breaks down as soon as the learning algorithm encompasses more than just model fitting, like data preprocessing, ensembles or other meta models.\n[mlr3pipelines](https://cran.r-project.org/package=mlr3pipelines) takes modularity one step further than [mlr3](https://mlr3.mlr-org.com): it makes it possible to build individual steps within a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) out of building blocks called [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\n\n### [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html): Pipeline Operators\n\nThe most basic unit of functionality within [mlr3pipelines](https://cran.r-project.org/package=mlr3pipelines) is the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html), short for \"pipeline operator\", which represents a trans-formative operation on input (for example a training dataset) leading to output.\nIt can therefore be seen as a generalized notion of a function, with a certain twist: [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s behave differently during a \"training phase\" and a \"prediction phase\".\nThe training phase will typically generate a certain model of the data that is saved as internal state.\nThe prediction phase will then operate on the input data depending on the trained model.\n\nAn example of this behavior is the *principal component analysis* operation (\"[`PipeOpPCA`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_pca.html)\"):\nDuring training, it will transform incoming data by rotating it in a way that leads to uncorrelated features ordered by their contribution to total variance.\nIt will *also* save the rotation matrix to be use for new data during the \"prediction phase\".\nThis makes it possible to perform \"prediction\" with single rows of new data, where a row's scores on each of the principal components (the components of the training data!) is computed.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-098_52c1515467e01d30264a25a9d5264373'}\n\n```{.r .cell-code}\npo = po(\"pca\")\npo$train(list(task))[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species       PC1         PC2         PC3          PC4\n  1:    setosa -2.684126  0.31939725 -0.02791483 -0.002262437\n  2:    setosa -2.714142 -0.17700123 -0.21046427 -0.099026550\n  3:    setosa -2.888991 -0.14494943  0.01790026 -0.019968390\n  4:    setosa -2.745343 -0.31829898  0.03155937  0.075575817\n  5:    setosa -2.728717  0.32675451  0.09007924  0.061258593\n ---                                                         \n146: virginica  1.944110  0.18753230  0.17782509 -0.426195940\n147: virginica  1.527167 -0.37531698 -0.12189817 -0.254367442\n148: virginica  1.764346  0.07885885  0.13048163 -0.137001274\n149: virginica  1.900942  0.11662796  0.72325156 -0.044595305\n150: virginica  1.390189 -0.28266094  0.36290965  0.155038628\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-099_8d4160d63e072a405fa8663d606d7a4d'}\n\n```{.r .cell-code}\nsingle_line_task = task$clone()$filter(1)\npo$predict(list(single_line_task))[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species       PC1       PC2         PC3          PC4\n1:  setosa -2.684126 0.3193972 -0.02791483 -0.002262437\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-100_630a0a729be0847d78235b62f50dfdb9'}\n\n```{.r .cell-code}\npo$state\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStandard deviations (1, .., p=4):\n[1] 2.0562689 0.4926162 0.2796596 0.1543862\n\nRotation (n x k) = (4 x 4):\n                     PC1         PC2         PC3        PC4\nPetal.Length  0.85667061 -0.17337266  0.07623608  0.4798390\nPetal.Width   0.35828920 -0.07548102  0.54583143 -0.7536574\nSepal.Length  0.36138659  0.65658877 -0.58202985 -0.3154872\nSepal.Width  -0.08452251  0.73016143  0.59791083  0.3197231\n```\n:::\n:::\n\n\nThis shows the most important primitives incorporated in a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html):\n* **`$train()`**, taking a list of input arguments, turning them into a list of outputs, meanwhile saving a state in `$state`\n* **`$predict()`**, taking a list of input arguments, turning them into a list of outputs, making use of the saved `$state`\n* **`$state`**, the \"model\" trained with `$train()` and utilized during `$predict()`.\n\nSchematically we can represent the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) like so:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-101_02c8482769b667d90f5d9d1464bcf675'}\n::: {.cell-output-display}\n![](images/po_viz.png){width=464}\n:::\n:::\n\n\n#### Why the `$state`\n\nIt is important to take a moment and notice the importance of a `$state` variable and the `$train()` / `$predict()` dichotomy in a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html).\nThere are many preprocessing methods, for example scaling of parameters or imputation, that could in theory just be applied to training data and prediction / validation data separately, or they could be applied to a task before resampling is performed.\nThis would, however, be fallacious:\n\n* The preprocessing of each instance of prediction data should not depend on the remaining prediction dataset.\nA prediction on a single instance of new data should give the same result as prediction performed on a whole dataset.\n* If preprocessing is performed on a task *before* resampling is done, information about the test set can leak into the training set.\nResampling should evaluate the generalization performance of the *entire* machine learning method, therefore the behavior of this entire method must only depend only on the content of the *training* split during resampling.\n\n#### Where to get [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s\n\nEach [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) is an instance of an \"`R6`\" class, many of which are provided by the [mlr3pipelines](https://cran.r-project.org/package=mlr3pipelines) package itself.\nThey can be constructed explicitly (\"`PipeOpPCA$new()`\") or retrieved from the [`mlr_pipeops`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops.html) dictionary: `po(\"pca\")`.\nThe entire list of available [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s, and some meta-information, can be retrieved using [`as.data.table()`](https://www.rdocumentation.org/packages/data.table/topics/as.data.table):\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-102_6ca1ea736713fbf66a900e7d757fae92'}\n\n```{.r .cell-code}\nas.data.table(mlr_pipeops)[, c(\"key\", \"input.num\", \"output.num\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               key input.num output.num\n 1:         boxcox         1          1\n 2:         branch         1         NA\n 3:          chunk         1         NA\n 4: classbalancing         1          1\n 5:     classifavg        NA          1\n---                                    \n60:      threshold         1          1\n61:  tunethreshold         1          1\n62:       unbranch        NA          1\n63:         vtreat         1          1\n64:     yeojohnson         1          1\n```\n:::\n:::\n\n\nWhen retrieving [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s from the [`mlr_pipeops`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops.html) dictionary, it is also possible to give additional constructor arguments, such as an [id](#pipeop-ids-and-id-name-clashes) or [parameter values](#hyperparameters).\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-103_41519e040ee3909c601600713cd60df5'}\n\n```{.r .cell-code}\npo(\"pca\", rank. = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPipeOp: <pca> (not trained)\nvalues: <rank.=3>\nInput channels <name [train type, predict type]>:\n  input [Task,Task]\nOutput channels <name [train type, predict type]>:\n  output [Task,Task]\n```\n:::\n:::\n\n\n### PipeOp Channels\n\n#### Input Channels\n\nJust like functions, [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s can take multiple inputs.\nThese multiple inputs are always given as elements in the input list.\nFor example, there is a [`PipeOpFeatureUnion`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_featureunion.html) that combines multiple tasks with different features and \"`cbind()`s\" them together, creating one combined task.\nWhen two halves of the `iris` task are given, for example, it recreates the original task:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-104_96487c11c3f161dd4588ed65c426ec96'}\n\n```{.r .cell-code}\niris_first_half = task$clone()$select(c(\"Petal.Length\", \"Petal.Width\"))\niris_second_half = task$clone()$select(c(\"Sepal.Length\", \"Sepal.Width\"))\n\npofu = po(\"featureunion\", innum = 2)\n\npofu$train(list(iris_first_half, iris_second_half))[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n  1:    setosa          1.4         0.2          5.1         3.5\n  2:    setosa          1.4         0.2          4.9         3.0\n  3:    setosa          1.3         0.2          4.7         3.2\n  4:    setosa          1.5         0.2          4.6         3.1\n  5:    setosa          1.4         0.2          5.0         3.6\n ---                                                            \n146: virginica          5.2         2.3          6.7         3.0\n147: virginica          5.0         1.9          6.3         2.5\n148: virginica          5.2         2.0          6.5         3.0\n149: virginica          5.4         2.3          6.2         3.4\n150: virginica          5.1         1.8          5.9         3.0\n```\n:::\n:::\n\n\nBecause [`PipeOpFeatureUnion`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_featureunion.html) effectively takes two input arguments here, we can say it has two **input channels**.\nAn input channel also carries information about the *type* of input that is acceptable.\nThe input channels of the `pofu` object constructed above, for example, each accept a [`Task`](https://mlr3.mlr-org.com/reference/Task.html) during training and prediction.\nThis information can be queried from the `$input` slot:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-105_aa4d400fce4319ee6ae8e1b44a913b73'}\n\n```{.r .cell-code}\npofu$input\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     name train predict\n1: input1  Task    Task\n2: input2  Task    Task\n```\n:::\n:::\n\n\nOther [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s may have channels that take different types during different phases.\nThe `backuplearner` [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html), for example, takes a `NULL` and a [`Task`](https://mlr3.mlr-org.com/reference/Task.html) during training, and a [`Prediction`](https://mlr3.mlr-org.com/reference/Prediction.html) and a [`Task`](https://mlr3.mlr-org.com/reference/Task.html) during prediction:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-106_0101270af62bd8f32e434550b212c0a6'}\n\n```{.r .cell-code}\n# TODO this is an important case to handle here, do not delete unless there is a better example.\n# po(\"backuplearner\")$input\n```\n:::\n\n\n#### Output Channels\n\nUnlike the typical notion of a function, [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s can also have multiple **output channels**.\n`$train()` and `$predict()` always return a list, so certain [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s may return lists with more than one element.\nSimilar to input channels, the information about the number and type of outputs given by a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) is available in the `$output` slot.\nThe `chunk` PipeOp, for example, chunks a given [`Task`](https://mlr3.mlr-org.com/reference/Task.html) into subsets and consequently returns multiple [`Task`](https://mlr3.mlr-org.com/reference/Task.html) objects, both during training and prediction.\nThe number of output channels must be given during construction through the `outnum` argument.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-107_335b4e16eeec5701ca1fc3cd44e8ace4'}\n\n```{.r .cell-code}\npo(\"chunk\", outnum = 3)$output\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      name train predict\n1: output1  Task    Task\n2: output2  Task    Task\n3: output3  Task    Task\n```\n:::\n:::\n\n\nNote that the number of output channels during training and prediction is the same.\nA schema of a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) with two output channels:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-108_437ece5c67d755daccdddfce03be07af'}\n::: {.cell-output-display}\n![](images/po_multi_alone.png){width=282}\n:::\n:::\n\n\n#### Channel Configuration\n\nMost [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s have only one input channel (so they take a list with a single element), but there are a few with more than one;\nIn many cases, the number of input or output channels is determined during construction, e.g. through the `innum` / `outnum` arguments.\nThe `input.num` and `output.num` columns of the [`mlr_pipeops`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops.html)-table [above](#where-to-get-pipeops) show the default number of channels, and `NA` if the number depends on a construction argument.\n\nThe default printer of a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) gives information about channel names and types:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-109_de9bfac7e37d7c9fb2a81bb519271e0a'}\n\n```{.r .cell-code}\n# po(\"backuplearner\")\n```\n:::\n\n\n### [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html): Networks of [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s\n\n#### Basics\n\nWhat is the advantage of this tedious way of declaring input and output channels and handling in/output through lists?\nBecause each [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) has a known number of input and output channels that always produce or accept data of a known type, it is possible to network them together in **[`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)**s.\nA [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) is a collection of [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s with \"edges\" that mandate that data should be flowing along them.\nEdges always pass between [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) *channels*, so it is not only possible to explicitly prescribe which position of an input or output list an edge refers to, it makes it possible to make different components of a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)'s output flow to multiple different other [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s, as well as to have a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) gather its input from multiple other [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\n\nA schema of a simple graph of [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-110_3c98e9d07deb30acd672f6c5e28be8f5'}\n::: {.cell-output-display}\n![](images/po_multi_viz.png){width=430}\n:::\n:::\n\n\nA [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) is empty when first created, and [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s can be added using the **`$add_pipeop()`** method.\nThe **`$add_edge()`** method is used to create connections between them.\nWhile the printer of a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) gives some information about its layout, the most intuitive way of visualizing it is using the `$plot()` function.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-111_b1dbdfefabb4c2f3837e211947e44bad'}\n\n```{.r .cell-code}\ngr = Graph$new()\ngr$add_pipeop(po(\"scale\"))\ngr$add_pipeop(po(\"subsample\", frac = 0.1))\ngr$add_edge(\"scale\", \"subsample\")\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-112_49b090fb87ad534a314fca6987ba7f6f'}\n\n```{.r .cell-code}\nprint(gr)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGraph with 2 PipeOps:\n        ID         State  sccssors prdcssors\n     scale <<UNTRAINED>> subsample          \n subsample <<UNTRAINED>>               scale\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-113_4f52c79af745368109d58a82f7bc6562'}\n\n```{.r .cell-code}\ngr$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-113-1.png){width=768}\n:::\n:::\n\n\nA [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) itself has a **`$train()`** and a **`$predict()`** method that accept some data and propagate this data through the network of [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\nThe return value corresponds to the output of the [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) output channels that are not connected to other [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-114_f6cfb62a00674e7874e8835ac25211fa'}\n\n```{.r .cell-code}\ngr$train(task)[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length   Petal.Width Sepal.Length Sepal.Width\n 1:     setosa   -1.2224563 -1.3110521482  -1.25996379  0.78617383\n 2:     setosa   -1.1658087 -1.3110521482  -0.53538397  0.78617383\n 3:     setosa   -1.4490469 -1.3110521482  -1.01843718  0.32731751\n 4:     setosa   -1.0525134 -1.0486667950  -0.89767388  1.70388647\n 5: versicolor    0.1370873  0.1320672944  -0.41462067 -1.73753594\n 6: versicolor   -0.1461509 -0.2615107354  -1.01843718 -2.42582042\n 7: versicolor    0.5336209  0.0008746178   0.30995914 -0.59039513\n 8: versicolor    0.3070303  0.1320672944   0.67224905 -0.36096697\n 9: versicolor    0.1370873  0.0008746178  -0.05233076 -1.04925145\n10:  virginica    0.9868021  1.1816087073   1.15530226 -0.13153881\n11:  virginica    0.8735068  1.4439940605   0.67224905  0.32731751\n12:  virginica    1.1000974  1.1816087073   1.03453895  0.55674567\n13:  virginica    0.7602115  0.3944526477   0.55148575 -0.59039513\n14:  virginica    0.9868021  0.7880306775   0.67224905  0.09788935\n15:  virginica    0.7035638  0.9192233541   0.55148575 -1.27867961\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-115_545e643084f216e1d89f06668acf24ac'}\n\n```{.r .cell-code}\ngr$predict(single_line_task)[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n1:  setosa    -1.335752   -1.311052   -0.8976739    1.015602\n```\n:::\n:::\n\n\nThe collection of [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s inside a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) can be accessed through the **`$pipeops`** slot.\nThe set of edges in the Graph can be inspected through the **`$edges`** slot.\nIt is possible to modify individual `PipeOps` and edges in a Graph through these slots, but this is not recommended because no error checking is performed and it may put the [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) in an unsupported state.\n\n#### Networks\n\nThe example above showed a linear preprocessing pipeline, but it is in fact possible to build true \"graphs\" of operations, as long as no loops are introduced^[It is tempting to denote this as a \"directed acyclic graph\", but this would not be entirely correct because edges run between channels of [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s, not [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s themselves.].\n[`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s with multiple output channels can feed their data to multiple different subsequent [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s, and [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s with multiple input channels can take results from different [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s.\nWhen a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) has more than one input / output channel, then the [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)'s `$add_edge()` method needs an additional argument that indicates which channel to connect to.\nThis argument can be given in the form of an integer, or as the name of the channel.\n\nThe following constructs a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) that copies the input and gives one copy each to a \"scale\" and a \"pca\" [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html).\nThe resulting columns of each operation are put next to each other by \"featureunion\".\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-116_a303ac15f2902b656e183c71e8b94e87'}\n\n```{.r .cell-code}\ngr = Graph$new()$\n  add_pipeop(po(\"copy\", outnum = 2))$\n  add_pipeop(po(\"scale\"))$\n  add_pipeop(po(\"pca\"))$\n  add_pipeop(po(\"featureunion\", innum = 2))\n\ngr$\n  add_edge(\"copy\", \"scale\", src_channel = 1)$        # designating channel by index\n  add_edge(\"copy\", \"pca\", src_channel = \"output2\")$  # designating channel by name\n  add_edge(\"scale\", \"featureunion\", dst_channel = 1)$\n  add_edge(\"pca\", \"featureunion\", dst_channel = 2)\n\ngr$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-116-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-117_612e52dd60258b88829b05c8553a1fb1'}\n\n```{.r .cell-code}\ngr$train(iris_first_half)[[1]]$data()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Species Petal.Length Petal.Width       PC1          PC2\n  1:    setosa   -1.3357516  -1.3110521 -2.561012 -0.006922191\n  2:    setosa   -1.3357516  -1.3110521 -2.561012 -0.006922191\n  3:    setosa   -1.3923993  -1.3110521 -2.653190  0.031849692\n  4:    setosa   -1.2791040  -1.3110521 -2.468834 -0.045694073\n  5:    setosa   -1.3357516  -1.3110521 -2.561012 -0.006922191\n ---                                                          \n146: virginica    0.8168591   1.4439941  1.755953  0.455479438\n147: virginica    0.7035638   0.9192234  1.416510  0.164312126\n148: virginica    0.8168591   1.0504160  1.639637  0.178946130\n149: virginica    0.9301544   1.4439941  1.940308  0.377935674\n150: virginica    0.7602115   0.7880307  1.469915  0.033362474\n```\n:::\n:::\n\n\n#### Syntactic Sugar\n\nAlthough it is possible to create intricate [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)s with edges going all over the place (as long as no loops are introduced), there is usually a clear direction of flow between \"layers\" in the [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html).\nIt is therefore convenient to build up a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) from layers, which can be done using the **`%>>%`** (\"double-arrow\") operator.\nIt takes either a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) or a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) on each of its sides and connects all of the outputs of its left-hand side to one of the inputs each of its right-hand side--the number of inputs therefore must match the number of outputs.\nTogether with the [`gunion()`](https://mlr3pipelines.mlr-org.com/reference/gunion.html) operation, which takes [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s or [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)s and arranges them next to each other akin to a (disjoint) graph union, the above network can more easily be constructed as follows:\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-118_3fb4df05c7c56b8f2c04e60e96a2068b'}\n\n```{.r .cell-code}\ngr = po(\"copy\", outnum = 2) %>>%\n  gunion(list(po(\"scale\"), po(\"pca\"))) %>>%\n  po(\"featureunion\", innum = 2)\n\ngr$plot(html = FALSE)\n```\n\n::: {.cell-output-display}\n![](pipelines_files/figure-html/pipelines-118-1.png){width=672}\n:::\n:::\n\n\n#### [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) IDs and ID Name Clashes\n\n[`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s within a graph are addressed by their **`$id`**-slot.\nIt is therefore necessary for all [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)s within a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) to have a unique `$id`.\nThe `$id` can be set during or after construction, but it should not directly be changed after a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) was inserted in a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html).\nAt that point, the **`$set_names()`**-method can be used to change [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) ids.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-119_bd90d1a1de86d9c705a82279b3fd6fe2'}\n\n```{.r .cell-code}\npo1 = po(\"scale\")\npo2 = po(\"scale\")\npo1 %>>% po2 # name clash\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in gunion(list(g1, g2), in_place = c(TRUE, TRUE)): Assertion on 'ids of pipe operators of graphs' failed: Must have unique names, but element 2 is duplicated.\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-120_6607667a4e2c25eba36ea1f384bec81d'}\n\n```{.r .cell-code}\npo2$id = \"scale2\"\ngr = po1 %>>% po2\ngr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGraph with 2 PipeOps:\n     ID         State sccssors prdcssors\n  scale <<UNTRAINED>>   scale2          \n scale2 <<UNTRAINED>>              scale\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-121_1cbe56271bfdb1bb927f7093f3c5954f'}\n\n```{.r .cell-code}\n# Alternative ways of getting new ids:\npo(\"scale\", id = \"scale2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPipeOp: <scale2> (not trained)\nvalues: <robust=FALSE>\nInput channels <name [train type, predict type]>:\n  input [Task,Task]\nOutput channels <name [train type, predict type]>:\n  output [Task,Task]\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-122_ec3145ec4c475c1657faf7853503df3f'}\n\n```{.r .cell-code}\n# sometimes names of PipeOps within a Graph need to be changed\ngr2 = po(\"scale\") %>>% po(\"pca\")\ngr %>>% gr2\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in gunion(list(g1, g2), in_place = c(TRUE, TRUE)): Assertion on 'ids of pipe operators of graphs' failed: Must have unique names, but element 3 is duplicated.\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-123_30d73ef1b742313c76927a7c46230e9e'}\n\n```{.r .cell-code}\ngr2$set_names(\"scale\", \"scale3\")\ngr %>>% gr2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGraph with 4 PipeOps:\n     ID         State sccssors prdcssors\n  scale <<UNTRAINED>>   scale2          \n scale2 <<UNTRAINED>>   scale3     scale\n scale3 <<UNTRAINED>>      pca    scale2\n    pca <<UNTRAINED>>             scale3\n```\n:::\n:::\n\n\n### Learners in Graphs, Graphs in Learners\n\nThe true power of [mlr3pipelines](https://cran.r-project.org/package=mlr3pipelines) derives from the fact that it can be integrated seamlessly with [mlr3](https://mlr3.mlr-org.com).\nTwo components are mainly responsible for this:\n\n* [`PipeOpLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner.html), a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) that encapsulates a [mlr3](https://mlr3.mlr-org.com) [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) and creates a [`PredictionData`](https://mlr3.mlr-org.com/reference/PredictionData.html) object in its `$predict()` phase\n* [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html), a [mlr3](https://mlr3.mlr-org.com) [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) that can be used in place of any other [mlr3](https://mlr3.mlr-org.com) [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html), but which does prediction using a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) given to it\n\nNote that these are dual to each other: One takes a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) and produces a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) (and by extension a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)); the other takes a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) and produces a [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html).\n\n#### [`PipeOpLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner.html)\n\nThe [`PipeOpLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner.html) is constructed using a [mlr3](https://mlr3.mlr-org.com) [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) and will use it to create [`PredictionData`](https://mlr3.mlr-org.com/reference/PredictionData.html) in the `$predict()` phase.\nThe output during `$train()` is `NULL`.\nIt can be used after a preprocessing pipeline, and it is even possible to perform operations on the [`PredictionData`](https://mlr3.mlr-org.com/reference/PredictionData.html), for example by averaging multiple predictions or by using the `PipeOpBackupLearner`\" operator to impute predictions that a given model failed to create.\n\nThe following is a very simple [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) that performs training and prediction on data after performing principal component analysis.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-124_4cb161107b069f3bc8cc7ea6d97b6b6f'}\n\n```{.r .cell-code}\ngr = po(\"pca\") %>>% po(\"learner\",\n  lrn(\"classif.rpart\"))\n```\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-125_8d4cba25d033d924c8980931dc46fad6'}\n\n```{.r .cell-code}\ngr$train(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$classif.rpart.output\nNULL\n```\n:::\n\n```{.r .cell-code}\ngr$predict(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$classif.rpart.output\n<PredictionClassif> for 150 observations:\n    row_ids     truth  response\n          1    setosa    setosa\n          2    setosa    setosa\n          3    setosa    setosa\n---                            \n        148 virginica virginica\n        149 virginica virginica\n        150 virginica virginica\n```\n:::\n:::\n\n\n#### [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html)\n\nAlthough a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html) has `$train()` and `$predict()` functions, it can not be used directly in places where [mlr3](https://mlr3.mlr-org.com) `Learners` can be used like resampling or benchmarks.\nFor this, it needs to be wrapped in a [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) object, which is a thin wrapper that enables this functionality.\nThe resulting [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) is extremely versatile, because every part of it can be modified, replaced, parameterized and optimized over.\nResampling the graph above can be done the same way that resampling of the [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) was performed in the [introductory example](#whats-the-point).\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-126_b91bd6a211a003be27fd9a151e39aef3'}\n\n```{.r .cell-code}\nlrngrph = as_learner(gr)\nresample(task, lrngrph, rsmp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ResampleResult> of 1 iterations\n* Task: iris\n* Learner: pca.classif.rpart\n* Warnings: 0 in 0 iterations\n* Errors: 0 in 0 iterations\n```\n:::\n:::\n\n\n### Hyperparameters\n\n[mlr3pipelines](https://cran.r-project.org/package=mlr3pipelines) relies on the [paradox](https://paradox.mlr-org.com) package to provide parameters that can modify each [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)'s behavior.\n[paradox](https://paradox.mlr-org.com) parameters provide information about the parameters that can be changed, as well as their types and ranges.\nThey provide a unified interface for benchmarks and parameter optimization (\"tuning\").\nFor a deep dive into [paradox](https://paradox.mlr-org.com), see [the tuning chapter](#searchspace) or the [in-depth `paradox` chapter](#paradox).\n\nThe [`ParamSet`](https://paradox.mlr-org.com/reference/ParamSet.html), representing the space of possible parameter configurations of a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html), can be inspected by accessing the **`$param_set`** slot of a [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) or a [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html).\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-127_2e26084240c9f326084e38b22cc18357'}\n\n```{.r .cell-code}\nop_pca = po(\"pca\")\nop_pca$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ParamSet:pca>\n               id    class lower upper nlevels       default value\n1:         center ParamLgl    NA    NA       2          TRUE      \n2:         scale. ParamLgl    NA    NA       2         FALSE      \n3:          rank. ParamInt     1   Inf     Inf                    \n4: affect_columns ParamUty    NA    NA     Inf <Selector[1]>      \n```\n:::\n:::\n\n\nTo set or retrieve a parameter, the **`$param_set$values`** slot can be accessed.\nAlternatively, the `param_vals` value can be given during construction.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-128_7790a41235e0ba47153aff5e9b4adcbc'}\n\n```{.r .cell-code}\nop_pca$param_set$values$center = FALSE\nop_pca$param_set$values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$center\n[1] FALSE\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-129_d6c15ed6234cf8f146fdf22ddd7ffac0'}\n\n```{.r .cell-code}\nop_pca = po(\"pca\", center = TRUE)\nop_pca$param_set$values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$center\n[1] TRUE\n```\n:::\n:::\n\n\nEach [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html) can bring its own individual parameters which are collected together in the [`Graph`](https://mlr3pipelines.mlr-org.com/reference/Graph.html)'s `$param_set`.\nA [`PipeOp`](https://mlr3pipelines.mlr-org.com/reference/PipeOp.html)'s parameter names are prefixed with its `$id` to prevent parameter name clashes.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-130_047afa830b2024fd0c4ad9a8fecc4b94'}\n\n```{.r .cell-code}\ngr = op_pca %>>% po(\"scale\")\ngr$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ParamSetCollection>\n                     id    class lower upper nlevels        default value\n1:           pca.center ParamLgl    NA    NA       2           TRUE  TRUE\n2:           pca.scale. ParamLgl    NA    NA       2          FALSE      \n3:            pca.rank. ParamInt     1   Inf     Inf                     \n4:   pca.affect_columns ParamUty    NA    NA     Inf  <Selector[1]>      \n5:         scale.center ParamLgl    NA    NA       2           TRUE      \n6:          scale.scale ParamLgl    NA    NA       2           TRUE      \n7:         scale.robust ParamLgl    NA    NA       2 <NoDefault[3]> FALSE\n8: scale.affect_columns ParamUty    NA    NA     Inf  <Selector[1]>      \n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-131_e5def29b766445af8e668692ffa66a23'}\n\n```{.r .cell-code}\ngr$param_set$values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$pca.center\n[1] TRUE\n\n$scale.robust\n[1] FALSE\n```\n:::\n:::\n\n\nBoth [`PipeOpLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_learner.html) and [`GraphLearner`](https://mlr3pipelines.mlr-org.com/reference/mlr_learners_graph.html) preserve parameters of the objects they encapsulate.\n\n\n::: {.cell hash='pipelines_cache/html/pipelines-132_5757da932c3d60f8ddaa94557e31fd1f'}\n\n```{.r .cell-code}\nop_rpart = po(\"learner\", lrn(\"classif.rpart\"))\nop_rpart$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ParamSet:classif.rpart>\n                id    class lower upper nlevels        default value\n 1:             cp ParamDbl     0     1     Inf           0.01      \n 2:     keep_model ParamLgl    NA    NA       2          FALSE      \n 3:     maxcompete ParamInt     0   Inf     Inf              4      \n 4:       maxdepth ParamInt     1    30      30             30      \n 5:   maxsurrogate ParamInt     0   Inf     Inf              5      \n 6:      minbucket ParamInt     1   Inf     Inf <NoDefault[3]>      \n 7:       minsplit ParamInt     1   Inf     Inf             20      \n 8: surrogatestyle ParamInt     0     1       2              0      \n 9:   usesurrogate ParamInt     0     2       3              2      \n10:           xval ParamInt     0   Inf     Inf             10     0\n```\n:::\n:::\n\n::: {.cell hash='pipelines_cache/html/pipelines-133_3a26521637476ac3010b80f644a32ab0'}\n\n```{.r .cell-code}\nglrn = as_learner(gr %>>% op_rpart)\nglrn$param_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ParamSetCollection>\n                              id    class lower upper nlevels        default\n 1:                   pca.center ParamLgl    NA    NA       2           TRUE\n 2:                   pca.scale. ParamLgl    NA    NA       2          FALSE\n 3:                    pca.rank. ParamInt     1   Inf     Inf               \n 4:           pca.affect_columns ParamUty    NA    NA     Inf  <Selector[1]>\n 5:                 scale.center ParamLgl    NA    NA       2           TRUE\n 6:                  scale.scale ParamLgl    NA    NA       2           TRUE\n 7:                 scale.robust ParamLgl    NA    NA       2 <NoDefault[3]>\n 8:         scale.affect_columns ParamUty    NA    NA     Inf  <Selector[1]>\n 9:             classif.rpart.cp ParamDbl     0     1     Inf           0.01\n10:     classif.rpart.keep_model ParamLgl    NA    NA       2          FALSE\n11:     classif.rpart.maxcompete ParamInt     0   Inf     Inf              4\n12:       classif.rpart.maxdepth ParamInt     1    30      30             30\n13:   classif.rpart.maxsurrogate ParamInt     0   Inf     Inf              5\n14:      classif.rpart.minbucket ParamInt     1   Inf     Inf <NoDefault[3]>\n15:       classif.rpart.minsplit ParamInt     1   Inf     Inf             20\n16: classif.rpart.surrogatestyle ParamInt     0     1       2              0\n17:   classif.rpart.usesurrogate ParamInt     0     2       3              2\n18:           classif.rpart.xval ParamInt     0   Inf     Inf             10\n1 variable not shown: [value]\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}