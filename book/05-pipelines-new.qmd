# Pipelines {#pipelines}

```{r pipelines-setup, include = F}
library(mlr3)
library(mlr3book)
library(mlr3pipelines)
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
knitr::opts_chunk$set(fig.width=7, fig.height=5)
```

Machine learning toolkits often try to abstract away the processes happening inside machine learning algorithms.
This makes it easy for the user to switch out one algorithm for another without having to worry about what is happening inside, what kind of data it is able to operate on etc.
The benefit of using `r mlr3book::mlr_pkg("mlr3")`, for example, is that one can use any `r ref("Learner")`, `r ref("Task")`, or `r ref("Resampling")` etc. and use them for typical machine learning operations, mostly independently of what algorithms or datasets they represent.
In the following code snippet, for example, it would be trivial to swap in a different `r ref("Learner")` than `"classif.rpart"` without having to worry about implementation details of the Learners involved:
```{r 05-pipelines-in-depth-002, eval = FALSE}
task = as_task_classif(iris, target = "Species")
lrn = lrn("classif.rpart")
rsmp = rsmp("holdout")
resample(task, lrn, rsmp)
```

However, this modularity breaks down as soon as the learning algorithm encompasses more than just model fitting, like data preprocessing, ensembles or even more complicated meta-models.
This is where `r mlr3book::cran_pkg("mlr3pipelines")` steps in: it takes modularity one step further than `r mlr3book::mlr_pkg("mlr3")` and makes it possible to build individual steps within a `r ref("Learner")` out of building blocks that manipulate data, called `r ref("PipeOp")`s.

`r mlr3book::mlr_pkg("mlr3pipelines")` [@mlr3pipelines] is a dataflow programming toolkit for `r mlr3book::mlr_pkg("mlr3")`.
It provides an expressive and intuitive language for defining processes such as data preprocessing, model fitting, ensemble learning and prediction post-processsing.
Individual, frequently encountered building blocks, such as missing value imputation or majority vote ensembling, are provided as (R6-)objects, so-called PipeOps.
These PipeOps can be connected using directed edges inside a Graph (or Pipeline) to represent the flow of data between operations.

Some examples of what can be implemented with `r mlr3book::mlr_pkg("mlr3pipelines")` are:

* Data manipulation and preprocessing operations, e.g. PCA, feature filtering, imputation.
* Task subsampling for speed or for handling imbalanced classes.
* `r mlr3book::mlr_pkg("mlr3")` Learner operations for prediction and stacking.
* Ensemble methods and aggregation of predictions.

A very simple sequential Graph that does various preprocessing operations before fitting a Learner looks like the following:
```{r 05-pipelines-002, echo=FALSE, fig.align='center'}
knitr::include_graphics("images/single_pipe.svg")
```

An example for a more elaborate Pipeline that does alternative path branching and can therefore be [tuned](#optimization) to use the best preprocessing operation `r mlr3book::mlr_pkg("mlr3pipelines")` is depicted here:
```{r 05-pipelines-003, echo = FALSE, width = 10, height = 10, eval = TRUE, message=FALSE}
# This just produces a plot, not visible to the user.
library("mlr3pipelines")

graph = po("branch", c("nop", "pca", "scale")) %>>%
  gunion(list(
    po("nop", id = "null1"),
    po("pca"),
    po("scale")
  ))
gr = graph %>>%
  po("unbranch", c("nop", "pca", "scale")) %>>%
  po("learner", lrn("classif.rpart"))

gr$plot(html = FALSE)
```

In the following, we will # TODO

# Quick Introduction{#pipelines-quick-introduction}
 <!-- 6 pages -->

While the following chapters will give an in-depth introduction to `r mlr3book::mlr_pkg("mlr3pipelines")` that explain its concepts in detail, we will first present a quick introduction sufficient to get started.
To use `mlr3pipelines`, it suffices to load the package:
```{r pipeop-quickstart-library}
library("mlr3pipelines")
```

## Creating and Configuring `PipeOP`s

`PipeOp`s can easily be created using the `po()` short access function.
Just like `Learner`s, they have hyperparameters that can be set during construction as well as using the `$param_set$values` slot.
The ID of a `PipeOp` can be set during construction as well; this may be necessary to avoid nameclashes later on, because when `PipeOp`s are combined in a `Graph`, they need to have differing IDs.

```{r pipeop-quickstart-construction-1}
pca = po("pca", scale. = TRUE)
pca
pca2 = po("pca", id = "pca2")
pca2$param_set$values$center = FALSE
pca2
```

An `mlr3` `Learner` can be turned into a `PipeOp` (a `PipeOpLearner`, in fact) using `as_pipeop()`.
This is, however, often not necessary since this happens automatically in most places where a `PipeOp` is expected.
```{r pipeop-quickstart-construction-2}
lp = as_pipeop(lrn("classif.rpart"))
lp
```

More about `PipeOp`s and how they are created and configured is described in Chapter TODO.

## Creating `Graph`s

The easiest way to combine `PipeOp`s is to use the `%>>%`-operator.
It combines its left hand side with its right hand side sequentially, so that the right hand side gets the result from its left hand side as input.
The `$plot()` method can be used to show what `Graph` was created:

```{r pipeop-quickstart-graphs-1}
gr = pca %>>% lp
gr$plot(html = FALSE)
```

Chapter TODO gives a more in-depth introduction into how simple `Graph`s are constructed.

## Using `Graph`s as `Learners`s

`Graph`s in which the last operation is a `PipeOpLearner` can be turned into a `Learner` (a `GraphLearner`, to be precise) that performs the operations represented by the `Graph` in order by using `as_learner()`.

```{r pipeop-quickstart-graphlearner-1}
gl = as_learner(gr)
gl
gl$train(tsk("iris"))
gl$model$classif.rpart$model
```

Notice how the decision variables in the model are not the columns of the original dataset, but instead the principal components extracted by the `"pca"`-`PipeOp`.
The `Learner` can be `resample()`d, `benchmark()`d and `tune()`d just as a normal `Learner`.

```{r pipeop-quickstart-graphlearner-2}
rr = resample(tsk("iris"), gl, rsmp("cv"))
rr$aggregate()
```

When evaluating the performance of a machine learning process consisting e.g. of preprocessing, followed by model fitting, it is strongly advised to always put the entire preprocessing operation *inside* the resampling loop, as is done here -- `mlr3pipelines` encourages this more accurate approach.
Making a PCA on the entire dataset (i.e. `tsk("iris")`) instead, followed by resampling the `"classif.rpart"` `Learner` on it, would effectively leak information from the training set to the test set, leading to biased results.

See Chapter TODO about how to effectively use `Graph`s as `Learner`s in `mlr3`.


## Tuning `GraphLearner`s

`mlr3pipelines` is well suited for tuning entire machine learning pipelines.
For one because performance evaluations are more accurate, see above, but also because the constructed `Graph` objects have a combined hyperparameter space that can be tuned together.
Notice how the hyperparameters of both the `"pca"` `PipeOp`, as well as of the `"classif.rpart"` `Learner`, are present.
They are prefixed by each object's ID to avoid possible name clashes.

```{r pipeop-quickstart-graphlearner-3}
gl$param_set
```

This `GraphLearner` behaves like any other `Learner` for the sake of tuning. The following tunes the number of principal components to use, along with the tree size to use:
```{r pipeop-quickstart-tuning-1}
library("mlr3tuning")
gl$param_set$values$pca.rank. = to_tune(1, 4)
gl$param_set$values$classif.rpart.maxdepth = to_tune(2, 6)

tr = tune(tnr("grid_search"), tsk("iris"), gl, rsmp("cv"))
tr$result
```

Chapter TODO gives more details on the topic of tuning `Graph`s.

## Non-Sequential `Graph`s

One distinguishing feature of `mlr3pipelines` is that it can represent `Graph`s with parallel paths, for example alternative preprocessing operations that then get combined together in a "`cbind`"-operation. To arrange `Graph`s in parallel, the `gunion()`-function can be used. The `%>>%` operator tries to automatically connect all outputs of its left hand side to all inputs of its right hand side. The following fits a model on both the centered and the non-centered principal components of the `iris` dataset. The features get combined using the `"featureunion"` `PipeOp` and then given to the `"classif.rpart"` `Learner`.
```{r pipeop-quickstart-nonseq-1}
gr2 = gunion(list(po("pca", center = TRUE), po("pca", center = FALSE, id = "pca2"))) %>>%
  po("featureunion", innum = c("centered", "noncentered")) %>>% lrn("classif.rpart")
gr2$keep_results = TRUE
gr2$plot(html = FALSE)
gl2 = as_learner(gr2)
gl2$train(tsk("iris"))
```
This already shows some advanced usage necessary for this scenario: The ID of one of the `"pca"` `PipeOp`s needs to be changed to avoid name collisions, and the `innum` construction argument of `"featureunion"` is set to a vector of column prefixes to use, as both `"pca"` `PipeOp`s produce columns with the same name.
Setting the`$keep_results` debug-flag of the `Graph` is not necessary, but it allows us to find out what was actually returned by the `"featureunion"` `PipeOp` during training:
```{r pipeop-quickstart-nonseq-2}
gl2$graph_model$pipeops$featureunion$.result
```
We can also look at the trained `"classif.rpart"`-model to see that both centered as well as noncentered features were used
```{r pipeop-quickstart-nonseq-3}
gl2$model$classif.rpart$model
```

See Chapter TODO for more on non-sequential `Graph`s.

## Common `Graph` Patterns

There are various patterns that frequently occur when building machine learning pipelines that consist of more than just a single `PipeOp` operation. A collection is provided in the `mlr_graphs`-`Dictionary` and can be accessed using the `ppl()` short access function. Examples are `"robustify"`, which does preprocessing that ensures that a given `Task` is compatible with a given `Learner`, `"branch"`, which does alternative path branching and introduces a hyperparameter that controls which part of a `Graph` gets executed, and `"stacking"`, which uses the prediction of one or more `Learner`s to support the training of another `Learner`.

The following is an example, using the `"classif.ranger"` and `"classif.multinom"` model predictions as features for a `"classif.rpart"` model:
```{r pipeop-quickstart-ppl-1}
library("mlr3learners")
gr3 = ppl("stacking", lrns(c("classif.ranger", "classif.multinom")), lrn("classif.rpart"))
gr3$plot(html = FALSE)
```

The `mlr_graphs` `Dictionary` is presented in Chapter TODO.

# `r ref("PipeOp")`: Pipeline Operators

The most basic unit of functionality within `r mlr3book::cran_pkg("mlr3pipelines")` is the `r ref("PipeOp")`, short for "pipeline operator", which represents a transformative operation on input (for example a training dataset) leading to output.
It can therefore be seen as a generalized notion of a function, with a certain twist: `r ref("PipeOp")`s behave differently during a "training phase" and a "prediction phase".
The training phase will typically generate a certain model of the data that is saved as internal state.
The prediction phase will then operate on the input data depending on the trained model.

An example of this behavior is the *principal component analysis* operation ("`r ref("PipeOpPCA")`"):
```{r pipeop-intro-1}
pca = po("pca")
pca
```

Training is done using the `$train()`-method. Unlike the `Learner`'s `$train()` method, the `PipeOp`'s `$train()` can have multiple inputs, as well as multiple outputs. This is realized through `list`s: Both the `$train()` input as well as output of a `PipeOp` is always a `list`; depending on the operation, these lists have one or more elements. To use the `"pca"` `PipeOp`, for example, it is called with a list with a single element, the training `Task`. In return it produces the resulting `Task` with features replaced by their principal components.

```{r 05-pipelines-in-depth-003}
poin = list(tsk("iris"))
poout = pca$train(poin)
poout
poout[[1]]$data()
```

During training, the PCA transforms incoming data by rotating it in a way that leads to uncorrelated features ordered by their contribution to total variance.
The rotation matrix is also saved to be used for new data during the "prediction phase".
This makes it possible to perform "prediction" with single rows of new data, where a row's scores on each of the principal components (the components of the *training* data!) is computed.

Similarly to `$train()`, the `$predict()` function operates on `list`s:

```{r 05-pipelines-in-depth-004}
single_line_iris = tsk("iris")$filter(1)
single_line_iris$data()
poin = list(single_line_iris)
poout = pca$predict(poin)
poout[[1]]$data()
```

The internal state that is trained in the `$train()` call is saved in the `$state` property. Its function is comparable to that of the `$model` of a `Learner`, and its content depends on the class of `PipeOp` being used.

```{r 05-pipelines-in-depth-005}
pca$state
```

TODO: https://raw.githubusercontent.com/mlr-org/mlr-outreach/main/2021_mlr3_talks/mlr3pipelines.pdf , state-bild "(6/37)"

## Creating `r ref("PipeOp")`s

Each `r ref("PipeOp")` is an instance of an "`R6`" class, many of which are provided by the `r mlr3book::cran_pkg("mlr3pipelines")` package itself.
They can be retrieved from the `r ref("mlr_pipeops")` dictionary, most easily by using the `po()` short access function.
Besides that, they can also be constructed explicitly ("`PipeOpPCA$new()`").
When retrieving `r ref("PipeOp")`s from the `r ref("mlr_pipeops")` dictionary, it is also possible to give additional constructor arguments, such as an [id](#pipeop-ids-and-id-name-clashes) or [parameter values](#hyperparameters). Setting the ID explicitly is necessary when using multiple instances of the same class of `PipeOp` in a single `Graph`, since otherwise a name collision would occur, see [LINK](#ids-and-id-name-clashes)

```{r 05-pipelines-in-depth-009}
po("pca", rank. = 3, id = "pca2")
```

Some `PipeOp`s, in fact, require construction arguments, for example when they are operators that wrap another `mlr3`-object.
```{r 05-pipelines-pipeops-005, eval = FALSE}
learner = po("learner")

# Error in as_learner(learner) : argument "learner" is missing, with no default
```

```{r 05-pipelines-pipeops-006}
learner = po("learner", lrn("classif.rpart"))
```

Calling `po()` by itself prints all available `PipeOp`s, and `as.data.table(po())` will give a more detailed list with more meta-data.
```{r 05-pipelines-in-depth-010}
po()
```


# `r ref("Graph")`: Networks of `r ref("PipeOp")`s


## Basics: Sequential `Graph`s

`PipeOp`s are used to represent individual computational steps in machine learning pipelines, whereas these pipelines themselves are defined by `Graph` objects.
A `r ref("Graph")` is a collection of `r ref("PipeOp")`s with "edges" that mandate that data should be flowing along them.

It is most convenient to build up a `r ref("Graph")` from a sequence of `PipeOp`s, which can be done using the **`%>>%`** ("double-arrow") operator.
When given two `r ref("PipeOp")`s, it creates a `Graph` that executes first the left-hand `PipeOp`, followed by the right-hand `PipeOp`.
It can also be used to sequence a `r ref("Graph")` with a `PipeOp`, or another `Graph`. The following example creates a `Graph` that first adds a `Petal.Area` feature to a given dataset, and then performs scaling and centering of all numeric features.
```{r 05-sequential-01}
p_area = po("mutate", mutation = list(Petal.Area = ~Petal.Width * Petal.Length))
p_scale = po("scale")
gr = p_area %>>% p_scale
```

While the printer of a `r ref("Graph")` gives some information about the layout of a `Graph`, the most intuitive way of visualizing it is using the `$plot()` function.

```{r 05-pipelines-in-depth-017}
print(gr)
```

```{r 05-pipelines-in-depth-018, fig.width = 8, fig.height = 8}
gr$plot(html = FALSE)
```


## `Graph`s are Nodes with Edges

Internally, `Graph`s are collections of `PipeOp`s with edges that connect them. 
The collection of `r ref("PipeOp")`s inside a `r ref("Graph")` can be accessed through the **`$pipeops`** slot.
The set of edges in the Graph can be inspected through the **`$edges`** slot.

```{r 05-pipelines-in-depth-018-2}
gr$pipeops
gr$edges
```

Besides using the `%>>%`-operator (and a few more advanced operations presented in Section TODO) to create `Graph`s, it is also possible to create them explicitly. 
A `r ref("Graph")` is empty when first created, and `r ref("PipeOp")`s can be added using the **`$add_pipeop()`** method.
The **`$add_edge()`** method is used to create connections between them.
The above `Graph` can therefore also be created in the following way:


```{r 05-pipelines-in-depth-016}
gr = Graph$new()
gr$add_pipeop(p_area)
gr$add_pipeop(p_scale)
gr$add_edge("mutate", "scale")  # address by PipeOp-ID
```


:::{.callout-warning}
Although it is also possible to modify individual `PipeOps` and edges in a Graph through the `$pipeops` and `$edges` slots, this is not recommended, because no error checking is performed and it may put the `r ref("Graph")` in an unsupported state.
:::

## Using a `Graph`

A `r ref("Graph")` itself has a **`$train()`** and a **`$predict()`** method that accept some data and propagate this data through the network of `r ref("PipeOp")`s.
The return value corresponds to the output of the `r ref("PipeOp")` outputs that are not connected to other `r ref("PipeOp")`s. Just like for `PipeOp`s, the output is a list.

```{r 05-pipelines-in-depth-019}
result = gr$train(tsk("iris"))
result
result[[1]]$data()
```

```{r 05-pipelines-in-depth-020}
result = gr$predict(single_line_iris)
result[[1]]$data()
```

## Debugging a `Graph` with Intermediate Results

When `Graph`s are evaluated, they do not keep intermediate results for memory efficiency, unless the `$keep_results` flag is set first. Inspecting these results may help understanding the inner workings of `Graph`s, in particular when they produce unexpected results. 

```{r 05-pipelines-in-depth-021-x}
gr$keep_results = TRUE
result = gr$predict(single_line_iris)
intermediate = gr$pipeops$scale$.result
intermediate
intermediate[[1]]$data()
```

# Sequential `Learner`-Pipelines

Probably the most common application for `mlr3pipelines` is to use it to perform basic preprocessing tasks, such as missing value imputation or factor encoding, and to then feed the resulting data into a `Learner`.
A `Graph` representing this workflow manipulates data and fits a `Learner`-model during training, and uses the fitted model with data that was likewise preprocessed during prediction.
Conceptually, the process may look as follows:

```{r 05-pipelines-modeling-002, echo=FALSE }
knitr::include_graphics("images/pipe_action.svg")
```

While a `Learner` is not a `PipeOp` by itself, it can easily be converted into one using `as_pipeop()`, or alternatively `po("learner")`, which creates a `PipeOpLearner`-wrapper-class.
```{r 05-pipelines-modeling-0}
l_rpart = lrn("classif.rpart")
p_rpart = po("learner", l_rpart)
p_rpart
```

However, this is rarely necessary, since the `%>>%`-operator automatically converts `Learner`s to `PipeOp`s. The following code creates a `Graph` that adds a `Petal.Area` feature, followed by fitting a `"classif.rpart"` decision tree model.

```{r 05-pipelines-modeling-1}
p_area = po("mutate", mutation = list(Petal.Area = ~Petal.Width * Petal.Length))
gr = p_area %>>% l_rpart  # could just as well use p_rpart
gr$plot(html = FALSE)
```

While the whole `Graph` object behaves similarly to a `Learner`, it is still a distinct kind of object. To use a `Graph` as a `Learner` within `mlr3`, it is necessary to use a wrapper-class, `GraphLearner`. This can be constructed by calling `as_learner()`:
```{r 05-pipelines-modeling-2}
glrn = as_learner(gr)
```
This `Learner` can be used like any other `mlr3`-`Learner`. In particular it can be used with `resample()` and `benchmark()`. Let us compare our sequential pipeline with the `"classif.rpart"`-`Learner` by itself:
```{r 05-pipelines-modeling-3}
grid = benchmark_grid(tsks("iris"), list(glrn, l_rpart), rsmps("repeated_cv"))
bmr = benchmark(grid)
bmr$aggregate()
```

## Accessing Pipeline Objects

The `glrn` variable containing the `GraphLearner` object can be used as an ordinary `Learner`. However, it is really a wrapper around a `Graph`, which contains `PipeOp`s, which themselves contain things. The following demonstrates how the flow of data in a `GraphLearner` can be analyzed. First, the `$keep_results` flag is set so intermediate results are retained. The `Graph` can be accessed through the `$graph_model` slot.
```{r 05-pipelines-modeling-debugging}
glrn$graph_model$keep_results = TRUE
glrn$train(tsk("iris"))
```

It is now possible to investigate what data was given to the `"classif.rpart"` `Learner` by looking at the output of the `mutate`-`PipeOp`.
As expected, it contains the additional feature `Petal.Area`.
```{r 05-pipelines-modeling-debugging-1}
mutate_result = glrn$graph_model$pipeops$mutate$.result
mutate_result
mutate_result[[1]]$data()
```

One can also look at the `$state` of the various `PipeOp`s to investigate the trained model. Here the trained `"classif.rpart"` classification tree is interesting. However, it is wrapped inside a `PipeOpLearner`. The trained `Learner` has to be extracted from the `PipeOp` before inspection.
```{r 05-pipelines-modeling-debugging-2}
trained_p_rpart = glrn$graph_model$pipeops$classif.rpart
trained_p_rpart
trained_l_rpart = trained_p_rpart$learner_model
trained_l_rpart
trained_l_rpart$model
```

## Pipeline Hyperparameters

Just like `mlr3` `Learner`s, `PipeOp`s can have *hyperparameters* provided by the [`r mlr3book::mlr_pkg("paradox")`](https://paradox.mlr-org.com) package that modify the `PipeOp`'s behavior.
They can be accessed through the `$param_set` slot and provide information about the parameters that can be changed.

```{r 05-pipelines-in-depth-032}
p_pca = po("pca")
p_pca$param_set
```

As for `Learner` objects, the `$param_set$values` slot can be accessed to change hyperparameter settings; alternatively, hyperparameter values can be given during construction.

```{r 05-pipelines-in-depth-033}
p_pca$param_set$values$center = FALSE
p_pca$param_set$values
```
Alternatively:
```{r 05-pipelines-in-depth-034}
p_pca = po("pca", center = FALSE)
p_pca$param_set$values
```

Each `r ref("PipeOp")` can bring its own individual parameters which are collected together in the `r ref("Graph")`'s `$param_set`.
A `r ref("PipeOp")`'s parameter names are prefixed with its `$id` to prevent parameter name clashes.

```{r 05-pipelines-in-depth-035}
gr = p_pca %>>% po("scale", center = TRUE)
gr$param_set
gr$param_set$values
```

When a `Learner` gets encapsulated in a `PipeOpLearner` through `as_pipeop()`, it exposes the `Learner`'s `ParamSet`. When this `PipeOp` then becomes part of a `Graph`, the hyperparameters get prefixed with the `PipeOp`'s ID, which is the `Learner`'s ID by default. When a `Graph` is converted back to a `Learner` using `as_learner`, the resulting `GraphLearner` retains the `Graph`'s `ParamSet`.

```{r 05-pipelines-in-depth-037}
l_rpart = lrn("classif.rpart", maxdepth = 2)
l_rpart$param_set$values
p_rpart = as_pipeop(l_rpart)
p_rpart$param_set$values
gr = p_pca %>>% p_rpart
gr$param_set$values
glrn = as_learner(gr)
glrn$param_set$values
```

The hyperparameters of a `GraphLearner` can be changed directly (recommended), but they can also be accessed indirectly by modifying the underlying `Graph`'s, `PipeOp`'s, or `Learner`'s hyperparameters. The following demonstrates the many options:

```{r 05-pipelines-in-depth-038}
# modify directly
glrn$param_set$values$classif.rpart.cp = 0.1
# modify Graph
glrn$graph_model$param_set$values$classif.rpart.maxcompete = 10
# modify PipeOp
glrn$graph_model$pipeops$classif.rpart$param_set$values$minbucket = 2
# modify Learner
glrn$graph_model$pipeops$classif.rpart$learner_model$param_set$values$minsplit = 10
glrn$param_set$values
```

## IDs and Name Clashes

To ensure that `PipeOp`s can be accessed by their ID within `Graph`s, it is necessary that their IDs within a `Graph` are unique. IDs can be set during construction using the `id`-argument of `po()`, or they can be changed for existing `PipeOp`s. For `PipeOp`s that are already in a `Graph`, the `$set_names()` method can also be used to change IDs, although this should arely be necessary.

```{r 05-pipelines-in-depth-039, eval = FALSE}
gr = po("pca") %>>% po("pca")
# Error in gunion(list(g1, g2), in_place = c(TRUE, TRUE)) :
# Assertion on 'ids of pipe operators of graphs' failed: Must have unique names, but element 2 is duplicated.
```

```{r 05-pipelines-in-depth-040}
gr = po("pca") %>>% po("pca", id = "pca2")
gr
gr$set_names("pca", "pca1")
gr
```

:::{.callout-warning}
Do not change the ID of a `PipeOp` that is already in a `Graph` through `graph$pipeops$<old_id>$id = <new_id>`, since this will only change the `PipeOp`'s record of its own ID, not the `Graph`'s record. The `PipeOp` will have undefined behavior in this case.
:::

# Advanced Graphs

So far, we have shown how simple sequential `Graph`s can be built from preprocessing `PipeOp`s and encapsulated `Learner`s. We will now show more involved pipelines that can perform more complex operations.

## Parallel `PipeOp`s

Beyond chaining `PipeOp`s sequentially to perform preprocessing operations in order, it is also possible to arrange `PipeOp`s in parallel. Most `Graph` layouts can be built using two tools:

* The **`gunion()`** operation, which takes multiple `PipeOp`s, `Graph`s, or a mixture of them, and arranges them in parallel, and
* the **`%>>%`**-operator, which is able to chain `Graph`s that contain parallel elements, as long as the number of inputs and outputs matches. It can even connect a `Graph` with a single output to a `Graph` with multiple inputs (the data is distributed to all inputs), or a `Graph` with multiple outputs to certain special `PipeOp`s with a single input.

The following creates a `Graph` that first centers its inputs, and then copies the scaled data to two parallel streams: one replaces the data with columns that indicate whether data is missing, the other imputes missing data using the median. The outputs of both streams are then combined into a single dataset using `PipeOpFeatureUnion`.

```{r 05-pipelines-modeling-003}
gr = po("scale", center = TRUE, scale = FALSE) %>>%
  gunion(list(
    po("missind"),
    po("imputemedian")
  )) %>>%
  po("featureunion")
gr$plot(html = FALSE)
```

Processing the first five lines of the "Pima" dataset with this `Graph` shows how the missing values of the `insulin` and `triceps` features are handled: they are imputed, and the corresponding "missing"-columns indicate where values were missing.
```{r 05-pipelines-modeling-004}
pima_head = tsk("pima")$filter(1:5)
pima_head$data()
result = gr$train(pima_head)
result[[1]]$data()
```

## `PipeOpSelect`, `PipeOpFeatureUnion`, and `affect_columns`

It is a typical pattern for `Graph`s that an operation should be applied to a certain subset of features, but not to another subset. There are two two ways in which this can be realized:

1. Many preprocessing `PipeOp`s have an `affect_columns` hyperparameter. It can be set so that the `PipeOp` only operates on a certain subset of columns.
1. One can use the `PipeOpSelect` operator in parallel, picking out certain features on which operations should be performed, and unite the result using `PipeOpFeatureUnion`.

Both of these solutions make use of `Selector`-functions. These are helper-functions that indicate to a `PipeOp` which features an operation it should apply to. Straightforward `Selector`s are, for example, `selector_grep()`, which selects features by name matching a regular expression, or `selector_type()`, which selects by type. Other `Selector`s can perform set-operations (`selector_union()`, `selector_setdiff()`) or take all features *not* taken by another `Selector` (`selector_invert()`).

If one wants to perform PCA on the "Petal" features of the Iris dataset, but only do scaling on the other features, one would first need a `Selector` that selects these two columns:
```{r 05-pipelines-multicol-1}
sel_petal = selector_grep("^Petal")
sel_not_petal = selector_invert(sel_petal)
```

Solving the problem with the `affect_columns` hyperparameter would work as follows:
```{r 05-pipelines-multicol-2}
gr = po("pca", affect_columns = sel_petal) %>>%
  po("scale", affect_columns = sel_not_petal)

result = gr$train(tsk("iris"))
result[[1]]$data()
```

Solving this using parallel paths makes use of the `PipeOpSelect` operator. It removes all features that are not selected by a given `Selector`, making it possible to have independent data processing streams for different feature subsets. Since two `PipeOpSelect` operators are present, it is necessary to give them different IDs to avoid id name clashes. The solution makes use of the fact that all parallel paths all copies of the input data when they are at the beginning of a `Graph`.
```{r 05-pipelines-multicol-3}
gr = gunion(list(
  po("select", id = "sel_petal", selector = sel_petal) %>>% po("pca"),
  po("select", id = "sel_sepal", selector = sel_not_petal) %>>% po("scale")
)) %>>% po("featureunion")
gr$plot(html = FALSE)
```
```{r 05-pipelines-multicol-4}
result = gr$train(tsk("iris"))
result[[1]]$data()
```

The advantage of the first method is that it creates a very simple, sequential `Graph`. However, sometimes it is not possible to perform a desired operation only using `affect_columns`, particularly when the same set of features is used in multiple operations, or when the original features should be kept. The following, for example, performs PCA on the "Petal" features, but also keeps all original features. The latter is accomplished using the `PipeOpNOP` operator that does not change its operand.


```{r 05-pipelines-multicol-5}
gr = gunion(list(
  po("select", id = "sel_petal", selector = sel_petal) %>>% po("pca"),
  po("nop")
)) %>>% po("featureunion")
gr$plot(html = FALSE)
```
```{r 05-pipelines-multicol-6}
result = gr$train(tsk("iris"))
result[[1]]$data()
```

## Bagging {#pipe-model-ensembles-bagging}

We first examine Bagging introduced by [@Breiman1996].
The basic idea is to create multiple predictors and then aggregate those to a single, more powerful predictor.

> "... multiple versions are formed
> by making bootstrap replicates of the learning set
> and using these as new learning sets" [@Breiman1996]

Bagging then aggregates a set of predictors by averaging (regression) or majority vote (classification).
The idea behind bagging is, that a set of weak, but different predictors can be combined in order to arrive at a single, better predictor.

We can achieve this by downsampling our data before training a learner, repeating this e.g. 10 times and then performing a majority vote on the predictions.
Graphically, it may be summarized as follows:

```{r 05-pipelines-non-linear-008, echo=FALSE}
knitr::include_graphics("images/nonlinear_pipeops.svg")
```

First, we create a simple pipeline, that uses `r ref("PipeOpSubsample")` before a `r ref("PipeOpLearner")` is trained:

```{r 05-pipelines-non-linear-009}
single_pred = po("subsample", frac = 0.7) %>>% lrn("classif.rpart")
```

We can now copy this operation 10 times using `r ref("pipeline_greplicate")`.
The `r ref("pipeline_greplicate")` allows us to parallelize many copies of an operation by creating a Graph containing `n` copies of the input Graph.

```{r 05-pipelines-non-linear-010}
pred_set = pipeline_greplicate(single_pred, 10)
```

Afterwards we need to aggregate the 10 pipelines to form a single model:

```{r 05-pipelines-non-linear-011}
bagging = pred_set %>>%
  po("classifavg", innum = 10)
```

Now we can plot again to see what happens:

```{r 05-pipelines-non-linear-012, fig.width=7.5}
bagging$plot(html = FALSE)
```

This pipeline can be converted to a `r ref("Learner")`; the following compares it to a single `"classif.rpart"`-`Learner`:

```{r 05-pipelines-non-linear-013}
l_bag = as_learner(bagging)
l_bag$id = "bagging"
l_rpart = lrn("classif.rpart")
grid = benchmark_grid(tsks("iris"), list(l_bag, l_rpart), rsmps("repeated_cv"))
bmr = benchmark(grid)
bmr$aggregate()
```

## `PipeOpLearnerCV` and Stacking

## Stacking {#pipe-model-ensembles-stacking}

Stacking [@Wolpert1992] is another technique that can improve model performance.
The basic idea behind stacking is the use of predictions from one model as features for a subsequent model to possibly improve performance.

Below an conceptual illustration of stacking:

```{r 05-pipelines-non-linear-014, echo=FALSE, fig.align='center', out.width="98%"}
knitr::include_graphics("images/stacking.svg")
```

As an example we can train a decision tree and use the predictions from this model in conjunction with the original features in order to train an additional model on top.

To limit overfitting, we additionally do not predict on the original predictions of the learner and use `r ref("PipeOpLearnerCV")` instead.
`r ref("PipeOpLearnerCV")` performs nested cross-validation on the training data, fitting a model in each fold.
Each of the models is then used to predict on the out-of-fold data.
As a result, we obtain predictions for every data point in our input data.

We first create a "level 0" learner, which is used to extract a lower level prediction.

```{r 05-pipelines-non-linear-015, eval = TRUE}
l_rpart = lrn("classif.rpart")
lrn_0 = po("learner_cv", l_rpart, id = "rpart_cv")
```

We use `r ref("PipeOpNOP")`  in combination with `r ref("gunion")`, in order to send the unchanged Task to the next level.
There it is combined with the predictions from our decision tree learner.

```{r 05-pipelines-non-linear-016, eval = TRUE}
level_0 = gunion(list(lrn_0, po("nop")))
```

Afterwards, we want to concatenate the predictions from `r ref("PipeOpLearnerCV")` and the original Task using `r ref("PipeOpFeatureUnion")` :

```{r 05-pipelines-non-linear-017, eval = TRUE}
combined = level_0 %>>% po("featureunion")
```

Now we can train another learner on top of the combined features:

```{r 05-pipelines-non-linear-018, fig.width=7.5, eval = TRUE}
stack = combined %>>% po("learner", l_rpart)
stack$plot(html = FALSE)
```

Training this model shows how the second `"classif.rpart"`-`Learner` used the output of the first `"classif.rpart"`-`Learner` as input.

```{r 05-pipelines-non-linear-019, eval = TRUE}
l_stack = as_learner(stack)
l_stack$train(tsk("iris"))
l_stack$graph_model$pipeops$classif.rpart$learner_model$model
```

In many real-world applications, stacking is done for multiple levels and on multiple representations of the dataset.
On a lower level, different preprocessing methods can be defined in conjunction with several learners.
On a higher level, we can then combine those predictions in order to form a very powerful model.


# Tuning Graphs



## Tuning Combined Spaces

Here we define a `r ref("ParamSet")` for the "rpart" learner and the "variance" filter which should be optimized during the tuning process.

```{r 05-pipelines-modeling-008}
library("paradox")
ps = ps(
  classif.rpart.cp = p_dbl(lower = 0, upper = 0.05),
  variance.filter.frac = p_dbl(lower = 0.25, upper = 1)
)
```

After having defined the `r ref("Tuner")`, a random search with 10 iterations is created.
For the inner resampling, we are simply using holdout (single split into train/test) to keep the runtimes reasonable.

```{r 05-pipelines-modeling-009}
library("mlr3tuning")
instance = TuningInstanceSingleCrit$new(
  task = task,
  learner = glrn,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  search_space = ps,
  terminator = trm("evals", n_evals = 20)
)
```

```{r 05-pipelines-modeling-010}
tuner = tnr("random_search")
tuner$optimize(instance)
```

The tuning result can be found in the respective `result` slots.

```{r 05-pipelines-modeling-011}
instance$result_learner_param_vals
instance$result_y
```


## Tuning Alternative Paths

The `r ref("PipeOpBranch")` and `r ref("PipeOpUnbranch")` POs make it possible to specify multiple alternative paths.
Only one path is actually executed, the others are ignored.
The active path is determined by a hyperparameter.
This concept makes it possible to tune alternative preprocessing paths (or learner models).

Below a conceptual visualization of branching:

```{r 05-pipelines-non-linear-002, echo=FALSE, fig.align='center', out.width="98%"}
knitr::include_graphics("images/branching.svg")
```

`PipeOp(Un)Branch` is initialized either with the number of branches, or with a `character`-vector indicating the names of the branches.
If names are given, the "branch-choosing" hyperparameter becomes more readable.
In the following, we set three options:

1. Doing nothing ("nop")
1. Applying a PCA
1. Scaling the data

It is important to "unbranch" again after "branching", so that the outputs are merged into one result objects.

In the following we first create the branched graph and then show what happens if the "unbranching" is not applied:

```{r 05-pipelines-non-linear-003, eval = TRUE}
graph = po("branch", c("nop", "pca", "scale")) %>>%
  gunion(list(
    po("nop", id = "null1"),
    po("pca"),
    po("scale")
  )) %>>% po("unbranch", c("nop", "pca", "scale"))
```

We obtain the following results:

```{r 05-pipelines-non-linear-004}
graph$plot(html = FALSE)
```

TODO: tune this

## Tuning `PipeOpProxy`

TODO

# Common Patterns and `ppl()`

TODO: this?

The example above showed a linear preprocessing pipeline, but it is in fact possible to build true "graphs" of operations, as long as no loops are introduced^[It is tempting to denote this as a "directed acyclic graph", but this would not be entirely correct because edges run between channels of `r ref("PipeOp")`s, not `r ref("PipeOp")`s themselves.].
`r ref("PipeOp")`s with multiple output channels can feed their data to multiple different subsequent `r ref("PipeOp")`s, and `r ref("PipeOp")`s with multiple input channels can take results from different `r ref("PipeOp")`s.
When a `r ref("PipeOp")` has more than one input / output channel, then the `r ref("Graph")`'s `$add_edge()` method needs an additional argument that indicates which channel to connect to.
This argument can be given in the form of an integer, or as the name of the channel.

The following constructs a `r ref("Graph")` that copies the input and gives one copy each to a "scale" and a "pca" `r ref("PipeOp")`.
The resulting columns of each operation are put next to each other by "featureunion".

```{r 05-pipelines-in-depth-021, tidy = FALSE}
gr = Graph$new()$
  add_pipeop(po("copy", outnum = 2))$
  add_pipeop(po("scale"))$
  add_pipeop(po("pca"))$
  add_pipeop(po("featureunion", innum = 2))

gr$
  add_edge("copy", "scale", src_channel = 1)$        # designating channel by index
  add_edge("copy", "pca", src_channel = "output2")$  # designating channel by name
  add_edge("scale", "featureunion", dst_channel = 1)$
  add_edge("pca", "featureunion", dst_channel = 2)

gr$plot(html = FALSE)
```
```{r 05-pipelines-in-depth-022}
# gr$train(iris_first_half)[[1]]$data()
```

## Multilevel Stacking

In order to showcase the power of `r mlr3book::mlr_pkg("mlr3pipelines")`, we will show a more complicated stacking example.

In this case, we train a `r mlr3book::cran_pkg("glmnet")` and 2 different `r mlr3book::cran_pkg("rpart")` models (some transform its inputs using `r ref("PipeOpPCA")`) on our task in the "level 0" and concatenate them with the original features (via `r ref("gunion")`).
The result is then passed on to "level 1", where we copy the concatenated features 3 times and put this task into an `r mlr3book::cran_pkg("rpart")` and a `r mlr3book::cran_pkg("glmnet")` model.
Additionally, we keep a version of the "level 0" output (via `r ref("PipeOpNOP")`) and pass this on to "level 2".
In "level 2" we simply concatenate all "level 1" outputs and train a final decision tree.

In the following examples, use `<lrn>$param_set$values$<param_name> = <param_value>` to set hyperparameters for the different learner.

```{r 05-pipelines-non-linear-020}
library("magrittr")
library("mlr3learners") # for classif.glmnet

rprt = lrn("classif.rpart", predict_type = "prob")
glmn = lrn("classif.glmnet", predict_type = "prob")

#  Create Learner CV Operators
lrn_0 = po("learner_cv", rprt, id = "rpart_cv_1")
lrn_0$param_set$values$maxdepth = 5L
lrn_1 = po("pca", id = "pca1") %>>% po("learner_cv", rprt, id = "rpart_cv_2")
lrn_1$param_set$values$rpart_cv_2.maxdepth = 1L
lrn_2 = po("pca", id = "pca2") %>>% po("learner_cv", glmn)

# Union them with a PipeOpNULL to keep original features
level_0 = gunion(list(lrn_0, lrn_1, lrn_2, po("nop", id = "NOP1")))

# Cbind the output 3 times, train 2 learners but also keep level
# 0 predictions
level_1 = level_0 %>>%
  po("featureunion", 4) %>>%
  po("copy", 3) %>>%
  gunion(list(
    po("learner_cv", rprt, id = "rpart_cv_l1"),
    po("learner_cv", glmn, id = "glmnt_cv_l1"),
    po("nop", id = "NOP_l1")
  ))

# Cbind predictions, train a final learner
level_2 = level_1 %>>%
  po("featureunion", 3, id = "u2") %>>%
  po("learner", rprt, id = "rpart_l2")

# Plot the resulting graph
level_2$plot(html = FALSE)

task = tsk("iris")
lrn = as_learner(level_2)
```

And we can again call `.$train` and `.$predict`:

```{r 05-pipelines-non-linear-021, warning=FALSE}
lrn$
  train(task, train.idx)$
  predict(task, test.idx)$
  score()
```

# Graph, The Whole Story

## PipeOp Channels

### Input Channels

Just like functions, `r ref("PipeOp")`s can take multiple inputs.
These multiple inputs are always given as elements in the input list.
For example, there is a `r ref("PipeOpFeatureUnion")` that combines multiple tasks with different features and "`cbind()`s" them together, creating one combined task.
When two halves of the `iris` task are given, for example, it recreates the original task:

```{r 05-pipelines-in-depth-009}
iris_first_half = task$clone()$select(c("Petal.Length", "Petal.Width"))
iris_second_half = task$clone()$select(c("Sepal.Length", "Sepal.Width"))

pofu = po("featureunion", innum = 2)

pofu$train(list(iris_first_half, iris_second_half))[[1]]$data()
```

Because `r ref("PipeOpFeatureUnion")` effectively takes two input arguments here, we can say it has two **input channels**.
An input channel also carries information about the *type* of input that is acceptable.
The input channels of the `pofu` object constructed above, for example, each accept a `r ref("Task")` during training and prediction.
This information can be queried from the `$input` slot:

```{r 05-pipelines-in-depth-010}
pofu$input
```

Other `r ref("PipeOp")`s may have channels that take different types during different phases.
The `backuplearner` `r ref("PipeOp")`, for example, takes a `NULL` and a `r ref("Task")` during training, and a `r ref("Prediction")` and a `r ref("Task")` during prediction:

```{r 05-pipelines-in-depth-011}
# TODO this is an important case to handle here, do not delete unless there is a better example.
# po("backuplearner")$input
```

### Output Channels

Unlike the typical notion of a function, `r ref("PipeOp")`s can also have multiple **output channels**.
`$train()` and `$predict()` always return a list, so certain `r ref("PipeOp")`s may return lists with more than one element.
Similar to input channels, the information about the number and type of outputs given by a `r ref("PipeOp")` is available in the `$output` slot.
The `chunk` PipeOp, for example, chunks a given `r ref("Task")` into subsets and consequently returns multiple `r ref("Task")` objects, both during training and prediction.
The number of output channels must be given during construction through the `outnum` argument.

```{r 05-pipelines-in-depth-012}
po("chunk", outnum = 3)$output
```

Note that the number of output channels during training and prediction is the same.
A schema of a `r ref("PipeOp")` with two output channels:

```{r 05-pipelines-in-depth-013, echo = FALSE}
knitr::include_graphics("images/po_multi_alone.png")
```

### Channel Configuration

Most `r ref("PipeOp")`s have only one input channel (so they take a list with a single element), but there are a few with more than one;
In many cases, the number of input or output channels is determined during construction, e.g. through the `innum` / `outnum` arguments.
The `input.num` and `output.num` columns of the `r ref("mlr_pipeops")`-table [above](#where-to-get-pipeops) show the default number of channels, and `NA` if the number depends on a construction argument.

The default printer of a `r ref("PipeOp")` gives information about channel names and types:

TODO!!
```{r 05-pipelines-in-depth-014, out.width="98%"}
# po("backuplearner")
```

## Edges

TODO

Edges always pass between `r ref("PipeOp")` *channels*, so it is not only possible to explicitly prescribe which position of an input or output list an edge refers to, it makes it possible to make different components of a `r ref("PipeOp")`'s output flow to multiple different other `r ref("PipeOp")`s, as well as to have a `r ref("PipeOp")` gather its input from multiple other `r ref("PipeOp")`s.


A schema of a simple graph of `r ref("PipeOp")`s:

```{r 05-pipelines-in-depth-015, echo = FALSE}
knitr::include_graphics("images/po_multi_viz.png")
```


## How `%>>%` Works

TODO

# Specific PipeOps

## Imputation: `PipeOpImpute`

Often you will be using data sets that have missing values.
There are many methods of dealing with this issue, from relatively simple imputation using either mean, median or histograms to way more involved methods including using machine learning algorithms in order to predict missing values.
These methods are called imputation.

The following `r ref("PipeOp")`s, `r ref("PipeOpImpute")`:

- Add an indicator column marking whether a value for a given feature was missing or not (numeric only)
- Impute numeric values from a histogram
- Impute categorical values using a learner
- We use `po("featureunion")` and `po("nop")` to cbind the missing indicator features. In other words to combine the indicator columns with the rest of the data.

```{r 05-pipelines-special-pipeops-002}
# Imputation example
task = tsk("penguins")
task$missings()

# Add missing indicator columns ("dummy columns") to the Task
pom = po("missind")
# Simply pushes the input forward
nop = po("nop")
# Imputes numerical features by histogram.
pon = po("imputehist", id = "imputer_num")
# combines features (used here to add indicator columns to original data)
pou = po("featureunion")
# Impute categorical features by fitting a Learner ("classif.rpart") for each feature.
pof = po("imputelearner", lrn("classif.rpart"), id = "imputer_fct", affect_columns = selector_type("factor"))
```

Now we construct the graph.

```{r 05-pipelines-special-pipeops-003}
impgraph = list(
  pom,
  nop
) %>>% pou %>>% pof %>>% pon

impgraph$plot()
```

Now we get the new task and we can see that all of the missing values have been imputed.

```{r 05-pipelines-special-pipeops-004}
new_task = impgraph$train(task)[[1]]

new_task$missings()
```

A learner can thus be equipped with automatic imputation of missing values by adding an imputation Pipeop.

```{r 05-pipelines-special-pipeops-005}
polrn = po("learner", lrn("classif.rpart"))
lrn = as_learner(impgraph %>>% polrn)
```

## Feature Engineering: `PipeOpMutate`

New features can be added or computed from a task using `r ref("PipeOpMutate")` .
The operator evaluates one or multiple expressions provided in an `alist`.
In this example, we compute some new features on top of the `iris` task.
Then we add them to the data as illustrated below:

`iris` dataset looks like this:

```{r 05-pipelines-special-pipeops-006}
task = task = tsk("iris")
head(as.data.table(task))
```

Once we do the mutations, you can see the new columns:

```{r 05-pipelines-special-pipeops-007}
pom = po("mutate")

# Define a set of mutations
mutations = list(
  Sepal.Sum = ~ Sepal.Length + Sepal.Width,
  Petal.Sum = ~ Petal.Length + Petal.Width,
  Sepal.Petal.Ratio = ~ (Sepal.Length / Petal.Length)
)
pom$param_set$values$mutation = mutations

new_task = pom$train(list(task))[[1]]
head(as.data.table(new_task))
```

If outside data is required, we can make use of the `env` parameter.
Moreover, we provide an environment, where expressions are evaluated (`env` defaults to `.GlobalEnv`).

## Training on data subsets: `PipeOpChunk`

In cases, where data is too big to fit into the machine's memory, an often-used technique is to split the data into several parts.
Subsequently, the parts are trained on each part of the data.

After undertaking these steps, we aggregate the models.
In this example, we split our data into 4 parts using `r ref("PipeOpChunk")` .
Additionally, we create 4 `r ref("PipeOpLearner")`  POS, which are then trained on each split of the data.

```{r 05-pipelines-special-pipeops-008}
chks = po("chunk", 4)
lrns = ppl("greplicate", po("learner", lrn("classif.rpart")), 4)
```

Afterwards we can use `r ref("PipeOpClassifAvg")` to aggregate the predictions from the 4 different models into a new one.

```{r 05-pipelines-special-pipeops-009}
mjv = po("classifavg", 4)
```

We can now connect the different operators and visualize the full graph:

```{r 05-pipelines-special-pipeops-010, fig.width=7.5, fig.height = 9}
pipeline = chks %>>% lrns %>>% mjv
pipeline$plot(html = FALSE)
```

```{r 05-pipelines-special-pipeops-011}
task = tsk("iris")
train.idx = sample(seq_len(task$nrow), 120)
test.idx = setdiff(seq_len(task$nrow), train.idx)

pipelrn = as_learner(pipeline)
pipelrn$train(task, train.idx)$
  predict(task, train.idx)$
  score()
```

## Feature Selection beyond `PipeOpSelect`

When a particular, pre-determined set of features should be selected, the `PipeOpSelect` operator is usually sufficient. However, often it is desirable to select features depending on their relationship with the target variable, for example to create models that rely on only very few features while still being relatively performant. This process is called *feature filtering*.

The package `r mlr3book::mlr_pkg("mlr3filters")` contains many different `"mlr3filters::Filter")`s that can be used to select features for subsequent learners.
This is often required when the data has a large amount of features.

A `r ref("PipeOp")` for filters is `r ref("PipeOpFilter")`:

```{r 05-pipelines-special-pipeops-012}
po("filter", mlr3filters::flt("information_gain"))
```

How many features to keep can be set using `filter_nfeat`, `filter_frac` and `filter_cutoff`.

TODO some example

# Comparison to Recipes, SKLearn etc.

TODO
