# Parallelization {#parallelization}

```{r setup-07, include = FALSE, comment="", results="asis"}
library(fansi)
options(crayon.enabled = TRUE)
old.hooks <- fansi::set_knit_hooks(knitr::knit_hooks)

knitr::opts_chunk$set(collapse = TRUE)
```

`r gh_pkg("mlr-org/mlr3")` uses the `r cran_pkg("future")` backends for parallelization.
Make sure you have installed the required packages `r cran_pkg("future")` and
`r cran_pkg("future.apply")`:

`r gh_pkg("mlr-org/mlr3")` is capable of parallelizing a variety of different scenarios.
One of the most used cases is to parallelize the `r ref("Resampling")` iterations.
See [Section Resampling](#resampling) for a detailed introduction to resampling.

In the following, we will use the _spam_ task and a simple classification tree (`"classif.rpart"`) to showcase parallelization.

First, we run the experiment sequentially:

Now, we use the `r cran_pkg("future")` package to parallelize the resampling by selecting a backend via the function `r ref("future::plan()")` and then repeat the resampling.
We use the `"multiprocess"` backend here which uses threads on UNIX based systems and a "Socket" cluster on Windows.

```{r 07-parallelization-3, eval = FALSE}
future::plan("multiprocess")

task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.rpart")
resampling = mlr_resamplings$get("subsampling")

time = Sys.time()
  resample(task, learner, resampling)

Sys.time() - time
```

```{block, type='caution'}
By default all CPUs of your machine are used unless you specify argument `workers` in `future::plan()`.
```

On most systems you should see a decrease in the reported elapsed time.
On some systems (e.g. Windows), the overhead for parallelization is quite large though.
Therefore, it is advised to only enable parallelization for experiments which run more than 10s each.

## Choosing the parallelization level

Often you find yourself in the situation that multiple levels could potentially be run in parallel.
Depending on your experiment design you should choose the one that can be parallelized most efficiently and run all others sequentially.

Possible parallelization levels include:

- Hyperparameter tuning
- Resampling iterations
- Feature selection

```{block, type='warning'}
Setting custom parallelization levels is not yet supported.
```
