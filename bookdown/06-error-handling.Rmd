# Error Handling {#error-handling}

To demonstrate how to properly deal with misbehaving learners, `mlr3` ships with the learner `classif.debug`:

```{r 06-error-handling-1}
task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.debug")
print(learner)
```
The hyperparameters let us control
1. what conditions should be signaled (message, warning, error), and
2. during which stage the conditions should be signaled (train or predict).

Alternatively, we can tell the learner to provoke a segfault which tears down the complete R session.
With its default settings, it will do nothing special: it learns a random label which is used to create constant predictions.

## Conditions

In the defaults, `mlr3` does not handle catch conditions.
Thus, the exception raised by the debug learner stops the execution and can be tracebacked:

```{r 06-error-handling-2, error = TRUE}
task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.debug")
learner$param_set$values = list(error_train = TRUE)
e = Experiment$new(task, learner)
e$train()
```

<!--
Note that `mlr3` adds the class "trainError" to the error condition.
This allows us to differentiate errors thrown by the learner from other errors via `r ref("tryCatch()")`:
```{r}
tryCatch(e$train(),
  trainError = function(e) { message("model failed to fit") }
)
```
Analogously to "trainError", an exception with class "predictError" is raised if the learner is unable to predict,
and a "scoreError" is raised if the performance measure fails.
-->


## Encapsulation

The learner execution can be encapsulated, so that exceptions do not stop the program flow and output is logged to the experiment instead of just printed to the console.
One way to encapsulate the execution is provided by the package `r cran_pkg("evaluate")`.
The encapsulation can be enabled via `r ref("mlr_control()")`:
```{r 06-error-handling-3}
task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.debug")
learner$param_set$values = list(warning_train = TRUE, error_train = TRUE)

ctrl = mlr_control(encapsulate_train = "evaluate")
e = Experiment$new(task, learner, ctrl = ctrl)
e$train()
e$has_errors # any errors recorded?
e$log("train") # print train log
e$log("train")$warnings # get all the warnings
e$log("train")$errors # get all the errors
```
You can also enable the encapsulation for the *predict* step of an experiment by setting `encapsulate_predict` in `r ref("mlr_control()")`.

Another possibility to encapsulate is execution via package the [`callr`](https://cran.r-project.org/package=callr).
[`callr`](https://cran.r-project.org/package=callr) spawns a new R process, and thus even guards the session from segfaults.
On the downside, starting new processes comes with a computational overhead.

```{r 06-error-handling-5}
ctrl = mlr_control(encapsulate_train = "callr")
task = mlr_tasks$get("spam")
learner = mlr_learners$get("classif.debug")
learner$param_set$values = list(segfault_train = TRUE)
e = Experiment$new(task, learner)
e$train(ctrl = ctrl)
e$has_errors
e$log("train")$errors
```

Note that it is still impossible to perform the predict step without a fitted model:
```{r 06-error-handling-6, error = TRUE}
e$predict()
```


## Fallback learners

Fallback learners have the purpose to be able to continue with an experiment, although the learner or the measure are misbehaving in some sense.
Some typical examples include:

* The learner fails to fit a model during `$train()`.
  E.g., some convergence criterion is not met or the learner ran out of memory.
* The learner fails to predict for some or all observations during `$predict()`.
  E.g., new factor levels are encountered which the model cannot handle.

The fallback learner from the package `r mlr_pkg("mlr3pipelines")` can be used for these scenarios.
